 up again. All right, that is recording too. Yeah. Okay, so today I want to wrap up what
 we've been talking about with point clouds and what I've been calling geometric view
 of perception. Okay, so just to recap a bit, we started off by talking about, let's say
 maybe day one, in addition to introducing point clouds and cameras and the like, we
 talked about the point registration problem, where you have two point clouds and you're
 trying to find the pose that maps one into the other. So that's point set registration
 or point registration. We went from there into the iterative closest point algorithm.
 That snuck into day two, but that was the start. And then day two, we started addressing
 the fact that real point clouds are messy, right? We talked about the various ways that
 they could be messy. And we talked about generalizing the notion of correspondence as one way to
 address this, right? And things like more clever ways to deal with outliers, right?
 And we generally toyed around with generalizations of this point set registration problem. You
 know, we're trying to find, we've got two point clouds. We have to guess the correspondences
 or somehow be told the correspondences, but we're going to roughly try to register these
 two point clouds together. But I don't want to leave this sort of part of the course until
 I tell you that I don't think point registration, point set registration is sort of the only
 way to think about this. And it's not clear, we started talking about it a little bit at
 the end last time, that this idea that you should just find the pose that makes two point
 sets close together is always the best objective. It might be lacking in important ways.
 So today, I want to go beyond just registration and start thinking about some of the other
 aspects of what makes a good perception system, even if you're given just point cloud data,
 what are things that you need that maybe is beyond the metric which just says, are my
 points close together? Okay. And I can start with that, you know, and this is still in
 the context of sort of geometric perception. Unfortunately, there's a lot of perception
 that's beyond geometry too, but even in the landscape of sort of geometry, I think there's
 things that are missing from our basic algorithms, and I want to start talking about them today.
 So here's what happens when you start using ICP and all these variants, right? You have
 a beautiful model of your mustard bottle or your coffee mug or something like this. It's
 sitting on the table. You've got a couple cameras pointing at it, and ICP tells you
 roughly that, you know, here's the table, and it's like, you know, here's my mug, and
 it's telling you that your mug is in the table, right? For instance, like it got some returns,
 it did its best bet to fit, and it's giving you a pose back that says, you know, mug is
 in the table. I guarantee that'll happen. It'll happen for a bunch of different reasons,
 maybe because you have points down on the table that are pulling it down, you know,
 or we have outliers or something like this, but this is a very classic thing to happen
 is you're looking at it and you say, that's a silly answer. Clearly, the mug's not in
 the table. Or you'll get another one where, you know, the mug is floating in the air,
 and, you know, again, you know something that the point set registration algorithm doesn't
 know, which is that mugs don't spontaneously hover in the air, right? I mean, maybe when
 they're in motion, but if the scene is static, you know, then this shouldn't be a reasonable
 answer. And another one that you'll get often is if you're trying to register multiple things,
 it's sort of a version of this. You can get, you know, if you're trying to register multiple
 mugs at the same time, you'll get them overlapping, for instance, right? You'll say, it'll say,
 I found two mugs in the scene, for instance, and they're, you know, in penetration. Okay,
 so there's clearly things that you know that we somehow haven't yet expressed in our points
 should be close in a Euclidean distance objective. Okay? There's another really clever one about
 knowing, just knowing that the camera, you know, if the camera is getting point clouds
 here or points here, and the camera is over here, right? Then you also know, for instance,
 that there can't be an object anywhere here between the camera and the points, right?
 We haven't captured that yet either. So the goal for today is to think about ways
 to capture those kind of events. Yeah. So this I'll call, this here I'll call the free
 space constraints. This would be, I guess, both this one and this being in the table,
 these are non-penetration constraints. And this one's actually interesting, right? The
 fact that mugs don't fly normally. This has to do with physics, right? It requires something
 about the equations of motion to know that that's not an okay solution. So in the case
 of a static scene, I think the simplest version of this would just be to say this is a static
 equilibrium constraint. Right? You somehow know that if you were to draw the forces for
 a free body diagram, those forces should balance and you should have equilibrium, right? And
 we haven't yet told our perception system how to think about that. Okay. So all of these
 are possible. Some of them are harder than others, but to do it, we're going to have
 to start, we're going to have to give up a little bit on the beauty of our formulation,
 right? When we were up here, we were solving this beautiful problem in the point set, right?
 Registration, right? Our, you know, we were solving this sort of a problem with some correspondences
 known and we used primarily the singular value decomposition in our inner loop, right? This
 was our heavy hitter was the ability to, if I give you a bunch of two point clouds and
 I need to, and I know the correspondences, then the inner loop could be, I can find that
 pose using singular value decomposition. And that's beautiful and it always works. You
 know, it'll like, you can give it noisy point clouds, it'll find the best effort. It'll
 solve this least squares problem. Okay. And it's every time you call it, it'll give you
 the same answer. It's good stuff. We're going to give up on that. We're going to have more
 approximate methods these days that will work sometimes, not always, but can work, can handle
 a richer specification of problems. Okay. So I realized last time I went off the rails
 a little bit, which is, see, this is why it's good to come to lecture even when the videos
 are online, because I saw all of you going like, what? Right. And I, that's feedback
 for me to know I went a little fast at the end. So let me just make sure I put this in
 context, right? What we've been talking about, some of these optimization problems, we've
 been talking about convex optimization problems. And the examples I gave you before were, for
 instance, when I had a quadratic objective, right? I had, let's say, x1, x2, and I wanted
 to minimize over x something that looks like ax minus b squared, right? Subject to some
 linear constraints. We've been playing with this now as a quadratic program. Okay. So
 this is a beautiful type of optimization problem where I can take, I don't have to even worry
 too much about having an initial guess for x. All I need to do is find the minimum of
 this cost landscape, which satisfies these constraints. And I know that I found the optimal
 answer to the problem. This is just one example of the space of convex optimization problems,
 which we're going to use but not study in the depth that they're worth studying. But
 I think you can use them very effectively with just having this basic understanding
 of things that have quadratic objectives can be handed into a quadratic programming solver,
 for instance. If you had a linear objective but still linear constraints, that would be
 a linear program. Some of you know about that. There's other examples. So linear programming
 is a really important class. LPs. You might hear second order cone programming. This is
 LP. This is SOCP. And I mentioned too quickly last time, semi-definite programming, which
 is SDP. Okay. So there's these important classes of objective functions which look more interesting.
 They might look like ice cream cones instead of like a bowl. But they all have this property
 that if you write the problem down and you can fit it into one of these frameworks, then
 you are sure that your solver will be able to find a minima and give you the global answer.
 And we'll use some of them again as users throughout the class. But I want to mostly
 make a distinction between those and what we're going to start doing today, which is
 more general non-convex optimization. Okay. So now I'm going to think more generally about
 minimizing some function subject to some constraints. I still have my objective function
 up here, my constraints down here, and my decision variable is x. But now when f is
 arbitrary, I've lost this beautiful picture. I can suddenly start having cost landscapes
 that are much more complicated. Maybe f is doing this. And the expectations we should
 have for the algorithm are therefore a little bit less, right? We're going to basically
 have algorithms that will say if I start from an initial guess, they'll find a minimum,
 right? Maybe I start from this initial guess and I'll walk down the hill, right? And it
 will return a point saying, you know, this is the best I could find, right? Some minimum.
 We'll call this a local minimum. But we, in general, unless you know something more
 about the class of these curves, we lose the ability to say that I guarantee I found the
 best solution. Okay? So this is just a very high-level setup, but what I want you to make
 sure it lands is that the problem of registering two-point clouds where objective is just this
 nice quadratic distance between the points, we were able to use strong convex optimization
 kind of ideas for that. When you start doing these other important things, which are obviously
 important to rule out non-sensible solutions, then we are almost always going to leave this
 picture and enter this picture. So you will find you'll have perception systems that maybe
 don't stick the mug in the table, but they might not give you the best solution. How
 is that at that level? Are there questions at that level? I know some of you know this
 well and some of you, that's a very fast introduction to a big topic, but I'm trying to walk that
 line. Yes?
 [inaudible]
 That's a great question. So the question is, when humans are doing perception, what, you
 know, are we, what are we doing? Are our senses better or whatever? Of course, I don't know
 exactly the answer, but I think some things are clear. I think we are bringing so much
 extra information to bear on the problem, common sense type information that changes
 the way we perceive the world in ways that these geometric algorithms are not capturing.
 And even deep learning algorithms are not capturing, although they're getting closer,
 right? I think as we start, you know, using foundation models and big, large scale models
 that really have some broader understanding of where objects can be in the world, then
 maybe there's hope for some common sense. But like, you know, if I open a refrigerator,
 I have tons of priors about what I expect to see in the fridge and what I don't expect
 to see in the fridge, right? If there was, I don't know, a gorilla in my fridge, I would
 be surprised and my perception system would fail probably, right? You know, at least in
 the short term, I would probably run, you know, I don't know. But there's, I think if
 you, if you start reflecting on what you're doing as you're going through the world, before
 you open your eyes, you're bringing in so many initial guesses, right? Which then makes
 the, you know, I think we probably don't have super accurate geometric reasoning. I mean,
 people are good at 3D reasoning, but not like depth camera, sub millimeter accuracy kind
 of good. I think robots should be far superior than humans in terms of accuracy and those
 kinds of computations. Okay. But I think certainly we are able to rule out silly cases. The computational
 machinery with which we do that is hard to know. Yes.
 [inaudible]
 Okay. That's a huge question. I love it. Well, maybe, so the question was about tactile
 sensing and how, you know, but let me bite off a version of that question, right? So,
 how would, how would a tactile sensor, for instance, fit into this? And, and since we're
 talking about point clouds and geometry, a particular type of tactile sensor that's very
 popular these days is when you actually put a camera underneath your finger, okay, or
 palm or something like this, and you actually can get a point cloud. It's a very special
 point cloud that has, that never sees past your skin, for instance. But you can imagine
 actually using these tools almost out of the box with a tactile sensor also. Think of it
 as a camera that has a minimum, a maximum range that is your skin. Okay. But of course,
 bringing in things like non-penetration becomes very important when you know immediately that
 things are going to be touching before you, before you see them. So, so I think actually
 this lecture is very well motivated by tactile sensing. So, so why, you know, I think, I
 think you're right to continually press on why tactile sensors, I think tactile sensors
 have more potential than they have realized so far. I think everybody in the field would
 agree with that, but somehow we have, you know, massive data sets of, in a massive computer
 vision community and stuff like that, and we have like a few people making tactile sensors.
 A new one came out today, the GelSight Mini just came out today. If anybody saw that,
 that's cool. So maybe a new form factor, but, but they're just not as many, they're not
 in everybody's iPhones, right? It's a smaller scale. That community is still growing. Okay.
 So I want you to know actually that although there's a ton of things to know about these
 different problem classes, and when you go from non-convex to convex and things like
 this, when you're writing the, when you're writing code, for instance, in a mathematical
 program or in, there's a handful of optimization parsers which try to do some of the heavy
 lifting for you. Okay. So if you write in costs and constraints, you know, in the language
 of mathematical program, you add cost, add cost, add constraint. Mathematical program
 is actually doing a lot of work behind the scenes to decide whether you've still stayed
 in the realm of a convex optimization, and when it can detect that you have, then it
 will call a special solver that's extremely, you know, efficient for convex optimization.
 When you add a more general constraint, then it'll bounce over to a different, there's
 still custom solvers behind there that solve nonlinear problems, but they use a different
 set of algorithms behind the scenes. So, for instance, if you just in, you know, mathematical
 program, you add a quadratic cost, that's, so it doesn't even have to guess at this point.
 It knows the objective is quadratic when you say add quadratic cost. Okay. If you add a
 cost like this, actually, x dot x, where x is a decision variable, then because this
 is actually, x is actually symbolic, it knows enough to be able to parse that and realize
 you've added a quadratic constraint, and it will solve, call a QP solver. So, you know,
 like those are the same here. Okay. But you can also add arbitrary functions as costs
 or constraints, and we'll do that today. Okay. Just define a Python function. And here, it
 doesn't have the ability anymore to know that it's, even though this one happens to be quadratic,
 you could have put an arbitrary function behind there. So, it sees that it's going to start
 calling a nonlinear optimization solver. And when it calls your function, actually, it's
 going to pass in a version of x, a variable that is an autodiff type, which is automatic
 differentiation, so that it can also take gradients of your function and try to use,
 you know, gradients of this in order to get down there as fast as possible. Yes.
 [inaudible]
 That's a great point. So, there's two points to there. So, let me repeat the question. So,
 let's say I'm not taking a, you know, we've been talking mostly about you woke up, your eyes are
 open, the world was still, how do you understand it? And in that case, something like a static
 equilibrium constraint is appropriate. But the problem is actually different when things are
 moving, both in the case, in two ways. I think, first of all, if you open your eyes and admit
 things could have been moving when you started, then you don't want to be using static equilibrium
 constraints. You could use more general dynamic constraints. You know that things are not going
 to be, you know, falling faster than the acceleration due to gravity, for instance.
 That could be a constraint on your perception system. There's also a separate part of that
 question, which is, if I'm not opening my eyes and taking a one-shot sort of approach to it,
 but I'm rather tracking, then that can also change the problem. You can take an initial guess and
 expect that the answer only moved a little bit. And the same way we did instead of inverse
 kinematics, we did differential inverse kinematics. You could start taking, you know,
 just Jacobians of some of these things and expect actually a linearization of these problems to
 work fairly well. So I think in both ways, the tracking problem and the dynamic problem are
 pretty different. I'll mention tracking again at the end just to close that loop, but that's a
 very good point. Great. OK. So let's think about first the problem we already know, but in a way
 that gets us into non-convex. OK? So if I had parameterized my point registration problem,
 my point set registration problem, using theta instead of the pose written out with rotation
 matrices and the like, then already I have a non-convex formulation of the problem. So let
 me just say that carefully here. I think it's a good way to bridge to the more advanced versions
 here. If I wrote before, I was minimizing over p and r, where r was in SO(3), sum over i p plus r.
 OK. I could write it like this, or I can write it with the r transpose equals i, right?
 Determinant of r equals plus 1. Now, by writing this and this, I feel that I've over specified it,
 but at least it's super clear. OK? So the decision variables here were-- this is a matrix now. You
 know, r is a 3 by 3 matrix. This is a 3 by 1 vector, so I had 12 decision variables.
 Or in 2D, maybe it was a 2 by 2 matrix and a 2 by 1 in 2D. So what if we instead said,
 I want to parameterize this by just minimizing over p, which is the 2 by 1, and theta. OK?
 And I'll write the same objective, but now I'll have theta enter through the rotation matrix like
 this, right? Where r theta is my standard, cos theta minus sine theta, sine theta, cos theta.
 OK. So I've changed my decision variables instead of being from the matrix-- the entries of the
 matrix r to now being just one variable theta, right? This is just a scalar. That seems good.
 I've got less decision variables, maybe. But my beautiful quadratic bowls are not beautiful
 quadratic bowls anymore. I've got some sines and cosines in here that are changing it.
 In this simplest example, I can actually-- we can still think about what that landscape looks like.
 OK? So let's do that. And just so I can draw it on the board, let's even do it with the
 rotation-only case first. I'll just say positions are known, or we maybe played our trick of using
 relative positions, so we did everything relative. So let's think about having our model. So we had
 an accident last time, and my blue chalk is no longer with us. So the model points are now green.
 Sorry for that. I had a nice thing going there, but it's like my non-symmetric shape. This is my
 model points in 2D. OK? I've got my scene points, which are going to be only rotation for now,
 because I've already subtracted out-- because we know we can subtract that out. I've got my
 scene points like this. And the question is, what does the objective-- if I plot a function of theta,
 what does this cost look like? And is it going to be terrible, or is it going to be sort of OK?
 And I think it's actually not that bad to draw. It takes kind of a thought experiment,
 but let's take any one of these points. This is with the known correspondences,
 this case. So if I have my model point and my scene point, then my cost is the distance here.
 OK? My rotation, they should be-- if I had drawn it perfectly, they would lie on a circle,
 right? Because they can only-- they're only allowed to rotate, then those things are just
 going to move along the circle, right? OK. So if I have an initial guess, then my claim
 is that actually all-- this point here is going to contribute one cost term, which is
 the distance of that arc, right? The distance of that arc is going to be a function of my
 angle, theta, and the distance from the origin. I can just use my standard cosine-- law of
 cosines to figure out what that is. If I know this length, and I know this length are both
 some radius r, and I have-- I can write it as a function of this angle, I can tell you
 what that distance is, right? It's going to be-- what is it? r squared plus r squared
 minus 2 r squared cosine theta. It should be the length of that distance. Let me just
 make sure that checks. If cosine is-- if theta is 0, so it's exactly the same thing, that's
 1, and this is the distance of 0. I'm pretty happy with that. It's close to that. OK.
 And let's say that's the distance for the r-- for the ith point. OK? Now, the sum of
 the distances is just going to be a sum of all these things
 added up. These are constants. From the point of view of this optimization, I'm just optimizing
 theta. So I just have, actually, cosine theta times a big sum of 2 ri squareds plus whatever
 this is, right? That's my cos landscape. Even though the shape is kind of interesting or
 whatever, in polar coordinates, it's actually really easy to write the cos landscape.
 So if I'm searching in this parameter space, it just looks like a cosine, roughly. Adding
 a constant will move it up and down. Adding a multiple like this will scale it up and
 down. But roughly, my cos landscape for in 2D, reconstructing the orientation, looks
 like this. OK? My claim is that these-- and that's supposed to be a nice cosine, not a
 lumpy cosine, which is sort of important to the point I'm making here. So maybe I'll just
 make that a little lower so that those are the same. Yeah?
 If I start a nonlinear optimization and its basic behavior is to go downhill until it
 finds a local minima, then in this setting, it's actually not bad, right? It might tell
 me something that's the angle I expected. It might tell me something that's 2 pi away
 from the angle I expected, but it's still right. It's not wrong. And the answer it gives
 me might depend on what my initial guess was, but it's actually going to solve that problem
 very nicely.
 In particular, there's a trendy way to say this, right? This function is non-convex,
 but all minima are global minima. So we like to try to say that about neural networks,
 too. OK? And there's other-- I think this is a new trend is understanding cost landscapes
 where they have this property that are not the simple picture, but they somehow still
 get optimization problems. OK? So all minima are global minima. Minima. So they achieve
 the same cost.
 So it's sort of not crazy if you're trying to parameterize 2D estimation problems in
 terms of data. This is a little bit too rosy of a picture. In 3D, it's going to get more
 crazy. And when you have to search for the correspondences also, we know from ICP, or
 we should expect from ICP, that there are going to be cases where it can get stuck in
 local minima. So we'll see that happen, too.
 But I want to establish that out of the box, it's not terrible to think about trying to
 search directly over this kind of a parameterization. And these are the kind of tools that you have
 in non-convex optimization. Yes?
 [INAUDIBLE]
 Yeah. I just need one more color to make that-- I was just trying to find a function to compute
 this distance, the distance between the point on the model and the corresponding point in
 the scene. And my claim was that that's an easy thing to compute if I call this r, and
 I do it in polar coordinates. This is also going to be r, since it's just rotating around
 the origin. That's all I've given it the ability to do if I've subtracted out the means properly.
 And this is r. So then my math was just to compute this distance as a function of my
 rotation angle theta.
 [INAUDIBLE]
 Yeah, yeah. So good. So when I get the correct theta, my cost is zero. I've lined up all
 my points in the noise-free case. When I go all the way to the opposite side, I've got
 the biggest possible distance and my biggest possible error. But if I keep wrapping around
 2 pi, then I'll get zero error again.
 [INAUDIBLE]
 In fact, so I should have drawn this stopping at the-- in fact, that would have been more
 insightful on my part. I didn't think of it that way. I just looked at it in the algebra
 and said, I've got some constant, so it could be anywhere. But actually, that should be
 zero. It touches zero when things line up perfectly.
 [INAUDIBLE]
 Good. I drew it with a zero here. I forgot. I've had that insight once.
 That's our toolbox. Now we want to start saying, OK, if that cost function isn't enough,
 isn't rich enough, or I could potentially use constraints, how do I want to change that
 in order to capture these more rich phenomenon?
 So remember last time we talked about generalized correspondences, but we still did that two-step
 optimization. So let me write that.
 So for instance, when we talked about the coherent point drift, CPD, last time, my claim
 was that it was minimizing over some pose some function like this, right? And this was
 set using a Gaussian kernel in an iterative algorithm. So the same way ICP set the correspondences
 based on minimum distance and then solved this problem, CPD was setting the correspondences
 to be soft correspondences using a Gaussian kernel and then solving the SPD problem. Set
 it, solve the SPD problem, and alternate.
 The dream would be that we can solve for the correspondences and the poses at the same
 time. Now if we're willing to go to the non-convex optimization, then we can do that. We can
 write that down. Our mileage may vary because there could be local minima, but we at least
 can write that down.
 So today, we can do that same sort of thing. In fact, the more general way to write this
 would be to say minimize-- I could do it in terms of x, but maybe I'll minimize directly
 over theta now, for instance. And I could say ij. Let's take a non-linear loss function.
 I'll be careful about this in a second. And maybe it's a function of the transform points.
 So let's keep that structure.
 But I restricted myself to just quadratic functions before. Now I'm going to have an
 arbitrary loss function. The quadratic form is best for optimization, maybe, but the arbitrary
 loss function allows us to capture things like outliers and other features.
 So here are some sort of standard choices. You might hear about Huber loss. You could
 use the Gaussian kernel. That's roughly what the CPD was doing, which is nice because the
 idea from the Gaussian was that points that are far away have no effect on your optimization.
 It's a little subtle. I drew this here the way that you would normally see it in terms
 of a loss function. The Gaussian doesn't go to 0 in the way I've drawn it, but it's still--
 because it's flat, it has no effect on the optimization.
 So points that are far out here, if you were to move your guess a little bit and move them
 from here to here, it doesn't change your cost. So even though in a cost landscape setting,
 you might shift yourself up or down because it doesn't go to 0, but it doesn't change
 the shape of the landscape.
 I'm saying something I think simple. I hope I didn't say it in a complicated way. It's
 just that we were a little restricted by this quadratic form before, and we had to do these
 games with the coefficients. The more general case is just write the function you wanted
 directly in the loss.
 Any questions about that? Yeah?
 [INAUDIBLE]
 We could have done this-- so the question-- maybe I'll just try my answer. Hopefully,
 it's clear from this. Why didn't we do this right from the get-go? This is certainly one
 instance of this. This is just a more general form. If I choose L to just be the quadratic
 form, it could just be take whatever's inside this function and square it and multiply it
 by C. So this is a special case of this. This is a more general thing. And because it's
 more general, it can do things like taper off on the sides, which is a general way to
 handle outliers. That's the same way that we were handling outliers before. We now have
 machinery that'll handle outliers like this.
 [INAUDIBLE]
 Yep. Before, what we were doing was we were taking the losses we got from corresponding
 points. If the points were very unlikely to be corresponding, we were making that loss
 effectively zero. Here, in the same way, we're saying if the points are too far away with
 a-- let's say the Gaussian loss, if they're too far away, we're saying it has no effect
 on my cost. It's a flat. It's not quite zero, but it's flat. So it has no effect on the
 shape of my cost.
 [INAUDIBLE]
 Yeah. So those points that are far away are given our current guess. This is always going
 to be based on your initial guess. You're saying that my model is here, my scene is
 here. I'm going to give no weight to the difference between-- I'm not going to worry about trying
 to make this one match this one. That one's just too far away to worry about. I'll worry
 about the points that are closer, where my model to scene is smaller.
 Yeah? I had a request, just to convince everybody that I do read all the surveys. I really do.
 Not many of you write that much of the surveys. You tell me how many hours it takes, which
 is a little bit high this time. But also, a few of you write comments, and I read them
 all. And someone asked for a stretch break. All right. So let's take two seconds to just
 stand up and stretch. Yeah? It's a good time for it. You have to listen better now.
 Thank you.
 All right. They also said it could be small. They just were like, I just want to stretch
 my legs. So we're back at it. That's it.
 OK. There's a bunch of things to know about writing loss functions and writing code that
 uses these kind of loss functions. So in particular, when we were operating on this Euclidean distance
 a lot, I mentioned that there's data structures that are really good for that. So if you want
 to just find nearest neighbors in some Euclidean distance sense, a natural data structure is
 to use KD trees or other data structures you've learned from computer science classes, just
 to be efficient nearest neighbors. When you get into these more general loss functions
 that are functions of distances, there are other clever tricks. One of the ones that
 I like best is actually to use these sine distance functions. It depends on exactly
 what thing you're computing, but a common data structure that's useful to make these
 things fast, SDF. Not the scene description format. It's a different SDF. There's too
 many of them flying around. So the sine distance field or function, again, Stanford bunny comes
 up often, is just-- you can pre-compute. If I have, let's say, a mesh and I want to compute
 what is the distance, the closest distance from any point in the space to that mesh.
 And if I'm going to be doing a lot of queries, that's just asking what is the distance from
 a point to the mesh, then an efficient algorithm will, for instance, just pre-compute on a
 grid all of the distances from points in space to the mesh. They'll throw that on a GPU and
 then be able to access that super fast to do lots and lots of point queries, lots of
 distance computations on these 3D objects. The sine distance function, it's signed because
 you have a positive distance when you're outside the mesh and a negative distance when you're
 inside the mesh, because it's important to distinguish those two. And zero when you're
 on the boundary. It's just another representation of geometry, but it happens to make these
 distance-based objectives and queries very efficient. Yes?
 [INAUDIBLE]
 Yeah, that's a good question. So the way I've written it here, you're going to move the
 model every time because as you change the decision variables. But remember I said you
 could have also done everything like this, OWPSI. So the question was, which one are
 you going to pre-compute the sine distance function for? Typically, you have a model
 that you can afford to pre-compute with, and the scene comes in every time. So it makes
 sense to try to do your pre-computation on the model, not the scene. And if you were
 to flip over to this representation where you're moving the scene points around to match
 the model, then that makes this more efficient. It's not crazy actually to take a sine distance
 function and rotate it and translate it also, but I think this is more natural. Great question.
 Yes?
 [INAUDIBLE]
 Yep.
 [INAUDIBLE]
 Good. So that's a good question. So are these all convex? So the definition of a convex
 function is that if I take any two points on that function, that I could draw a straight
 line and it would have to be-- for a function, it would have to be above the function. So
 let's take the truncated least squares as the most extreme point. If I have this value
 here and this value here, then because the straight line between them is below the function,
 it's actually not a convex function. And this looks benign. And there are cases where, kind
 of like all global minima are OK, there are some non-convex functions that are benign.
 But once you get into this space and you start adding them and shifting them and multiplying
 them and having multiple together, you can quickly get into things that have local minima.
 Great question. Yeah. So this one actually, the Huber loss probably is convex. Yeah. I
 think I have to look at it exactly. But that sure looks convex to my eye. But the others
 are not necessarily.
 So yeah, I think some of the more efficient algorithms for doing these sort of-- especially
 tracking will actually pre-compute sign distance functions for the different models and put
 them on a GPU.
 So that's nice. We don't have an iterative algorithm in the sense of correspondences
 than implementation. And then SVD, we can write it all as one optimization and hand
 it directly to a non-convex solver and get to some local minima using this kind of formulation.
 So far, we're still in the space of objectives we already had, roughly. The real power of
 going to non-convex optimization and the real motivation to do that is to handle those constraints
 that I said weren't fitting nicely into the standard-- our previous formulation, the non-penetration,
 the static equilibrium, and the free space constraints.
 So just as an example of non-penetration, in 2D, let's say I have a bunch of scene points.
 Let's say I've just got a box that I'm trying to find. I've got a bunch of scene points
 like this. And I want to fit my model to my scene with my green chalk. I was looking for
 blue. But I want to say that my transformed model should not be in penetration. The box,
 I know, shouldn't be in the table. It shouldn't be in the wall. How can I write that as an
 optimization? I would like to think of it coming up with something that's as close as
 possible. It's trying to match the data, but it refused to go into the wall.
 We could do the same thing we did before. We can say-- let's do it with just theta in
 2D here. So
 that objective maybe isn't so bad yet. But let's say I'm going to-- subject to the constraint
 that all of the model points, once they're transformed into the world coordinates, are--
 in this case, let's say it's 0, 0 here. Let's just say that they're greater than 0. So the
 x component is greater than 0 and the y component is greater than 0.
 This is a non-convex constraint because this is still-- I write that for all j. To flesh
 that out, remember, we have-- it's still a function of my decision variables. And it's
 a non-convex. It's not a linear function in this case. But we know how to write it.
 This landscape is going to be not as simple as that cosine. I've suddenly added new constraints
 on possible-- at immiscible thetas and p's. But the initial picture isn't that crazy.
 And isn't that different? And we can definitely ask our solver to do that kind of thing.
 And if you do, I did. And I got this. So here's my salmon red scene, my blue model. I drew
 the correspondences in. So if I did an ICP sort of loop but with that constraint, then
 I get a good solution out.
 So once we go to this non-convex optimization, we can start writing rich constraints. What
 I said last time too quickly was that there are some ways to do convex optimization for
 this type of constraint and a handful of them. There's a world of trying to make the best
 convex approximations of these, which I'm a fan of, that world. But it's a more subtle
 thing that I failed to make the point of last time. It's in the notes if you want.
 So how would you write this down just to make it sort of hopefully actionable? So if I had
 decision variables p, there's two of them in 2D for my positions, my xy position. Theta
 is one variable. And I can add my cost just like this. R, remember, is now a function
 of theta. So this is a nonlinear, non-convex objective. So I have to do it by-- I can't
 say add quadratic cost anymore. I add a cost and I hand it a function. And then I'll add
 constraint and I'll pass it a function to do that bottom one.
 But those functions are easy enough to write. I just can say what's the position in the
 world. I take R as cos theta, sine theta, sine theta, cos theta. And I compute my--
 it's just sort of the normal math. And then similarly, as a square, I can just call square,
 multiply the two vectors together in numpy. And mostly, it'll just work.
 There's a little crap about getting your variables into the function and out, this whole using
 partial and then unpacking with split. I'm not a huge fan of that. We'll make it better
 someday. But that's the tunnel that goes into the solver and then comes back out of the
 solver. So there's a little bit of boilerplate to make that good.
 That's what solved the previous problem. And it can solve much more complicated problems.
 The generalization of this idea is, in general, you can say I have multiple models. Or maybe
 the world is part of my model. It could be a function of the decision variables or it
 could just be welded to the world. That's fine.
 In general, you might say I want to search for q, the positions of my kinematics, such
 that the bodies match the points. You see why I think of it as a kinematics problem.
 And subject to the fact that there's no constraints. There's no collisions, no penetrations.
 So there's a huge library of these tools that you'll build up on the kinematics pipeline.
 They're all doing something like this under the scenes, but they're calling the kinematics
 methods to make it effective.
 So you can compute the signed distance of closest points between two bodies. That's
 queries that you can just ask the geometry engine for. And even better, you can just
 say I want the distance between two bodies to be at least some distance.
 And there's actually a bunch of details inside there to try to make that good for
 solvers. The computational geometry of doing those queries is sort of subtle, but I'll
 talk a bit about it next week when we talk about simulation.
 But if I have two bodies, then already you can imagine that finding the distance between
 two bodies, the closest distance between two bodies, that's like an interesting computational
 geometry problem. It seems sort of manageable when I draw it like that.
 It gets worse when they penetrate and you have to do the interior. Then the answers
 are not typically clean, even for relatively simple objects.
 But in particular for a solver, if you have multiple bodies, and if the closest point
 between bodies flops from being this body to this body, for instance, then that gives
 you cost functions that can look-- typically they're continuous but not differentiable.
 So you can have things like this in your cost landscape.
 And we try to do a lot of work to-- if it's at the minimum, that's one thing. It could
 also be on the way down to a minimum, it could do some silly things like this. These all
 make it harder for the optimizer to find its way to a good minimum.
 So there's hard work in the middle there that these functions do for you to try to smooth
 that out a little bit. Just not enough to change your answer significantly, but enough
 to make the numerics good. There's a lot of details behind it. There's all open source,
 so you can look at it. But the difference between writing your own like this and getting
 it all right versus calling one that's been hardened a little bit is in all these different
 little nuances.
 Non-penetration, this example of bodies moving around and not being allowed to penetrate,
 is a classic example where you will have local minima. You sort of don't expect to have the
 nice picture of this. So let me try to make that point. So imagine-- I've got to get all
 my colors right. So I've got some scene points over here. My box is here. I have some part
 of my world here, which I'd say don't run into the table or the wall or something like
 this. And my current guess is my model is over here. This sort of an optimization is
 going to try to pull it in here, and it's going to stop when it hits the constraint.
 And there's nothing powerful enough in the description we're giving it to suddenly change
 its mind and try something fundamentally different. And in general, even if your bodies are convex
 bodies, like the interior of the body that are convex, because we're working in the space
 outside those bodies, collision avoidance constraints are the classic example of local
 minima in optimization. It's one of the multiple minima in optimization. So don't expect miracles.
 It's going to get stuck here. It's going to say, here, this is the best I could do. It's
 not going to pop over here. But when you're close, it can do wonderful things with complicated
 constraints.
 I mentioned three to begin with. I mentioned non-penetration, which I gave a very simple
 example of there. I mentioned static stability constraints. I'm going to talk about that
 more. You'll even do a problem set, I think, on it when we talk about the physics engine,
 because you're going to use some of the equations of motion in order to write that kind of a
 constraint.
 But the last one, which I think is so important and maybe one of the biggest reasons why the
 point registration problem, I think, is not sufficient, is that gaze constraint, the free
 space constraint. And I think it's so clever.
 So this is the free space constraint. So if I have my scene points over here and my cameras
 over here, I guess I didn't get any returns over there because it's partial. It's occluded.
 Then I should immediately be able to say that any solution that's putting my model over
 here is a bad solution. It's not just that even if it's close in the sense of getting
 those points close, it's violating something that I know about the problem, which is to
 have gotten this point from that camera, it must not be anything here.
 So there's various ways to write that. The one that convinced me first of how important
 this was used sine distance functions on a GPU to make it fast. And the way that they
 did it was they actually made a new obstacle. They turned it into a non-penetration constraint.
 So they basically said, I'm going to go ahead and make an obstacle. I'll call it my observation
 obstacle, which is all, which is the, not the convex hull, it's the body defined by
 the rays between my camera and those points. And they said, I have a new body like this.
 I can compute the sine distance from that body on the fly and ask that the points in
 my model have a positive sine distance with that constraint.
 And I think that's just such an important cue that if you write an objective which says
 make my points match in a squared, in a quadratic sense, you just can't capture that. In fact,
 even if you've only reasoned about point clouds, you've already lost that piece of information,
 right? The depth image in some sense had more information than the point cloud. The point
 cloud has thrown away where the cameras were.
 But that is a hugely rich source of information to rule out a lot of possible strange candidates
 in the perception problem. And the folks that did that, I think, best, the one that I learned
 it from was this project called DART, which was trying to solve for Q. Is that playing?
 Oh, yeah. Okay. They compute these sine distance fields, right? That's a visualization of the
 sine distance function. And they do it for each body. And then they search over Q. And
 they make these incredible demos of even tracking real people's hands with an approximate model
 of a hand where they're just using this basic idea to solve that problem subject to the
 kinematics constraints. We're using theta instead of pose, non-penetration constraints,
 and free space constraints written as non-penetration constraints, all with sine distance functions.
 I put it in the middle because I had some cool visualizations of the optimization at
 work. Okay. So when you're seeing that, what are you seeing, right? You're seeing the solver
 take an initial guess. It has some Q. It's somewhere on the landscape. And it's walking
 down the landscape, and it's slowly fitting into the -- snapping into place. And they
 just did incredible tracking demos with this kind of work. Even tracking humans. Super
 impressive. It can get -- okay. So the property of these algorithms are that if you start
 with a good initial guess, it can snap in. But if you just think of this as like in the
 context of this demo, you actually saw it lost the arm for a second. Did you guys notice
 the frame where it lost the arm? So if it gets confused, then it's sometimes very hard
 to get back. So these things will work incredibly well until they don't and then they fall off
 the rails. So don't put it in a safety-critical application. But they're super powerful. Okay?
 And that's an example of using it recursively to solve the tracking problem like we talked
 about. So we took the initial guess. We found some minima. And then we took a new snapshot
 from our camera. The problem data moved a little bit. But hopefully the minima didn't
 move too much. And we just keep solving. And it's trying to track the moving minima in
 the landscape. [ Inaudible ]
 Those -- no, the limbs are all using the same tracking method. The comparison is -- I think
 only one of them is visualized in that. Yeah. So the parameterization is Q, which is like
 the generalized positions. And it's just searching through Q in order to solve those. Okay. So
 that was -- that's the sort of -- the importance of non-convex geometric reasoning in there.
 Like I said, there are more advanced topics in geometric perception. For instance, I really
 like the convex relaxations, where you try to find versions of the hard problem that
 you can solve very reliably. I put a very simple example of one in the notes. I think
 this notion of tracking gets into a nice set of different tools where you can solve the
 tracking problem differently than you'd solve just the one-shot perception problem. Like
 I say, you can use differential kinematics instead of inverse kinematics. So dynamic
 obstacles, if you will. And I would say dense reconstruction is also a nearby problem here.
 If you wanted to build a map of the world or build your object model from just having
 a camera moving around it, these two both are sort of -- you might have heard of SLAM,
 simultaneous localization and mapping in robotics. It's really based on the same foundations
 that we've talked about here. Very dependent on getting correspondences correct, but hugely
 powerful and important and successful applications of these.
 So if I just reflect back on what we did and where does it fit in the space of manipulation
 tools, I think geometry is incredibly important. I think our depth sensors are superhuman in
 their accuracy, for instance. So in terms of refinement of an initial guess, they're
 incredibly valuable. But I remember a few years ago when we started doing more work
 with deep learning perception and we were using RGB as much as we were using depth.
 And that transition sort of happened where we started using the color values, handing
 them to a neural network. And I remember asking the guys in the lab, I said, OK, if you were
 to give away either the depth or the RGB, if I can take one away, which one would you
 keep? And that answer flipped. And I think nowadays, if people have to pick just one,
 they would say, take my depth, give me my RGB. Because there's so much information that
 is not captured in the XYZ value of the point cloud. Context about when objects start, when
 they stop, but also much, much more than that. We haven't talked enough about RGB, but we
 will.
 I do think that it's very natural to combine guesses based on data-driven methods and RGB,
 and then refine them with the geometric methods. And I think we learned a bunch of cool geometry
 stuff. Hopefully it's good. OK, see you next time.
 [SIDE CONVERSATION]
