1
00:00:00,000 --> 00:00:00,760
 [INTERPOSING VOICES]

2
00:00:00,760 --> 00:00:02,040
 Hello.

3
00:00:02,040 --> 00:00:03,760
 Welcome, everybody.

4
00:00:03,760 --> 00:00:05,200
 Thank you for packing in.

5
00:00:05,200 --> 00:00:08,040
 We've got a room that's not quite big enough.

6
00:00:08,040 --> 00:00:09,720
 We're going to have to see how that goes.

7
00:00:09,720 --> 00:00:13,560
 So I will make adjustments as necessary.

8
00:00:13,560 --> 00:00:15,320
 And I encourage everybody to come to class.

9
00:00:15,320 --> 00:00:17,520
 So don't let this dissuade you.

10
00:00:17,520 --> 00:00:22,280
 And I'll do some hardware demos to try to keep you coming.

11
00:00:22,280 --> 00:00:25,120
 So yeah, welcome to robotic manipulation.

12
00:00:25,120 --> 00:00:27,080
 I had to call it robotic manipulation

13
00:00:27,080 --> 00:00:30,400
 because I just thought manipulation in general

14
00:00:30,400 --> 00:00:33,440
 without context could be anything.

15
00:00:33,440 --> 00:00:36,320
 But I'm going to just talk about manipulation today

16
00:00:36,320 --> 00:00:38,240
 and throughout the semester.

17
00:00:38,240 --> 00:00:40,280
 I hope that by the end of the lecture,

18
00:00:40,280 --> 00:00:43,720
 you'll understand a bit more about what

19
00:00:43,720 --> 00:00:46,520
 I mean by manipulation and what are the exciting challenges

20
00:00:46,520 --> 00:00:48,240
 that it brings.

21
00:00:48,240 --> 00:00:51,000
 In particular, I mean, you guys are

22
00:00:51,000 --> 00:00:53,720
 coming into the field at exactly the right time.

23
00:00:53,720 --> 00:00:57,600
 My gosh, if robots are not just on this incredible rate

24
00:00:57,600 --> 00:01:01,240
 of progress right now, the things that we can do today

25
00:01:01,240 --> 00:01:02,840
 that we couldn't do last year, it's

26
00:01:02,840 --> 00:01:04,760
 kind of a fun time to write course notes

27
00:01:04,760 --> 00:01:07,240
 because the course notes I worked hard on a year ago

28
00:01:07,240 --> 00:01:10,160
 are obsolete in great ways now.

29
00:01:10,160 --> 00:01:14,720
 So you'll watch the course notes evolve during the semester.

30
00:01:14,720 --> 00:01:18,040
 OK, so let me dive in.

31
00:01:18,040 --> 00:01:20,880
 Let me just start with a little bit of the course info.

32
00:01:20,880 --> 00:01:22,540
 First of all, I'll introduce the people.

33
00:01:22,540 --> 00:01:24,400
 I didn't mean for that to be me to pop up,

34
00:01:24,400 --> 00:01:28,320
 but Tommy's here working the video camera.

35
00:01:28,320 --> 00:01:30,200
 We are going to try to record the lectures.

36
00:01:30,200 --> 00:01:33,840
 There's actually a brand new video capture

37
00:01:33,840 --> 00:01:36,040
 system in the back of the room that hopefully will do it

38
00:01:36,040 --> 00:01:38,720
 automatically and hopefully will be beautiful and good.

39
00:01:38,720 --> 00:01:42,120
 But just in case, we're doing it manually this time too.

40
00:01:42,120 --> 00:01:45,120
 I can't guarantee that every lecture will be perfect online.

41
00:01:45,120 --> 00:01:47,360
 We've had times where the audio was gone

42
00:01:47,360 --> 00:01:49,920
 or the blackboard was too fuzzy or something like this.

43
00:01:49,920 --> 00:01:51,480
 So coming to class is great.

44
00:01:51,480 --> 00:01:54,960
 But we do try to put it online.

45
00:01:54,960 --> 00:01:58,440
 Sorry, Tommy's working the camera here.

46
00:01:58,440 --> 00:02:00,200
 Michael's right here.

47
00:02:00,200 --> 00:02:03,080
 We have also Quincy.

48
00:02:03,080 --> 00:02:04,760
 Is Quincy here?

49
00:02:04,760 --> 00:02:06,160
 Maybe Quincy's not here yet.

50
00:02:06,160 --> 00:02:07,800
 OK, Ethan I saw, definitely.

51
00:02:07,800 --> 00:02:09,000
 Ethan's here.

52
00:02:09,000 --> 00:02:11,520
 Sadhana, right there.

53
00:02:11,520 --> 00:02:12,840
 Broken image, sorry for that.

54
00:02:12,840 --> 00:02:15,960
 Pranav, is Pranav here?

55
00:02:15,960 --> 00:02:16,960
 We've got another class.

56
00:02:16,960 --> 00:02:17,740
 OK, yeah.

57
00:02:17,740 --> 00:02:20,800
 And then we also have two communication instructors.

58
00:02:20,800 --> 00:02:22,600
 So I'll say a few more words about that.

59
00:02:22,600 --> 00:02:25,040
 But Elena's over here.

60
00:02:25,040 --> 00:02:25,600
 Awesome.

61
00:02:25,600 --> 00:02:27,680
 I think it's an extremely strong core staff.

62
00:02:27,680 --> 00:02:32,240
 And I hope you'll work with us closely over the semester.

63
00:02:32,240 --> 00:02:35,600
 Let me say a few words about the communications part.

64
00:02:35,600 --> 00:02:38,320
 I get a lot of questions just as the semester starts about this.

65
00:02:38,320 --> 00:02:41,320
 And I just want to say it as clearly as possible right now.

66
00:02:41,320 --> 00:02:43,320
 So you can take the class as an undergraduate.

67
00:02:43,320 --> 00:02:46,200
 You can take the class, the graduate version of the class,

68
00:02:46,200 --> 00:02:48,880
 the 4212.

69
00:02:48,880 --> 00:02:50,340
 If you're in the undergraduate, that

70
00:02:50,340 --> 00:02:53,960
 comes with a CIM component, the communications intensive.

71
00:02:53,960 --> 00:02:56,000
 So that's a 15 unit course.

72
00:02:56,000 --> 00:02:59,480
 That adds recitations on Friday.

73
00:02:59,480 --> 00:03:02,160
 If you're a grad student, you don't take the recitations.

74
00:03:02,160 --> 00:03:04,600
 The requirements are hopefully very clear on the website.

75
00:03:04,600 --> 00:03:06,040
 The differences, the grad students

76
00:03:06,040 --> 00:03:08,760
 will have a few extra problems on the problem sets

77
00:03:08,760 --> 00:03:11,360
 and different requirements for the project.

78
00:03:11,360 --> 00:03:12,660
 Both groups will do projects.

79
00:03:12,660 --> 00:03:15,880
 The technical expectations for the graduate students

80
00:03:15,880 --> 00:03:16,720
 are the--

81
00:03:16,720 --> 00:03:18,720
 you can be an undergrad who takes the grad class.

82
00:03:18,720 --> 00:03:21,000
 If you take 4212, the expectation

83
00:03:21,000 --> 00:03:24,880
 on the technical part of the presentation goes up a bit.

84
00:03:24,880 --> 00:03:26,720
 But you lose the CIM.

85
00:03:26,720 --> 00:03:29,960
 Now the CIM, some of you need it for graduation.

86
00:03:29,960 --> 00:03:30,980
 Some of you don't.

87
00:03:30,980 --> 00:03:33,560
 But I actually think it's awesome, whether you need it

88
00:03:33,560 --> 00:03:35,000
 or don't need it.

89
00:03:35,000 --> 00:03:37,680
 I have to say the projects are a big part of the class.

90
00:03:37,680 --> 00:03:40,920
 And at the end of the semester, some of the best projects

91
00:03:40,920 --> 00:03:44,120
 that have come out have been the ones that have been nurtured

92
00:03:44,120 --> 00:03:47,440
 through the CIM process to be like super projects.

93
00:03:47,440 --> 00:03:49,360
 So I really think it's excellent.

94
00:03:49,360 --> 00:03:52,240
 There'll be journal clubs where you're reviewing manipulation

95
00:03:52,240 --> 00:03:53,680
 relevant papers to begin with.

96
00:03:53,680 --> 00:03:57,480
 And then it'll work into helping you through the project,

97
00:03:57,480 --> 00:04:01,600
 turning your project from a project to a super project.

98
00:04:01,600 --> 00:04:04,880
 But yeah, just so you-- those are your options.

99
00:04:04,880 --> 00:04:07,280
 And there's the project-related CI assignments

100
00:04:07,280 --> 00:04:09,040
 are hopefully clear on the website.

101
00:04:09,040 --> 00:04:13,520
 And you can see the relevant project-related for the 4212.

102
00:04:13,520 --> 00:04:14,400
 Put them side by side.

103
00:04:14,400 --> 00:04:15,200
 Make your decision.

104
00:04:15,600 --> 00:04:18,400
 Again, the recitations are only if you're in the CIM.

105
00:04:18,400 --> 00:04:24,000
 OK, just quick logistics.

106
00:04:24,000 --> 00:04:27,920
 So we're going to mostly use Piazza for the robotics

107
00:04:27,920 --> 00:04:30,200
 portion of the semester.

108
00:04:30,200 --> 00:04:32,400
 So please make sure you're on Piazza.

109
00:04:32,400 --> 00:04:34,160
 Your MIT credentials should get you in.

110
00:04:34,160 --> 00:04:35,880
 If you have any trouble, let us know.

111
00:04:35,880 --> 00:04:38,920
 The CIM component only will try to push material to you

112
00:04:38,920 --> 00:04:40,000
 through Canvas.

113
00:04:40,000 --> 00:04:41,880
 So if you're an undergrad or if you're--

114
00:04:41,880 --> 00:04:43,040
 I should just say undergrad.

115
00:04:43,040 --> 00:04:44,800
 If you're an undergrad or if you're--

116
00:04:44,800 --> 00:04:47,440
 I should just say if you're taking 4210,

117
00:04:47,440 --> 00:04:49,480
 you should sign up for Canvas or log into Canvas.

118
00:04:49,480 --> 00:04:51,480
 Everybody has credentials, but you don't need it

119
00:04:51,480 --> 00:04:53,880
 if you're in 4212.

120
00:04:53,880 --> 00:04:55,800
 The course guidelines are up on the website.

121
00:04:55,800 --> 00:04:58,520
 The percentage distribution, the late policy, all these things

122
00:04:58,520 --> 00:05:00,200
 are hopefully very clear on the website.

123
00:05:00,200 --> 00:05:02,720
 I'm not going to give you a piece of paper handout.

124
00:05:02,720 --> 00:05:04,200
 So please review them and just make

125
00:05:04,200 --> 00:05:05,340
 sure you're happy with them.

126
00:05:05,340 --> 00:05:07,280
 If you have any questions, ask.

127
00:05:07,280 --> 00:05:09,280
 The lecture notes are on the website too.

128
00:05:09,280 --> 00:05:12,240
 And they're meant to be interactive.

129
00:05:12,240 --> 00:05:13,520
 And they're meant to be even a place where

130
00:05:13,520 --> 00:05:14,800
 you can ask questions directly.

131
00:05:14,800 --> 00:05:16,800
 You can highlight something in the lecture notes,

132
00:05:16,800 --> 00:05:18,960
 say, what the heck did you mean by this?

133
00:05:18,960 --> 00:05:20,200
 And I will answer.

134
00:05:20,200 --> 00:05:24,200
 It's a good way to ask questions.

135
00:05:24,200 --> 00:05:26,200
 OK, we have roughly weekly problem sets.

136
00:05:26,200 --> 00:05:29,840
 They will taper off as the project tapers up, ramps up.

137
00:05:29,840 --> 00:05:32,160
 So they're due on Wednesday.

138
00:05:32,160 --> 00:05:34,440
 The first problem set will be released maybe today,

139
00:05:34,440 --> 00:05:36,240
 but certainly by tomorrow.

140
00:05:36,240 --> 00:05:37,560
 It's on the course calendar.

141
00:05:37,560 --> 00:05:39,640
 And the final project is a big part of the course.

142
00:05:39,640 --> 00:05:42,140
 You're going to be able to build some pretty awesome systems

143
00:05:42,140 --> 00:05:44,320
 and most of them will be in simulation.

144
00:05:44,320 --> 00:05:46,600
 Some of you might have some hardware you want to try.

145
00:05:46,600 --> 00:05:49,760
 We have some hardware that if you convince me in simulation

146
00:05:49,760 --> 00:05:54,080
 that it's ready for hardware, we can try to help you with that.

147
00:05:54,080 --> 00:05:56,120
 OK, so all of the course website,

148
00:05:56,120 --> 00:06:01,800
 all the details of assignments and late terms, late policies

149
00:06:01,800 --> 00:06:03,840
 and everything are all on the website.

150
00:06:03,840 --> 00:06:05,680
 And this is what the course notes look like.

151
00:06:05,680 --> 00:06:09,000
 So you can see people ask questions.

152
00:06:09,000 --> 00:06:11,540
 I have a question about which rendering engine is used, right?

153
00:06:11,540 --> 00:06:11,960
 And I want to answer.

154
00:06:11,960 --> 00:06:14,240
 And actually, sometimes people from all over the world

155
00:06:14,240 --> 00:06:14,840
 ask questions.

156
00:06:14,840 --> 00:06:16,680
 And I do my best to answer.

157
00:06:16,680 --> 00:06:19,400
 Do you use OpenRave?

158
00:06:19,400 --> 00:06:20,400
 Do we use OpenRave?

159
00:06:20,400 --> 00:06:21,880
 No, no, no, don't use OpenRave.

160
00:06:21,880 --> 00:06:24,000
 You're talking about for this?

161
00:06:24,000 --> 00:06:26,280
 This is actually-- it's called a hypothesis.

162
00:06:26,280 --> 00:06:28,720
 It's a little HTML JavaScript plugin.

163
00:06:28,720 --> 00:06:36,120
 OK, yeah, you'll also find both in the lectures

164
00:06:36,120 --> 00:06:39,920
 and in the notes things that you can interact with.

165
00:06:39,920 --> 00:06:41,860
 The network seems to be a little slow here.

166
00:06:41,860 --> 00:06:44,500
 That's what it says when it's loading too, just so you know.

167
00:06:44,500 --> 00:06:46,820
 But we'll see how-- there we go.

168
00:06:46,820 --> 00:06:50,780
 OK, so you'll see we have this web-based visualizer.

169
00:06:50,780 --> 00:06:53,300
 That's pretty awesome.

170
00:06:53,300 --> 00:06:54,340
 You can interact with it.

171
00:06:54,340 --> 00:06:56,840
 If you're watching the slides and you've pulled up the slides,

172
00:06:56,840 --> 00:06:58,300
 you can interact with it right now.

173
00:06:58,300 --> 00:06:59,700
 This is just our saved render.

174
00:06:59,700 --> 00:07:01,940
 But this is also what you get when you're

175
00:07:01,940 --> 00:07:03,340
 doing work in the class.

176
00:07:03,340 --> 00:07:05,740
 And yeah, it's very interactive.

177
00:07:05,740 --> 00:07:09,340
 So this is our spot from Boston Dynamics simulation,

178
00:07:09,340 --> 00:07:14,460
 just saved a little recording of it getting up and looking

179
00:07:14,460 --> 00:07:17,700
 around a little bit.

180
00:07:17,700 --> 00:07:19,860
 You could sort of understand what's happening here.

181
00:07:19,860 --> 00:07:22,780
 So those green lines, it looks like lasers shooting out

182
00:07:22,780 --> 00:07:24,260
 of the feet or something like that.

183
00:07:24,260 --> 00:07:24,820
 What are those?

184
00:07:24,820 --> 00:07:30,260
 Contact forces, contact forces.

185
00:07:30,260 --> 00:07:33,660
 So I can actually turn those on and off, the contact forces.

186
00:07:33,660 --> 00:07:35,280
 That makes it a little cleaner.

187
00:07:35,280 --> 00:07:37,620
 It's actually kind of cool too.

188
00:07:37,620 --> 00:07:40,200
 If you want to see what the inertial properties of the robot

189
00:07:40,200 --> 00:07:43,340
 are, you can visualize its inertial ellipses.

190
00:07:43,340 --> 00:07:45,740
 If you want to see-- a lot of times the collision geometry

191
00:07:45,740 --> 00:07:47,460
 that the physics engine uses is different

192
00:07:47,460 --> 00:07:49,300
 than the original geometry.

193
00:07:49,300 --> 00:07:52,620
 So you can see what the collision geometries of spot

194
00:07:52,620 --> 00:07:53,120
 looks like.

195
00:07:53,120 --> 00:07:54,580
 Those are the things that are going

196
00:07:54,580 --> 00:07:57,960
 to cause contact forces between the robot and the world.

197
00:07:57,960 --> 00:07:59,700
 But this is an interactive part.

198
00:07:59,700 --> 00:08:01,780
 And it should work on every computer.

199
00:08:01,780 --> 00:08:03,380
 It's just a browser-based thing.

200
00:08:03,380 --> 00:08:04,860
 So no installation.

201
00:08:04,860 --> 00:08:06,020
 Everything should just work.

202
00:08:06,020 --> 00:08:08,180
 Please use the notes, interact with the notes,

203
00:08:08,180 --> 00:08:09,420
 give me feedback on the notes.

204
00:08:09,420 --> 00:08:13,380
 OK.

205
00:08:13,380 --> 00:08:15,420
 We did the logistics.

206
00:08:15,420 --> 00:08:17,740
 So the main goal for today is to tell you

207
00:08:17,740 --> 00:08:20,460
 a little bit about what I mean by manipulation, which

208
00:08:20,460 --> 00:08:23,300
 might not be what some other professors mean about--

209
00:08:23,300 --> 00:08:24,980
 who do robotics mean by manipulation.

210
00:08:24,980 --> 00:08:28,580
 I'll tell you my slant on it and my biases for it,

211
00:08:28,580 --> 00:08:31,020
 give you some examples.

212
00:08:31,020 --> 00:08:33,820
 I come from a bit more of a controls background.

213
00:08:33,820 --> 00:08:36,180
 So I have a goal in this class to bring

214
00:08:36,180 --> 00:08:38,660
 some of the rigorous thinking of control theory

215
00:08:38,660 --> 00:08:43,500
 into the sort of wild west of robotic manipulation.

216
00:08:43,500 --> 00:08:45,660
 So I'm going to tell you a little bit why

217
00:08:45,660 --> 00:08:48,180
 I think that's important, the systems theory perspective,

218
00:08:48,180 --> 00:08:49,380
 because that helps me tell you a little bit

219
00:08:49,380 --> 00:08:50,840
 about the spectrum of things we're

220
00:08:50,840 --> 00:08:52,900
 going to cover in the class.

221
00:08:52,900 --> 00:08:55,200
 And then we'll just talk about some of the pieces,

222
00:08:55,200 --> 00:08:57,860
 the core components that you'll have in most modern manipulation

223
00:08:57,860 --> 00:09:01,100
 systems, and finish up with some of the broader

224
00:09:01,100 --> 00:09:03,380
 goals for the class.

225
00:09:03,380 --> 00:09:04,660
 So what is manipulation?

226
00:09:04,660 --> 00:09:08,380
 So one of the important figures--

227
00:09:08,380 --> 00:09:09,820
 sorry to walk on you there--

228
00:09:09,820 --> 00:09:12,460
 one of the important figures in manipulation research

229
00:09:12,460 --> 00:09:15,140
 was Matt Mason from Carnegie Mellon.

230
00:09:15,140 --> 00:09:19,460
 He's got a beautiful review of robotic manipulation.

231
00:09:19,460 --> 00:09:21,540
 It's a great thing to read if you're interested.

232
00:09:21,540 --> 00:09:23,620
 He was very thoughtful in thinking

233
00:09:23,620 --> 00:09:26,580
 about all the different ways you might define manipulation.

234
00:09:26,580 --> 00:09:30,400
 So his first definition was manipulation just

235
00:09:30,400 --> 00:09:33,020
 means activities performed by the hands.

236
00:09:33,020 --> 00:09:34,060
 That could be tool use.

237
00:09:34,060 --> 00:09:37,700
 That can be specifically picking up objects.

238
00:09:37,700 --> 00:09:40,540
 It can be potentially very rich.

239
00:09:40,540 --> 00:09:43,740
 And he goes through a series of different possible definitions.

240
00:09:43,740 --> 00:09:45,780
 But maybe the most operative one for the class

241
00:09:45,780 --> 00:09:48,940
 here, which is definition five, by the way,

242
00:09:48,940 --> 00:09:51,980
 is that manipulation refers to the agent's control

243
00:09:51,980 --> 00:09:55,480
 of the environment through selective contact.

244
00:09:55,480 --> 00:09:57,820
 So that's kind of a nice way to think about it right now.

245
00:09:57,820 --> 00:09:59,860
 My goal is to affect a change in the environment.

246
00:09:59,860 --> 00:10:03,260
 I've got people, objects, whatever in the world.

247
00:10:03,260 --> 00:10:07,340
 I want to apply forces in order to affect change.

248
00:10:07,340 --> 00:10:09,580
 And that task is manipulation.

249
00:10:09,580 --> 00:10:13,820
 So that's almost what I mean by manipulation.

250
00:10:13,820 --> 00:10:15,980
 So the only thing I don't like about that

251
00:10:15,980 --> 00:10:18,980
 is that kind of gives you this view of there's a robot

252
00:10:18,980 --> 00:10:20,980
 and there's an object.

253
00:10:20,980 --> 00:10:24,340
 In this case, it's holding a little red foam brick.

254
00:10:24,340 --> 00:10:27,300
 And I just want to change the position of the brick.

255
00:10:27,300 --> 00:10:28,340
 And that is good.

256
00:10:28,340 --> 00:10:29,740
 That is correct.

257
00:10:29,740 --> 00:10:31,980
 That is under the umbrella of manipulation.

258
00:10:31,980 --> 00:10:36,060
 But it means way more than that when I think about manipulation.

259
00:10:36,060 --> 00:10:39,140
 So this is manipulation.

260
00:10:39,140 --> 00:10:40,740
 And this is way more than most robots

261
00:10:40,740 --> 00:10:41,820
 can do with manipulation.

262
00:10:41,820 --> 00:10:45,460
 This is what we teach our kids, to tie their shoelaces.

263
00:10:45,460 --> 00:10:49,580
 But if you think about applying selective contact to the world

264
00:10:49,580 --> 00:10:51,780
 in order to accomplish this change in state

265
00:10:51,780 --> 00:10:54,900
 in the environment, that's tough.

266
00:10:54,900 --> 00:10:58,780
 That's super rich dynamics and control playing out right

267
00:10:58,780 --> 00:11:00,100
 there.

268
00:11:00,100 --> 00:11:01,300
 And we want to embrace that.

269
00:11:01,300 --> 00:11:03,860
 We want to sort of dig into some of the details of how

270
00:11:03,860 --> 00:11:05,980
 would you build a manipulation system towards that.

271
00:11:05,980 --> 00:11:09,460
 I can't actually offer a solution to that yet.

272
00:11:09,460 --> 00:11:10,060
 Maybe next year.

273
00:11:10,060 --> 00:11:14,860
 But even more so--

274
00:11:14,860 --> 00:11:17,540
 so that's kind of digging into how rich maybe the dynamics

275
00:11:17,540 --> 00:11:19,180
 and control could be.

276
00:11:19,180 --> 00:11:22,980
 But even more so is that we want to talk about open world

277
00:11:22,980 --> 00:11:25,020
 manipulation and with autonomy.

278
00:11:25,020 --> 00:11:27,060
 So I don't want someone using a joystick

279
00:11:27,060 --> 00:11:28,420
 to accomplish manipulation.

280
00:11:28,420 --> 00:11:30,340
 I want the robot to be making its own decisions

281
00:11:30,340 --> 00:11:32,420
 and understanding the world.

282
00:11:32,420 --> 00:11:35,460
 So Matt's definition refers to an agent's control

283
00:11:35,460 --> 00:11:37,460
 of the environment through selective contact.

284
00:11:37,460 --> 00:11:43,020
 All true, but it's broader when you're in an open world.

285
00:11:43,020 --> 00:11:45,220
 Open world is a term from video games.

286
00:11:45,220 --> 00:11:47,580
 So basically, you don't know what the objects are

287
00:11:47,580 --> 00:11:48,620
 going to be in the world.

288
00:11:48,620 --> 00:11:49,460
 You keep walking.

289
00:11:49,460 --> 00:11:51,820
 You keep getting more objects spawned in front of you.

290
00:11:51,820 --> 00:11:52,980
 Or you just walk into the next room,

291
00:11:52,980 --> 00:11:55,100
 and there's some objects you've never seen before.

292
00:11:55,100 --> 00:11:56,820
 How do you make a manipulation system

293
00:11:56,820 --> 00:11:59,180
 that's capable of reasoning about anything

294
00:11:59,180 --> 00:12:01,820
 that could be in somebody's home or somebody's factory

295
00:12:01,820 --> 00:12:03,500
 or whatever?

296
00:12:03,500 --> 00:12:07,180
 And that requires a lot more than just dynamics and control

297
00:12:07,180 --> 00:12:08,260
 the way we think of it.

298
00:12:08,260 --> 00:12:09,860
 That requires a very rich perception

299
00:12:09,860 --> 00:12:12,420
 and understanding of the environment,

300
00:12:12,420 --> 00:12:14,500
 some sort of common sense understanding

301
00:12:14,500 --> 00:12:15,420
 of what objects are.

302
00:12:15,420 --> 00:12:17,420
 If I've seen an object--

303
00:12:17,420 --> 00:12:19,100
 there's an object I've never seen before,

304
00:12:19,100 --> 00:12:21,420
 but it's similar enough to things I've seen,

305
00:12:21,420 --> 00:12:23,140
 I have a lot of intuition about how

306
00:12:23,140 --> 00:12:25,260
 it's going to act when I start applying forces.

307
00:12:25,260 --> 00:12:29,220
 How do you bring that into the robotic system?

308
00:12:29,220 --> 00:12:33,740
 And then the ability to make long-term task-level plans

309
00:12:33,740 --> 00:12:35,660
 and combine them all the way down to sort

310
00:12:35,660 --> 00:12:38,660
 of fine joint-level motions.

311
00:12:38,660 --> 00:12:42,860
 So if I need to make a bowl of cereal for my kid,

312
00:12:42,860 --> 00:12:45,460
 I need to go to the closet and pull out the cereal box.

313
00:12:45,460 --> 00:12:47,580
 I need to go to the fridge, move the pickles out of the way

314
00:12:47,580 --> 00:12:48,380
 to get to the milk.

315
00:12:48,380 --> 00:12:50,820
 I mean, this is like a complicated sequence

316
00:12:50,820 --> 00:12:53,500
 of actions that are trying to achieve

317
00:12:53,500 --> 00:12:55,300
 this physical goal of moving things around

318
00:12:55,300 --> 00:12:57,140
 in the environment.

319
00:12:57,140 --> 00:13:01,180
 You can get all the way to full intelligence just thinking

320
00:13:01,180 --> 00:13:02,180
 about manipulation.

321
00:13:02,180 --> 00:13:04,560
 And maybe it's the best way to think about intelligence,

322
00:13:04,560 --> 00:13:07,340
 but that's my bias.

323
00:13:07,340 --> 00:13:09,540
 So let me give you a couple examples now,

324
00:13:09,540 --> 00:13:11,940
 I think, just of systems that maybe capture that.

325
00:13:11,940 --> 00:13:14,900
 Often, these are going to come from the Toyota Research

326
00:13:14,900 --> 00:13:15,580
 Institute.

327
00:13:15,580 --> 00:13:17,700
 I have a second job over there.

328
00:13:17,700 --> 00:13:23,100
 And the folks at TRI can build robot systems

329
00:13:23,100 --> 00:13:25,020
 at a level of maturity, putting together

330
00:13:25,020 --> 00:13:26,560
 all these components in ways that it's

331
00:13:26,560 --> 00:13:28,060
 hard to do in academia.

332
00:13:28,060 --> 00:13:32,380
 So when I try to show a full stack robot of things,

333
00:13:32,380 --> 00:13:34,500
 I'll often turn to some of the videos

334
00:13:34,500 --> 00:13:35,620
 that are coming out of TRI.

335
00:13:35,620 --> 00:13:39,140
 So here's an example of a robot that's just tasked

336
00:13:39,140 --> 00:13:40,900
 with loading the dishwasher.

337
00:13:40,900 --> 00:13:43,060
 So it goes something like this.

338
00:13:43,060 --> 00:13:47,060
 So Siwan here dumps random junk into the sink.

339
00:13:47,060 --> 00:13:50,700
 There's also plates and mugs and spoons.

340
00:13:50,700 --> 00:13:53,700
 And the robot's job is to do the dishes, roughly.

341
00:13:53,700 --> 00:13:56,700
 So it's got to open the dishwasher.

342
00:13:56,700 --> 00:13:59,060
 It's got to put the mugs in the top shelf,

343
00:13:59,060 --> 00:14:00,820
 plates in the bottom shelf, the silverware

344
00:14:00,820 --> 00:14:02,260
 in the silverware rack.

345
00:14:02,260 --> 00:14:03,780
 Anything that's not a dish, it has

346
00:14:03,780 --> 00:14:06,820
 to understand it was not a dish and throw it in the refuse pile

347
00:14:06,820 --> 00:14:08,900
 over on the side.

348
00:14:08,900 --> 00:14:10,740
 If you think about all of the pieces that

349
00:14:10,740 --> 00:14:14,100
 have to go into making something like that work,

350
00:14:14,100 --> 00:14:16,140
 that's, I think, closer to what I

351
00:14:16,140 --> 00:14:18,620
 mean by the problem of manipulation.

352
00:14:18,620 --> 00:14:20,820
 There's a lot going on there.

353
00:14:20,820 --> 00:14:22,380
 Even at the low level--

354
00:14:22,380 --> 00:14:25,340
 I'll show you some of the slightly nuanced things

355
00:14:25,340 --> 00:14:26,340
 that are happening there.

356
00:14:26,340 --> 00:14:30,580
 But this system used to run all day and all day, all night,

357
00:14:30,580 --> 00:14:33,620
 and just do its best to load the dishes until someone

358
00:14:33,620 --> 00:14:36,740
 dumped more dishes in, and then just keep going.

359
00:14:36,740 --> 00:14:40,060
 Got to a very high level of maturity.

360
00:14:40,060 --> 00:14:41,820
 So just zoom in on a few of the things

361
00:14:41,820 --> 00:14:44,500
 that are happening that are actually super interesting.

362
00:14:44,500 --> 00:14:48,340
 So first of all, you had to open the dishwasher door.

363
00:14:48,340 --> 00:14:49,420
 That's non-trivial.

364
00:14:49,420 --> 00:14:53,460
 If you get that wrong, you can jam your robot.

365
00:14:53,460 --> 00:14:56,540
 Picking up silverware sometimes requires nudging it out

366
00:14:56,540 --> 00:14:58,740
 of the corner because your big robot hand doesn't fit

367
00:14:58,740 --> 00:15:00,580
 in the corner of the sink.

368
00:15:00,580 --> 00:15:02,220
 Picking up plates is one of my favorite.

369
00:15:02,220 --> 00:15:04,380
 You have to get your fingers in just right

370
00:15:04,380 --> 00:15:07,380
 and understand what's a plate and not a plate in subtle ways.

371
00:15:07,380 --> 00:15:10,700
 Here's the zoom in on the plates.

372
00:15:10,700 --> 00:15:12,980
 This is a simulation, of course, on the left

373
00:15:12,980 --> 00:15:15,220
 and the real robot on the right.

374
00:15:15,220 --> 00:15:17,540
 It's been a lot of work on trying to make simulations

375
00:15:17,540 --> 00:15:18,820
 match reality.

376
00:15:18,820 --> 00:15:22,020
 That's partly what makes teaching a class like this

377
00:15:22,020 --> 00:15:23,540
 really possible, the scale.

378
00:15:23,540 --> 00:15:26,700
 And lots of you interact with lots

379
00:15:26,700 --> 00:15:29,620
 of pretty complicated manipulation systems.

380
00:15:29,620 --> 00:15:30,540
 Yeah, please.

381
00:15:30,540 --> 00:15:31,020
 [INAUDIBLE]

382
00:15:31,020 --> 00:15:42,100
 Yeah, that's great.

383
00:15:42,100 --> 00:15:45,900
 So it depends on which version of the system you've seen.

384
00:15:45,900 --> 00:15:47,900
 So the first versions we did were actually

385
00:15:47,900 --> 00:15:50,020
 we would train perception systems that

386
00:15:50,020 --> 00:15:52,580
 worked for certain plates, certain mugs, certain spoons.

387
00:15:52,580 --> 00:15:56,060
 And then we started randomizing those and covering a big swath.

388
00:15:56,060 --> 00:15:59,060
 But you could probably go to the Disney store in the mall

389
00:15:59,060 --> 00:16:01,260
 and come home with a mug that I couldn't pick up

390
00:16:01,260 --> 00:16:02,660
 with that perception system.

391
00:16:02,660 --> 00:16:04,260
 So there's limits to how much diversity

392
00:16:04,260 --> 00:16:05,780
 we could handle in that.

393
00:16:05,780 --> 00:16:08,220
 And the deep learning revolution has brought us

394
00:16:08,220 --> 00:16:09,860
 new capabilities in that space.

395
00:16:09,860 --> 00:16:12,060
 But still, generalization is an open challenge.

396
00:16:12,060 --> 00:16:13,780
 So that's always a great question to ask,

397
00:16:13,780 --> 00:16:15,940
 sort of how general is this?

398
00:16:15,940 --> 00:16:19,780
 Does this work for exactly one type of plate or every plate?

399
00:16:19,780 --> 00:16:22,380
 And the answer is always something in between.

400
00:16:22,380 --> 00:16:29,780
 This is a simulation of a more dexterous hand

401
00:16:29,780 --> 00:16:31,460
 picking up those plates.

402
00:16:31,460 --> 00:16:33,060
 And by the way, simulation like this

403
00:16:33,060 --> 00:16:35,420
 didn't really work a few years ago.

404
00:16:35,420 --> 00:16:38,300
 It's only very recently that computer game engine quality

405
00:16:38,300 --> 00:16:41,340
 rendering has gotten good enough to train state

406
00:16:41,340 --> 00:16:42,740
 of the art perception systems.

407
00:16:42,740 --> 00:16:45,340
 And some of the physics engines have gotten good enough

408
00:16:45,340 --> 00:16:48,340
 that you can actually do research in simulation

409
00:16:48,340 --> 00:16:50,340
 that you expect to have work on the real robot.

410
00:16:50,340 --> 00:16:57,420
 And then the Boston Dynamics guys, they kick the robot.

411
00:16:57,420 --> 00:16:58,940
 It's hard to kick a dishwasher.

412
00:16:58,940 --> 00:17:02,020
 But that's kind of what we were going for there.

413
00:17:02,020 --> 00:17:05,660
 So even if someone closes the dishwasher rack

414
00:17:05,660 --> 00:17:07,140
 and the robot was working on a mug,

415
00:17:07,140 --> 00:17:08,940
 it's like, all right, I'll put the mug down

416
00:17:08,940 --> 00:17:10,620
 and I'll open the dishwasher rack again.

417
00:17:10,620 --> 00:17:13,700
 You can almost sense the robot being annoyed.

418
00:17:13,700 --> 00:17:15,180
 But it'll go pick it up.

419
00:17:15,180 --> 00:17:17,860
 But it'll get the job done most of the time.

420
00:17:17,860 --> 00:17:25,780
 So really, this quest of understanding manipulation

421
00:17:25,780 --> 00:17:29,060
 goes from low level control all the way up

422
00:17:29,060 --> 00:17:32,060
 to sort of scene level understanding, task level

423
00:17:32,060 --> 00:17:32,940
 planning.

424
00:17:32,940 --> 00:17:35,340
 There's really a broad level of intelligence, if you will.

425
00:17:35,340 --> 00:17:39,420
 You can go from the hind brain to the cortex or whatever.

426
00:17:39,420 --> 00:17:44,220
 And we'll explore the swath, the different rungs of the ladder.

427
00:17:44,220 --> 00:17:46,460
 Maybe that analogy is going a little too far

428
00:17:46,460 --> 00:17:47,580
 throughout the semester.

429
00:17:47,580 --> 00:17:50,260
 And for your project, you'll pick some level

430
00:17:50,260 --> 00:17:52,860
 and try to dive in a bit deeper and focus in on those.

431
00:17:52,860 --> 00:17:57,940
 The world gets even more open.

432
00:17:57,940 --> 00:18:01,300
 So one of my reflections on teaching the class last year

433
00:18:01,300 --> 00:18:03,820
 was that people did awesome projects.

434
00:18:03,820 --> 00:18:06,060
 But they were all a robot bolted to a table

435
00:18:06,060 --> 00:18:08,380
 and a hand doing certain objects.

436
00:18:08,380 --> 00:18:11,780
 Because that's all I had given people to work with.

437
00:18:11,780 --> 00:18:16,100
 So that limits your thinking, I think, a little bit.

438
00:18:16,100 --> 00:18:18,620
 Because the world gets even more open

439
00:18:18,620 --> 00:18:22,620
 if you can walk into the next room and see brand new objects.

440
00:18:22,620 --> 00:18:24,980
 So one of my goals for the term is

441
00:18:24,980 --> 00:18:29,100
 to bring more mobile manipulation into the discussion

442
00:18:29,100 --> 00:18:30,420
 and into your projects.

443
00:18:30,420 --> 00:18:33,500
 So this is an example, again, of a full system

444
00:18:33,500 --> 00:18:36,100
 from TRI, the Toyota Research Institute.

445
00:18:36,100 --> 00:18:38,860
 And it's actually-- they have a partnership

446
00:18:38,860 --> 00:18:40,900
 with a local grocery store.

447
00:18:40,900 --> 00:18:44,500
 And at night, they just take hundreds of items,

448
00:18:44,500 --> 00:18:47,100
 make a random shopping list, and go get the groceries.

449
00:18:47,100 --> 00:18:50,020
 And they drop groceries every once in a while.

450
00:18:50,020 --> 00:18:51,220
 They log their failures.

451
00:18:51,220 --> 00:18:53,180
 And they just get better and better and better

452
00:18:53,180 --> 00:18:55,060
 as they work on this more and more and more,

453
00:18:55,060 --> 00:19:01,020
 getting to solving real systems level tasks with a robot.

454
00:19:01,020 --> 00:19:03,700
 But going into an arbitrary grocery store

455
00:19:03,700 --> 00:19:07,580
 and dealing with the diversity of ad inventory,

456
00:19:07,580 --> 00:19:10,180
 that's bigger than the kitchen sink.

457
00:19:10,180 --> 00:19:13,300
 And you could have a new stocked item

458
00:19:13,300 --> 00:19:14,980
 that you've never seen before.

459
00:19:14,980 --> 00:19:16,620
 And if you go out of the grocery store,

460
00:19:16,620 --> 00:19:18,340
 it might be even more complicated still.

461
00:19:18,340 --> 00:19:29,020
 So again, Spot is a robot from Boston Dynamics.

462
00:19:29,020 --> 00:19:31,660
 It's got an arm on top of it often.

463
00:19:31,660 --> 00:19:33,940
 And like I said, one of our goals

464
00:19:33,940 --> 00:19:35,980
 this year is to do more mobile manipulation.

465
00:19:35,980 --> 00:19:42,540
 And so just for grins, I brought Spot.

466
00:19:42,540 --> 00:19:45,420
 It's hiding back here behind the door.

467
00:19:45,420 --> 00:19:47,860
 We'll do a little mobile manipulation challenge

468
00:19:47,860 --> 00:19:50,300
 real quick before the batteries run out.

469
00:19:50,300 --> 00:19:50,800
 Yeah.

470
00:19:50,800 --> 00:20:04,300
 Just got to wait for the motors to power on real quick.

471
00:20:04,300 --> 00:20:15,980
 But this is Spot.

472
00:20:15,980 --> 00:20:23,700
 I'll do my best to do live demos in the class.

473
00:20:23,700 --> 00:20:26,620
 It's a lot of work, and I'm far away from my buildings.

474
00:20:26,620 --> 00:20:29,220
 But this one can walk over, so that was pretty good.

475
00:20:29,220 --> 00:20:35,340
 All right.

476
00:20:35,340 --> 00:20:37,380
 I brought one of Spot's toys here

477
00:20:37,380 --> 00:20:40,980
 just to show a very basic demo.

478
00:20:40,980 --> 00:20:45,220
 But robot dogs love robot plush toys.

479
00:20:45,220 --> 00:20:48,100
 So why not?

480
00:20:48,100 --> 00:20:51,220
 We'll just walk up and ask him to pick up.

481
00:20:51,220 --> 00:20:55,780
 Now, depending on how I do this, it may or may not

482
00:20:55,780 --> 00:20:56,700
 show a failure mode.

483
00:20:56,700 --> 00:20:57,300
 But let's see.

484
00:20:57,300 --> 00:21:08,300
 All right.

485
00:21:08,300 --> 00:21:11,380
 Success, huh?

486
00:21:11,380 --> 00:21:12,980
 Go back and carry it back.

487
00:21:12,980 --> 00:21:22,580
 [VIDEO PLAYBACK]

488
00:21:22,580 --> 00:21:23,260
 All right.

489
00:21:23,260 --> 00:21:24,100
 Good job, Spot.

490
00:21:24,100 --> 00:21:24,600
 Yeah.

491
00:21:24,600 --> 00:21:33,540
 [APPLAUSE]

492
00:21:33,540 --> 00:21:35,900
 Now, because I want Spot to walk back home,

493
00:21:35,900 --> 00:21:37,220
 I'm going to power it down now.

494
00:21:37,220 --> 00:21:38,380
 OK?

495
00:21:38,380 --> 00:21:40,940
 Otherwise, the batteries are going to die on me.

496
00:21:40,940 --> 00:21:42,500
 You can carry it if you want to.

497
00:21:42,500 --> 00:21:46,260
 But I'm recruiting you if--

498
00:21:46,260 --> 00:21:47,620
 I don't know exactly the weight.

499
00:21:47,620 --> 00:21:48,980
 70 pounds, something like that?

500
00:21:48,980 --> 00:21:50,180
 It's a lot of battery weight.

501
00:21:50,180 --> 00:22:01,820
 It's also loud, so I have to fully power it down.

502
00:22:01,820 --> 00:22:02,740
 Cool.

503
00:22:02,740 --> 00:22:04,400
 Maybe I should have put it somewhere less

504
00:22:04,400 --> 00:22:05,240
 in front of my board.

505
00:22:05,240 --> 00:22:09,980
 [LAUGHTER]

506
00:22:09,980 --> 00:22:10,780
 Over here, Spot.

507
00:22:10,780 --> 00:22:11,280
 All right.

508
00:22:11,280 --> 00:22:16,800
 [LAUGHTER]

509
00:22:16,800 --> 00:22:17,280
 OK.

510
00:22:17,280 --> 00:22:20,600
 So some of you have taken Underactuated with me.

511
00:22:20,600 --> 00:22:21,840
 It's the other class I teach.

512
00:22:21,840 --> 00:22:22,760
 It's a graduate class.

513
00:22:22,760 --> 00:22:25,080
 If you haven't, maybe you'll take it next.

514
00:22:25,080 --> 00:22:27,280
 Or some of you might just know that I've done

515
00:22:27,280 --> 00:22:29,640
 sort of this controls background.

516
00:22:29,640 --> 00:22:33,040
 So let me tell you sort of how I came into manipulation

517
00:22:33,040 --> 00:22:35,080
 and a little bit what's the dynamics and controls

518
00:22:35,080 --> 00:22:35,520
 perspective.

519
00:22:35,520 --> 00:22:36,940
 I already showed you the shoelaces.

520
00:22:36,940 --> 00:22:40,320
 That's like awesome dynamics and control.

521
00:22:40,320 --> 00:22:41,980
 But there's some really important things

522
00:22:41,980 --> 00:22:46,240
 that happen which make manipulation a challenge,

523
00:22:46,240 --> 00:22:50,000
 like the thing I want to focus my work on controls on.

524
00:22:50,000 --> 00:22:54,000
 So I've done work on humanoid robots, on walking robots.

525
00:22:54,000 --> 00:22:56,880
 This is the early version of the Atlas robot

526
00:22:56,880 --> 00:22:58,680
 from Boston Dynamics.

527
00:22:58,680 --> 00:23:01,520
 You've seen the new version doing parkour

528
00:23:01,520 --> 00:23:02,960
 in awesome fashion.

529
00:23:02,960 --> 00:23:06,520
 And that's a real thing that really works beautifully well.

530
00:23:06,520 --> 00:23:09,040
 This was a DARPA robotics challenge a handful of years

531
00:23:09,040 --> 00:23:11,880
 ago where we had to program the whole stack to make it

532
00:23:11,880 --> 00:23:14,480
 cross stairs, open doors, turn valves, and things like this.

533
00:23:14,480 --> 00:23:16,280
 That was really the first time that we

534
00:23:16,280 --> 00:23:18,440
 had to do some amount-- that I really started thinking

535
00:23:18,440 --> 00:23:20,280
 about some amount of manipulation.

536
00:23:20,280 --> 00:23:22,120
 And it was a relatively closed world.

537
00:23:22,120 --> 00:23:23,600
 We had to turn various valves.

538
00:23:23,600 --> 00:23:26,240
 But they were all in a small family of valves.

539
00:23:26,240 --> 00:23:28,640
 And we would make a valve detector.

540
00:23:28,640 --> 00:23:30,760
 This was actually right as the deep learning thing

541
00:23:30,760 --> 00:23:31,520
 was happening.

542
00:23:31,520 --> 00:23:33,720
 So most people were not using--

543
00:23:33,720 --> 00:23:36,800
 I think nobody was really using deep learning that year.

544
00:23:36,800 --> 00:23:38,680
 Next year, everybody was using deep learning.

545
00:23:38,680 --> 00:23:42,200
 But OK, so-- and the way you would program a control system

546
00:23:42,200 --> 00:23:45,080
 like that is awesome.

547
00:23:45,080 --> 00:23:47,880
 I mean, you can make these balancing controllers that

548
00:23:47,880 --> 00:23:50,640
 are super robust, even if people are jumping on the vehicle

549
00:23:50,640 --> 00:23:52,760
 while you're trying to get out with one foot.

550
00:23:52,760 --> 00:23:56,440
 And that stuff works really well.

551
00:23:56,440 --> 00:23:58,040
 And it's built on this premise of you

552
00:23:58,040 --> 00:23:59,520
 kind of go through the world.

553
00:23:59,520 --> 00:24:03,640
 And you understand the world in a sort of geometry sense

554
00:24:03,640 --> 00:24:04,720
 for walking.

555
00:24:04,720 --> 00:24:08,160
 You have to sort of understand where you're allowed to step,

556
00:24:08,160 --> 00:24:11,040
 what you shouldn't run into.

557
00:24:11,040 --> 00:24:15,160
 But you can do a lot in locomotion

558
00:24:15,160 --> 00:24:18,600
 with a relatively limited understanding of the world.

559
00:24:18,600 --> 00:24:19,880
 You don't have to understand--

560
00:24:19,880 --> 00:24:22,920
 I mean, if you're walking on some obstacle course,

561
00:24:22,920 --> 00:24:23,560
 then it's more.

562
00:24:23,560 --> 00:24:25,680
 But if you've just got to understand, yeah,

563
00:24:25,680 --> 00:24:28,180
 I'm allowed to step there or I'm not allowed to step there,

564
00:24:28,180 --> 00:24:30,360
 that's a relatively limited amount of understanding

565
00:24:30,360 --> 00:24:31,960
 you have to do for the world.

566
00:24:31,960 --> 00:24:34,200
 When you look in the kitchen sink,

567
00:24:34,200 --> 00:24:37,440
 the natural extension of that is to try to say,

568
00:24:37,440 --> 00:24:39,120
 I'm going to write a mug detector.

569
00:24:39,120 --> 00:24:41,400
 I'm going to figure out where the mugs are,

570
00:24:41,400 --> 00:24:42,760
 what's the pose of the mugs.

571
00:24:42,760 --> 00:24:48,680
 Those highlights are key points of an output

572
00:24:48,680 --> 00:24:51,880
 from our pose detector of the mug.

573
00:24:51,880 --> 00:24:54,120
 And then you can start building a control system that's

574
00:24:54,120 --> 00:24:57,640
 trying to work a lot like Atlas when it's balancing on the car.

575
00:24:57,640 --> 00:24:59,280
 But now you're trying to regulate

576
00:24:59,280 --> 00:25:00,880
 the positions of the mugs.

577
00:25:00,880 --> 00:25:05,080
 And it's hard, but you can grow in that direction.

578
00:25:05,080 --> 00:25:06,680
 But then you start saying, OK, what

579
00:25:06,680 --> 00:25:09,240
 are all the mugs in the world that I haven't seen before?

580
00:25:09,240 --> 00:25:12,840
 And how do you write a control system that

581
00:25:12,840 --> 00:25:16,520
 accomplishes work on all the mugs in the world?

582
00:25:16,520 --> 00:25:19,560
 And that starts to challenge my views of control

583
00:25:19,560 --> 00:25:20,680
 from a few years ago.

584
00:25:20,680 --> 00:25:24,800
 So the standard thing of modeling the world,

585
00:25:24,800 --> 00:25:27,280
 having a perfect physics model, building a control system

586
00:25:27,280 --> 00:25:30,400
 to stabilize that model, doesn't really

587
00:25:30,400 --> 00:25:34,080
 map directly to any mug.

588
00:25:34,080 --> 00:25:36,400
 So we had to start changing the way we thought

589
00:25:36,400 --> 00:25:39,320
 about state, about representation.

590
00:25:39,320 --> 00:25:42,040
 I'll make those all more precise as we go.

591
00:25:42,040 --> 00:25:44,560
 Because the control problem in manipulation,

592
00:25:44,560 --> 00:25:47,360
 the control problem for Atlas doing parkour

593
00:25:47,360 --> 00:25:49,600
 is really about Atlas.

594
00:25:49,600 --> 00:25:53,400
 The robot needs to understand its dynamics very well.

595
00:25:53,400 --> 00:25:55,680
 And you can sort of master your dynamics

596
00:25:55,680 --> 00:25:57,520
 and do incredible things.

597
00:25:57,520 --> 00:25:59,820
 But the control problem for manipulation

598
00:25:59,820 --> 00:26:01,560
 is not just controlling the robot.

599
00:26:01,560 --> 00:26:03,900
 It's also controlling the objects in the world.

600
00:26:03,900 --> 00:26:05,940
 And that means you have to understand potentially

601
00:26:05,940 --> 00:26:07,120
 everything.

602
00:26:07,120 --> 00:26:10,640
 And it's weird that tying shoelaces or even picking up

603
00:26:10,640 --> 00:26:14,440
 objects in some ways is harder than doing backflips.

604
00:26:14,440 --> 00:26:17,680
 But they just exercise different parts of your brain

605
00:26:17,680 --> 00:26:20,120
 and of the robot's brain, I guess.

606
00:26:20,120 --> 00:26:23,680
 So the state of the robot is part of the problem.

607
00:26:23,680 --> 00:26:26,400
 But the stabilizing the state of the environment,

608
00:26:26,400 --> 00:26:28,320
 however you choose to represent that,

609
00:26:28,320 --> 00:26:30,240
 is another part of the problem.

610
00:26:30,240 --> 00:26:33,420
 And when you get to interesting manipulation tasks,

611
00:26:33,420 --> 00:26:37,500
 you think, how am I going to represent that?

612
00:26:37,500 --> 00:26:40,040
 If I read a piece of onion detector,

613
00:26:40,040 --> 00:26:43,200
 and then the number of onions is changing every time,

614
00:26:43,200 --> 00:26:47,040
 and this sort of just takes my classical understanding--

615
00:26:47,040 --> 00:26:49,120
 not even that classical-- my modern understanding

616
00:26:49,120 --> 00:26:52,260
 of control and challenges it in fundamental ways.

617
00:26:52,260 --> 00:26:55,860
 I don't know how to build world models of that that

618
00:26:55,860 --> 00:26:58,640
 are trying to estimate the shape and the pose of all the pieces

619
00:26:58,640 --> 00:27:00,200
 that would scale to a simple problem,

620
00:27:00,200 --> 00:27:03,860
 even though that should be not that hard of a problem.

621
00:27:03,860 --> 00:27:07,060
 So that's how I came to be super excited about manipulation,

622
00:27:07,060 --> 00:27:09,180
 is that I think it breaks--

623
00:27:09,180 --> 00:27:11,140
 I mean, we can do amazing things with control.

624
00:27:11,140 --> 00:27:11,940
 We can do backflips.

625
00:27:11,940 --> 00:27:12,900
 We can do these things.

626
00:27:12,900 --> 00:27:14,260
 But we can't do that.

627
00:27:14,260 --> 00:27:15,140
 Why can't we do that?

628
00:27:15,140 --> 00:27:16,260
 Humans do make it look easy.

629
00:27:16,260 --> 00:27:18,460
 It should be easy.

630
00:27:18,460 --> 00:27:21,860
 So that's my primary interest.

631
00:27:21,860 --> 00:27:25,220
 Now, the world is making super fast progress

632
00:27:25,220 --> 00:27:27,500
 in that dimension.

633
00:27:27,500 --> 00:27:29,660
 And one of the ways that people are doing it

634
00:27:29,660 --> 00:27:31,440
 is by using deep learning.

635
00:27:31,440 --> 00:27:35,640
 But most essentially, they will have potentially big perception

636
00:27:35,640 --> 00:27:38,400
 networks, so you can go directly from an image

637
00:27:38,400 --> 00:27:39,880
 to make your decisions.

638
00:27:39,880 --> 00:27:42,560
 But I think the most essential thing is that they

639
00:27:42,560 --> 00:27:46,240
 have intermediate layers that are

640
00:27:46,240 --> 00:27:50,080
 learning implicit state representations of the world.

641
00:27:50,080 --> 00:27:53,400
 So instead of having a mug detector

642
00:27:53,400 --> 00:27:57,000
 or having an onion piece detector,

643
00:27:57,000 --> 00:27:59,240
 the intermediate layers of the neural network

644
00:27:59,240 --> 00:28:02,380
 are able to learn some more fundamental representation that

645
00:28:02,380 --> 00:28:04,300
 does scale and maybe doesn't have

646
00:28:04,300 --> 00:28:05,680
 to track every piece of the onion

647
00:28:05,680 --> 00:28:07,660
 if it's not task relevant.

648
00:28:07,660 --> 00:28:11,200
 And these notions of new learned state representations,

649
00:28:11,200 --> 00:28:13,720
 I think, are fundamentally important

650
00:28:13,720 --> 00:28:16,880
 in how we have to think about the control problem.

651
00:28:16,880 --> 00:28:19,580
 Now, we'll talk a lot about visual motor policies.

652
00:28:19,580 --> 00:28:21,100
 That's the buzzword for it.

653
00:28:21,100 --> 00:28:23,020
 And we'll talk about different approaches to it

654
00:28:23,020 --> 00:28:25,060
 when we get there.

655
00:28:25,060 --> 00:28:26,680
 But that really does make a difference.

656
00:28:26,680 --> 00:28:31,300
 And so we started to see control systems that could really

657
00:28:31,300 --> 00:28:36,780
 go directly from RGB images, solve dynamics and control

658
00:28:36,780 --> 00:28:38,840
 problems that were non-trivial--

659
00:28:38,840 --> 00:28:41,980
 flexible hats hanging on a rack.

660
00:28:41,980 --> 00:28:44,560
 These are visually cluttered scenes.

661
00:28:44,560 --> 00:28:46,340
 Any shoe.

662
00:28:46,340 --> 00:28:48,420
 And solving them with some of the robustness

663
00:28:48,420 --> 00:28:53,020
 we associate with humanoid balancing, for instance,

664
00:28:53,020 --> 00:28:56,420
 but doing it in this more open world setting.

665
00:28:56,420 --> 00:28:58,860
 So that's where the research world is just

666
00:28:58,860 --> 00:28:59,940
 exploding right now.

667
00:28:59,940 --> 00:29:01,480
 And of course, large language models

668
00:29:01,480 --> 00:29:04,780
 are coming in to add that whole component too.

669
00:29:04,780 --> 00:29:10,140
 So I think this is going to change the way we think

670
00:29:10,140 --> 00:29:12,380
 about control for everything.

671
00:29:12,380 --> 00:29:15,500
 And that's why I'm passionate about pursuing it.

672
00:29:15,500 --> 00:29:18,140
 Just another zoom in of that example,

673
00:29:18,140 --> 00:29:22,100
 just to do a non-trivial but sort of starts

674
00:29:22,100 --> 00:29:25,500
 in the land of we can understand what a plate is.

675
00:29:25,500 --> 00:29:27,940
 We can understand the dynamics of a plate.

676
00:29:27,940 --> 00:29:29,740
 We can write a control system that

677
00:29:29,740 --> 00:29:31,580
 sort of thinks about the plate.

678
00:29:31,580 --> 00:29:35,400
 But when you start saying that the primary sensor is a camera

679
00:29:35,400 --> 00:29:37,280
 and you start saying we need to deal with all

680
00:29:37,280 --> 00:29:39,300
 the visual diversity and all the different plates

681
00:29:39,300 --> 00:29:41,680
 and all these things, then it gets really rich.

682
00:29:41,680 --> 00:29:44,540
 And that's where deep learning has opened things up for us.

683
00:29:44,540 --> 00:29:49,140
 It doesn't mean, though, that you

684
00:29:49,140 --> 00:29:52,940
 have to throw away fundamental basic understanding.

685
00:29:52,940 --> 00:29:56,020
 And I will still advocate for making darn sure

686
00:29:56,020 --> 00:29:58,460
 when you build your big complicated systems

687
00:29:58,460 --> 00:30:02,340
 that you understand how it works in a simple model that

688
00:30:02,340 --> 00:30:05,220
 is based on just physics and removes that complexity.

689
00:30:05,220 --> 00:30:07,900
 If you don't understand how the big complicated thing boils

690
00:30:07,900 --> 00:30:09,640
 down and works in the simple cases,

691
00:30:09,640 --> 00:30:12,900
 then I don't think you fully understand what's happening.

692
00:30:12,900 --> 00:30:15,980
 So that's just a simplified version of that same task.

693
00:30:15,980 --> 00:30:20,860
 Having said that, we can now do things

694
00:30:20,860 --> 00:30:24,060
 that would have defeated state representations

695
00:30:24,060 --> 00:30:24,940
 that we had before.

696
00:30:24,940 --> 00:30:30,060
 So how do you design a dough detector?

697
00:30:30,060 --> 00:30:32,540
 Or how do you roll the pizza dough?

698
00:30:32,540 --> 00:30:34,640
 But these tasks are relatively easy for some

699
00:30:34,640 --> 00:30:36,460
 of the deep learning approaches.

700
00:30:36,460 --> 00:30:39,340
 And we're trying to figure out how to put all this together

701
00:30:39,340 --> 00:30:42,820
 and to make really complicated systems.

702
00:30:42,820 --> 00:30:44,540
 It's actually surprisingly robust.

703
00:30:44,540 --> 00:30:47,420
 You can mess with the dough.

704
00:30:47,420 --> 00:30:49,140
 It'll just get it done.

705
00:30:49,140 --> 00:30:51,220
 Just keep rolling until it's happy.

706
00:30:51,220 --> 00:30:52,700
 You can perturb the dough.

707
00:30:52,700 --> 00:30:53,860
 It'll keep going.

708
00:30:53,860 --> 00:30:56,620
 You can spread sauce.

709
00:30:56,620 --> 00:30:57,500
 That's another one.

710
00:30:57,500 --> 00:31:00,100
 We had a list of things that I didn't know how to do,

711
00:31:00,100 --> 00:31:01,820
 of what's the state of the sauce.

712
00:31:01,820 --> 00:31:03,580
 I don't know what the state of the sauce is.

713
00:31:03,580 --> 00:31:05,180
 But we can now--

714
00:31:05,180 --> 00:31:08,340
 even though the task looks simple, it should be simple,

715
00:31:08,340 --> 00:31:09,700
 from a controls perspective, this

716
00:31:09,700 --> 00:31:11,380
 would have been extremely hard.

717
00:31:11,380 --> 00:31:13,800
 And the fact that we're starting to be able to do this

718
00:31:13,800 --> 00:31:15,220
 is just awesome.

719
00:31:18,820 --> 00:31:20,460
 That's kind of a high level motivation.

720
00:31:20,460 --> 00:31:21,500
 Any questions about that?

721
00:31:21,500 --> 00:31:26,540
 I want the class to be interactive.

722
00:31:26,540 --> 00:31:27,980
 I know it's big, which is great.

723
00:31:27,980 --> 00:31:30,180
 But feel free to ask questions.

724
00:31:30,180 --> 00:31:32,180
 Yeah?

725
00:31:32,180 --> 00:31:37,660
 [INAUDIBLE]

726
00:31:37,660 --> 00:31:38,660
 Yeah.

727
00:31:38,660 --> 00:31:52,020
 [INAUDIBLE]

728
00:31:52,020 --> 00:31:52,860
 Yeah, that's great.

729
00:31:52,860 --> 00:31:54,300
 So it's a big question.

730
00:31:54,300 --> 00:31:57,780
 So how exactly are the deep networks figuring out

731
00:31:57,780 --> 00:31:59,180
 the state representation?

732
00:31:59,180 --> 00:32:01,660
 And oftentimes, maybe a version of that question

733
00:32:01,660 --> 00:32:04,260
 is, is there even an explicit notion of state?

734
00:32:04,260 --> 00:32:06,640
 Is there a point in the network where you point and say,

735
00:32:06,640 --> 00:32:07,900
 that's the state?

736
00:32:07,900 --> 00:32:10,260
 And I'd say, in some approaches, yes.

737
00:32:10,260 --> 00:32:13,340
 There's an explicit, pre-trained something

738
00:32:13,340 --> 00:32:16,140
 that tries to come out with an explicit latent vector

739
00:32:16,140 --> 00:32:18,300
 that I would say, that's the state.

740
00:32:18,300 --> 00:32:20,500
 In other cases, you'd train the system end

741
00:32:20,500 --> 00:32:22,740
 to end, where the output is really motor actions

742
00:32:22,740 --> 00:32:25,060
 or long-term actions.

743
00:32:25,060 --> 00:32:27,220
 And then the notion of state is only

744
00:32:27,220 --> 00:32:29,220
 implicit somewhere in the layers of the network.

745
00:32:29,220 --> 00:32:32,460
 And you don't typically even go and find it.

746
00:32:32,460 --> 00:32:35,300
 So that's a choice that you can make.

747
00:32:35,660 --> 00:32:45,580
 [INAUDIBLE]

748
00:32:45,580 --> 00:32:46,260
 I don't do it.

749
00:32:46,260 --> 00:32:47,420
 The neural network does it.

750
00:32:47,420 --> 00:32:48,300
 So the question was--

751
00:32:48,300 --> 00:32:50,780
 [INAUDIBLE]

752
00:32:50,780 --> 00:32:53,740
 Yeah, so the question is, how would you do a liquid?

753
00:32:53,740 --> 00:32:55,020
 What's the state of a liquid?

754
00:32:55,020 --> 00:32:58,380
 I mean, the fluid dynamicists have an answer.

755
00:32:58,380 --> 00:33:00,500
 You could do Eulerian, or you could do Lagrangian.

756
00:33:00,500 --> 00:33:01,820
 You can track particles.

757
00:33:01,820 --> 00:33:02,780
 You can track whatever.

758
00:33:02,780 --> 00:33:04,660
 And that's not practical if you just

759
00:33:04,660 --> 00:33:07,340
 want to pour spread sauce.

760
00:33:07,340 --> 00:33:09,700
 So in that particular example, there

761
00:33:09,700 --> 00:33:13,180
 were a lot of demonstrations of humans teleoperating

762
00:33:13,180 --> 00:33:15,500
 the robot to spread the sauce.

763
00:33:15,500 --> 00:33:18,060
 And we said, when you see this picture,

764
00:33:18,060 --> 00:33:20,060
 you want to take similar actions.

765
00:33:20,060 --> 00:33:22,140
 And somewhere in the middle, it's

766
00:33:22,140 --> 00:33:23,740
 deciding a representation for sauce.

767
00:33:23,740 --> 00:33:28,580
 And I think if we want to generalize that,

768
00:33:28,580 --> 00:33:29,820
 maybe that can go the distance.

769
00:33:29,820 --> 00:33:32,280
 Or maybe we have to go in and understand that representation

770
00:33:32,280 --> 00:33:34,840
 and apply it in a more general way.

771
00:33:34,840 --> 00:33:35,340
 Yes?

772
00:33:35,340 --> 00:33:35,840
 [INAUDIBLE]

773
00:33:35,840 --> 00:33:49,880
 That's a super good question.

774
00:33:49,880 --> 00:33:51,220
 So the question is, would you--

775
00:33:51,220 --> 00:33:54,320
 I'll just repeat it for the folks watching.

776
00:33:54,320 --> 00:33:56,720
 Yeah, so the question is, if we know a lot of things

777
00:33:56,720 --> 00:33:58,680
 about what liquids can do from physics,

778
00:33:58,680 --> 00:34:00,920
 do we incorporate those in the neural representations?

779
00:34:00,920 --> 00:34:03,080
 Or is the neural network just ignoring that?

780
00:34:03,080 --> 00:34:05,120
 And I think the simplest answer is

781
00:34:05,120 --> 00:34:06,560
 we're almost always ignoring it.

782
00:34:06,560 --> 00:34:08,920
 But there's a very active field of research

783
00:34:08,920 --> 00:34:10,880
 of trying to do physics-inspired neural networks

784
00:34:10,880 --> 00:34:17,040
 and trying to bring in biases from, hopefully,

785
00:34:17,040 --> 00:34:19,240
 some of our knowledge about mechanics, for instance,

786
00:34:19,240 --> 00:34:21,360
 or in other fields where you have some other knowledge

787
00:34:21,360 --> 00:34:22,360
 into the neural network.

788
00:34:22,360 --> 00:34:24,720
 Now, the trade-off there, Rich Sutton

789
00:34:24,720 --> 00:34:29,360
 would say, any time you inject your understanding of the world,

790
00:34:29,360 --> 00:34:31,380
 then you've corrupted the system and you've

791
00:34:31,380 --> 00:34:34,040
 limited what it's capable of learning.

792
00:34:34,040 --> 00:34:36,320
 But you probably also made it more data efficient.

793
00:34:36,320 --> 00:34:37,840
 So there's a trade-off there.

794
00:34:37,840 --> 00:34:41,960
 Awesome.

795
00:34:41,960 --> 00:34:42,680
 Great question.

796
00:34:42,680 --> 00:34:49,440
 So I want to start digging in, unpacking

797
00:34:49,440 --> 00:34:52,000
 what are the different pieces of a manipulation system

798
00:34:52,000 --> 00:34:54,200
 and how we're going to think about them in this class

799
00:34:54,200 --> 00:34:57,800
 because I think about things through the lens of control,

800
00:34:57,800 --> 00:35:00,360
 even perception is just a control problem.

801
00:35:00,360 --> 00:35:06,460
 So how many people know Ross?

802
00:35:06,460 --> 00:35:07,620
 You don't have to know Ross.

803
00:35:07,620 --> 00:35:09,120
 Don't feel bad if you're not putting your arms up.

804
00:35:09,120 --> 00:35:10,720
 I'm just trying to understand.

805
00:35:10,720 --> 00:35:12,980
 I don't assume people know robotics.

806
00:35:12,980 --> 00:35:16,160
 But if you've done robotics, then you've probably

807
00:35:16,160 --> 00:35:20,080
 touched Ross, the robot operating system.

808
00:35:20,080 --> 00:35:21,080
 You pick.

809
00:35:21,080 --> 00:35:22,840
 You pick your threshold of whether you

810
00:35:22,840 --> 00:35:23,960
 have your knowledge of Ross.

811
00:35:23,960 --> 00:35:25,760
 But if you've been exposed to Ross,

812
00:35:25,760 --> 00:35:30,720
 then you have a sense for what the anatomy of a manipulation

813
00:35:30,720 --> 00:35:32,600
 system could look like.

814
00:35:32,600 --> 00:35:33,600
 So what is Ross?

815
00:35:33,600 --> 00:35:35,440
 Ross is, I think, one of the best things

816
00:35:35,440 --> 00:35:37,840
 that happened to robotics.

817
00:35:37,840 --> 00:35:39,220
 They call it an operating system.

818
00:35:39,220 --> 00:35:40,720
 That's kind of a misnomer.

819
00:35:40,720 --> 00:35:44,920
 It's really-- well, it's a way of packaging

820
00:35:44,920 --> 00:35:47,240
 different components of a manipulation system

821
00:35:47,240 --> 00:35:49,760
 that run on a proper operating system.

822
00:35:49,760 --> 00:35:53,080
 And they pass messages back and forth.

823
00:35:53,080 --> 00:35:56,400
 And it allowed us to sort of break up the manipulation

824
00:35:56,400 --> 00:35:58,840
 problem into a more modular approach.

825
00:35:58,840 --> 00:36:05,760
 So you might write a Ross node that could be my camera

826
00:36:05,760 --> 00:36:07,040
 driver, for instance.

827
00:36:07,040 --> 00:36:12,680
 So I buy a camera from Intel, let's say.

828
00:36:12,680 --> 00:36:16,800
 It has some low-level software that talks to it.

829
00:36:16,800 --> 00:36:18,840
 And somewhere, it gives you an image.

830
00:36:18,840 --> 00:36:20,400
 So I could make a little Ross node--

831
00:36:20,400 --> 00:36:22,480
 in fact, people have done this before me now--

832
00:36:22,480 --> 00:36:32,520
 make a little Ross node, which a Ross node is an executable,

833
00:36:32,520 --> 00:36:33,720
 a process that you'd run.

834
00:36:33,720 --> 00:36:41,160
 It could be a Python script or whatever.

835
00:36:41,160 --> 00:36:42,640
 But it's somehow something that runs

836
00:36:42,640 --> 00:36:45,200
 as a process on your computer and starts

837
00:36:45,200 --> 00:36:48,120
 sending messages that have the information you

838
00:36:48,120 --> 00:36:50,480
 need from that driver for the rest of the world

839
00:36:50,480 --> 00:36:51,320
 to think about.

840
00:36:51,320 --> 00:36:52,780
 So maybe from the driver, it's just

841
00:36:52,780 --> 00:36:54,560
 going to spit out RGB images.

842
00:36:54,560 --> 00:37:00,400
 In robotics, we often actually use depth cameras.

843
00:37:00,400 --> 00:37:04,440
 So they have red, green, blue, but also depth coming out.

844
00:37:04,440 --> 00:37:06,920
 And it just says, I'm going to send packets

845
00:37:06,920 --> 00:37:10,240
 on a network protocol that contain these images.

846
00:37:10,240 --> 00:37:13,600
 And I'll define exactly the spec in a general way.

847
00:37:13,600 --> 00:37:16,880
 And then you write a different process, a different Ross node

848
00:37:16,880 --> 00:37:18,360
 that might be my perception system.

849
00:37:19,360 --> 00:37:26,240
 And the perception system is a different executable.

850
00:37:26,240 --> 00:37:26,840
 You run it.

851
00:37:26,840 --> 00:37:27,760
 It's kind of a pain.

852
00:37:27,760 --> 00:37:28,800
 When you're working with Ross, you

853
00:37:28,800 --> 00:37:30,800
 have to start lots of processes every time

854
00:37:30,800 --> 00:37:32,880
 you want to run the robot.

855
00:37:32,880 --> 00:37:35,120
 But that's how we go.

856
00:37:35,120 --> 00:37:37,680
 So maybe I'll start a different process that starts listening

857
00:37:37,680 --> 00:37:42,560
 for RGB images and puts out, for instance,

858
00:37:42,560 --> 00:37:48,040
 what's the position or the pose of the mug.

859
00:37:48,040 --> 00:37:49,720
 Like I said, that's probably not going

860
00:37:49,720 --> 00:37:50,760
 to take us the whole way.

861
00:37:50,760 --> 00:37:53,720
 But that's a simple example for now.

862
00:37:53,720 --> 00:37:58,400
 And maybe the pose of the mug goes to some other planning

863
00:37:58,400 --> 00:38:05,240
 system that listens for the state of the mug

864
00:38:05,240 --> 00:38:12,600
 and maybe also the state of the robot, for instance,

865
00:38:12,600 --> 00:38:14,400
 and tries to decide, how does my robot

866
00:38:14,400 --> 00:38:16,000
 need to move through the world in order

867
00:38:16,000 --> 00:38:19,160
 to manipulate the mug?

868
00:38:19,160 --> 00:38:25,600
 And it'll pick out some joint trajectories, for instance.

869
00:38:25,600 --> 00:38:27,760
 This is just one version of that.

870
00:38:27,760 --> 00:38:31,880
 The deep learning version could look different, for instance.

871
00:38:31,880 --> 00:38:40,360
 And then maybe I've got my robot controller here

872
00:38:40,360 --> 00:38:43,000
 that thinks about commands of where the robot wants

873
00:38:43,000 --> 00:38:45,280
 the hands to be or the arms to be

874
00:38:45,280 --> 00:38:46,800
 and turns that into motor commands.

875
00:38:46,800 --> 00:38:58,400
 And then there's some other motor driver

876
00:38:58,400 --> 00:39:03,280
 that shipped from the company that you bought motors from.

877
00:39:03,280 --> 00:39:08,640
 And what's important, the reason I wanted to just take a second

878
00:39:08,640 --> 00:39:13,280
 to write that down, is that ROS really did an amazing thing.

879
00:39:13,280 --> 00:39:16,680
 It helped us start to modularize and compartmentalize

880
00:39:16,680 --> 00:39:21,720
 some of the complexity of building a big system like this.

881
00:39:21,720 --> 00:39:24,720
 And in particular, it made it easier to share.

882
00:39:24,720 --> 00:39:27,240
 It was an open source project, one

883
00:39:27,240 --> 00:39:30,240
 of the great open source projects in robotics.

884
00:39:30,240 --> 00:39:32,720
 And it started an entire ecosystem

885
00:39:32,720 --> 00:39:35,480
 of people who could say, well, maybe I'll

886
00:39:35,480 --> 00:39:38,280
 download a perception system from Carnegie Mellon.

887
00:39:38,280 --> 00:39:40,520
 And then I'll get my robot controller

888
00:39:40,520 --> 00:39:42,480
 from the German Space Agency.

889
00:39:42,480 --> 00:39:43,640
 They're really good at that.

890
00:39:43,640 --> 00:39:46,680
 And then I just want to write a planning system.

891
00:39:46,680 --> 00:39:49,600
 So I'll focus my attention on writing a really good planning

892
00:39:49,600 --> 00:39:50,840
 system.

893
00:39:50,840 --> 00:39:52,880
 And then if I succeed and write a really good one,

894
00:39:52,880 --> 00:39:54,080
 I'll put it up in ROS.

895
00:39:54,080 --> 00:39:56,660
 And everybody else can download it and work on their perception

896
00:39:56,660 --> 00:39:57,880
 systems or whatever.

897
00:39:57,880 --> 00:39:59,880
 And this sharing that happened because of ROS

898
00:39:59,880 --> 00:40:01,960
 was just fantastically good.

899
00:40:01,960 --> 00:40:04,960
 But also, the modularity that happened with that

900
00:40:04,960 --> 00:40:06,440
 was important and special.

901
00:40:06,440 --> 00:40:08,440
 So the fact that these are running

902
00:40:08,440 --> 00:40:11,400
 as different executables and the only connection

903
00:40:11,400 --> 00:40:15,480
 was this message type was sort of fundamental.

904
00:40:15,480 --> 00:40:19,640
 As long as I could compile your code,

905
00:40:19,640 --> 00:40:22,280
 if you could have been using C++, I was using Java,

906
00:40:22,280 --> 00:40:25,160
 you were whatever, somehow the ecosystem

907
00:40:25,160 --> 00:40:26,280
 became much more friendly.

908
00:40:26,280 --> 00:40:28,240
 In fact, if you wrote yours in Windows

909
00:40:28,240 --> 00:40:32,040
 and I wrote mine in Linux, Linux is better.

910
00:40:32,040 --> 00:40:33,560
 You should write it.

911
00:40:33,560 --> 00:40:35,640
 But even if you wrote it in Windows,

912
00:40:35,640 --> 00:40:39,120
 I could write a Docker image and just run my ROS process

913
00:40:39,120 --> 00:40:41,000
 in Windows.

914
00:40:41,000 --> 00:40:43,760
 And then I can put that all together and bundle it up.

915
00:40:43,760 --> 00:40:47,920
 And maybe, let me say, you wrote yours in Ubuntu 14

916
00:40:47,920 --> 00:40:48,960
 a long time ago, right?

917
00:40:48,960 --> 00:40:51,080
 And I wrote mine in 22.

918
00:40:51,080 --> 00:40:53,540
 And I don't want to run Ubuntu 14 anymore,

919
00:40:53,540 --> 00:40:55,500
 but I still want to run your perception system.

920
00:40:55,500 --> 00:40:59,000
 So I'll just put a Docker container around it.

921
00:40:59,000 --> 00:40:59,500
 OK.

922
00:40:59,500 --> 00:41:00,760
 So a little side note.

923
00:41:00,760 --> 00:41:03,880
 I have an interesting challenge of talking

924
00:41:03,880 --> 00:41:06,480
 to people that are at many levels of the spectrum here.

925
00:41:06,480 --> 00:41:07,860
 Some of you are robotics experts.

926
00:41:07,860 --> 00:41:10,720
 Some of you are never doing robotics yet.

927
00:41:10,720 --> 00:41:12,200
 This is great to start.

928
00:41:12,200 --> 00:41:15,640
 So I'll drop in some lingo somehow

929
00:41:15,640 --> 00:41:17,820
 that maybe not everybody understands.

930
00:41:17,820 --> 00:41:20,100
 I do that somewhat intentionally.

931
00:41:20,100 --> 00:41:22,400
 I apologize if I do it too much.

932
00:41:22,400 --> 00:41:24,080
 I hope that the folks that are experts

933
00:41:24,080 --> 00:41:25,200
 get a little bit out of it.

934
00:41:25,200 --> 00:41:26,440
 But I hope that it doesn't--

935
00:41:26,440 --> 00:41:29,440
 I will try to be conscious to never drop language

936
00:41:29,440 --> 00:41:32,000
 that you must know to understand the next concept.

937
00:41:32,000 --> 00:41:34,960
 So if I say, if you don't know what versions of Ubuntu are,

938
00:41:34,960 --> 00:41:36,920
 that's fine.

939
00:41:36,920 --> 00:41:38,680
 That was just a fun thing to drop.

940
00:41:38,680 --> 00:41:39,180
 OK.

941
00:41:39,180 --> 00:41:43,020
 Good.

942
00:41:43,020 --> 00:41:45,680
 So this is an extremely powerful way

943
00:41:45,680 --> 00:41:49,520
 to think about the complexity of building a big modern

944
00:41:49,520 --> 00:41:50,820
 manipulation system.

945
00:41:50,820 --> 00:41:52,880
 And really, this is a canonical standard.

946
00:41:52,880 --> 00:41:55,300
 We're going to build a separate perception system, because

947
00:41:55,300 --> 00:41:56,200
 there's some research groups that

948
00:41:56,200 --> 00:41:58,300
 are really good at perception, a separate planning

949
00:41:58,300 --> 00:42:00,500
 system, a separate robot control.

950
00:42:00,500 --> 00:42:02,600
 It's not clear that that's the right architecture.

951
00:42:02,600 --> 00:42:04,020
 And it's easy to point to examples

952
00:42:04,020 --> 00:42:09,060
 of that distinction is a limitation.

953
00:42:09,060 --> 00:42:10,460
 And we'll challenge that later.

954
00:42:10,460 --> 00:42:12,260
 But that's as a starting sketch.

955
00:42:12,260 --> 00:42:15,780
 This is sort of the sense, plan, act paradigm

956
00:42:15,780 --> 00:42:16,980
 in artificial intelligence.

957
00:42:16,980 --> 00:42:20,340
 And we don't love it, but it's been useful.

958
00:42:20,340 --> 00:42:29,420
 OK, so let me just contrast that with, let's say,

959
00:42:29,420 --> 00:42:33,300
 this is the raw software engineering view of the world.

960
00:42:33,300 --> 00:42:35,980
 So as long as you write a program that when I run,

961
00:42:35,980 --> 00:42:37,660
 it starts listening to messages, it

962
00:42:37,660 --> 00:42:39,540
 could be doing anything it wanted internally.

963
00:42:39,540 --> 00:42:41,380
 It could be calling random number generators.

964
00:42:41,380 --> 00:42:43,540
 It could be mining Bitcoin.

965
00:42:43,540 --> 00:42:47,260
 As long as it's spitting out the pose of the mug at 10 hertz,

966
00:42:47,260 --> 00:42:47,860
 I'm good.

967
00:42:47,860 --> 00:42:50,340
 I don't have to know anything about what's inside.

968
00:42:50,340 --> 00:42:53,480
 OK, let's contrast this with the control view

969
00:42:53,480 --> 00:42:57,340
 of the world, which makes similar diagrams,

970
00:42:57,340 --> 00:43:00,180
 but asks a little bit more about,

971
00:43:00,180 --> 00:43:02,780
 I want to know what's inside your diagrams.

972
00:43:02,780 --> 00:43:06,180
 So a standard approach in control,

973
00:43:06,180 --> 00:43:08,180
 a control system theory is, if you've ever

974
00:43:08,180 --> 00:43:12,500
 used Simulink or Modelico or a handful of these tools,

975
00:43:12,500 --> 00:43:14,860
 LabVIEW even is a bit like this.

976
00:43:14,860 --> 00:43:24,820
 There's something called model-based design,

977
00:43:24,820 --> 00:43:27,020
 which says if you've got a big, complicated system

978
00:43:27,020 --> 00:43:29,020
 and you want to think about it rigorously,

979
00:43:29,020 --> 00:43:32,860
 then you should start by encapsulating that complexity

980
00:43:32,860 --> 00:43:34,980
 in a block diagram.

981
00:43:34,980 --> 00:43:39,500
 So maybe I have my actual robot here,

982
00:43:39,500 --> 00:43:49,220
 and it's a thing that takes in motor commands

983
00:43:49,220 --> 00:43:52,180
 and puts out sensor information.

984
00:43:52,180 --> 00:43:53,140
 Maybe it's a simulator.

985
00:43:53,140 --> 00:43:55,820
 Maybe it's the robot.

986
00:43:55,820 --> 00:43:59,500
 But I have some sort of model of this.

987
00:43:59,500 --> 00:44:03,660
 Now, Ross really pushed the notion--

988
00:44:03,660 --> 00:44:07,180
 sensor-- Ross pushed the notion that these communication

989
00:44:07,180 --> 00:44:11,060
 channels should be network message passing.

990
00:44:11,060 --> 00:44:14,100
 But before, these were signals and systems

991
00:44:14,100 --> 00:44:16,660
 in block diagrams in controls.

992
00:44:16,660 --> 00:44:19,540
 And you could compose these signals and systems

993
00:44:19,540 --> 00:44:22,860
 into more complicated block diagrams.

994
00:44:22,860 --> 00:44:28,260
 And I think they're two sides of the same story.

995
00:44:28,260 --> 00:44:30,420
 And let's just compare and contrast them.

996
00:44:30,420 --> 00:44:33,540
 So if I'm in Simulink or something like this,

997
00:44:33,540 --> 00:44:35,340
 then in order to describe my robot,

998
00:44:35,340 --> 00:44:37,600
 I'm going to use the language of differential equations

999
00:44:37,600 --> 00:44:39,380
 typically, or difference equations,

1000
00:44:39,380 --> 00:44:42,260
 in order to describe what's happening inside this box.

1001
00:44:42,260 --> 00:44:44,980
 It could be really complicated difference equations,

1002
00:44:44,980 --> 00:44:48,060
 but they're probably not mining Bitcoin.

1003
00:44:48,060 --> 00:44:48,560
 You could.

1004
00:44:48,560 --> 00:44:50,560
 I guess you could.

1005
00:44:50,560 --> 00:44:56,220
 So inside here, I'll say it's not an arbitrary executable.

1006
00:44:56,220 --> 00:44:58,540
 It's not anything I could write in software.

1007
00:44:58,540 --> 00:45:02,060
 It's going to be some sort of difference equation.

1008
00:45:02,060 --> 00:45:09,100
 So here, x in this example would be the state of the robot,

1009
00:45:09,100 --> 00:45:10,900
 for instance.

1010
00:45:10,900 --> 00:45:13,140
 It could be the positions and velocities of the joint.

1011
00:45:13,140 --> 00:45:19,020
 u is typically used in these frameworks as the input.

1012
00:45:20,020 --> 00:45:23,120
 Which is, in this case, the motor commands.

1013
00:45:23,120 --> 00:45:31,760
 So I would have a difference equation

1014
00:45:31,760 --> 00:45:33,760
 that takes the state of the robot.

1015
00:45:33,760 --> 00:45:35,520
 Potentially does some complicated physics,

1016
00:45:35,520 --> 00:45:38,560
 in this case, or perception in some other case.

1017
00:45:38,560 --> 00:45:41,840
 Tells me how the state of the robot evolves on the next step.

1018
00:45:41,840 --> 00:45:43,680
 And then I have some other function

1019
00:45:43,680 --> 00:45:46,280
 that tells me how to generate the sensors

1020
00:45:46,280 --> 00:45:52,440
 from the state and the input.

1021
00:45:52,440 --> 00:45:55,160
 This is the language of difference equations.

1022
00:45:55,160 --> 00:46:05,160
 And you've seen it maybe in 18.03

1023
00:46:05,160 --> 00:46:09,760
 if you were an MIT undergrad or are an MIT undergrad.

1024
00:46:09,760 --> 00:46:12,840
 You probably saw simpler versions of it.

1025
00:46:12,840 --> 00:46:15,120
 You might have seen it as--

1026
00:46:15,120 --> 00:46:16,880
 this is a state space difference equation.

1027
00:46:16,880 --> 00:46:19,480
 Maybe you saw it first as a linear difference equation

1028
00:46:19,480 --> 00:46:22,120
 with linear algebra involved.

1029
00:46:22,120 --> 00:46:25,320
 Maybe if you took an intro controls course,

1030
00:46:25,320 --> 00:46:30,720
 you would have seen the state space version that would have

1031
00:46:30,720 --> 00:46:33,360
 included control inputs.

1032
00:46:33,360 --> 00:46:35,520
 Something like that.

1033
00:46:35,520 --> 00:46:37,840
 This is just the nonlinear generalization

1034
00:46:37,840 --> 00:46:40,960
 where f can be an arbitrary function.

1035
00:46:40,960 --> 00:46:43,480
 And what's interesting is that I would

1036
00:46:43,480 --> 00:46:47,440
 claim that almost everything you could write in your ROS--

1037
00:46:47,440 --> 00:46:49,600
 that you would want to write in your ROS ecosystem

1038
00:46:49,600 --> 00:46:52,560
 for controlling a big complicated robot

1039
00:46:52,560 --> 00:46:55,480
 could be described carefully with difference equations,

1040
00:46:55,480 --> 00:46:57,320
 differential equations.

1041
00:46:57,320 --> 00:47:00,360
 And in particular, writing it this way

1042
00:47:00,360 --> 00:47:03,280
 says when we're combining systems together,

1043
00:47:03,280 --> 00:47:05,960
 we're not only going to agree on the message pass, the message

1044
00:47:05,960 --> 00:47:07,440
 type that's passed.

1045
00:47:07,440 --> 00:47:11,000
 We're going to say something-- this embeds a timing semantics

1046
00:47:11,000 --> 00:47:12,960
 pretty firmly.

1047
00:47:12,960 --> 00:47:14,960
 So we have to say something about how often this

1048
00:47:14,960 --> 00:47:16,440
 is getting updated.

1049
00:47:16,440 --> 00:47:19,120
 We have to declare our state.

1050
00:47:19,120 --> 00:47:21,240
 So it's not going to be arbitrary.

1051
00:47:21,240 --> 00:47:22,440
 It's going to-- we have--

1052
00:47:22,440 --> 00:47:25,200
 for instance, if I ever wanted to rewind my simulation

1053
00:47:25,200 --> 00:47:29,520
 or my controller or whatever and just play it back in time,

1054
00:47:29,520 --> 00:47:31,280
 you can do that if you've declared state.

1055
00:47:31,280 --> 00:47:33,080
 But if you're doing arbitrary computations,

1056
00:47:33,080 --> 00:47:36,160
 you can't do that.

1057
00:47:36,160 --> 00:47:38,080
 And these functions can be complicated.

1058
00:47:38,080 --> 00:47:39,480
 That's not really a limitation.

1059
00:47:39,480 --> 00:47:42,120
 But it does ask you to sort of not just

1060
00:47:42,120 --> 00:47:45,040
 agree on the message passing, but agree on somehow

1061
00:47:45,040 --> 00:47:46,440
 that we're going to use difference

1062
00:47:46,440 --> 00:47:51,080
 and differential equations to describe our systems.

1063
00:47:51,080 --> 00:47:56,960
 In some cases, like the camera model, in simulation,

1064
00:47:56,960 --> 00:47:58,920
 the thing that takes the state of the world

1065
00:47:58,920 --> 00:48:03,480
 and puts out RGBD images, that's a full-on game renderer.

1066
00:48:03,480 --> 00:48:06,720
 That's a photorealistic renderer that I'm

1067
00:48:06,720 --> 00:48:08,560
 writing in this function g.

1068
00:48:08,560 --> 00:48:10,680
 So that's not what you saw in 18.03.

1069
00:48:10,680 --> 00:48:11,520
 And it's complicated.

1070
00:48:11,520 --> 00:48:12,880
 And you might not want to--

1071
00:48:12,880 --> 00:48:13,880
 there might be some questions you

1072
00:48:13,880 --> 00:48:16,680
 wouldn't want to ask about that big, complicated g.

1073
00:48:16,680 --> 00:48:21,360
 But it still fits in the intellectual framework.

1074
00:48:21,360 --> 00:48:23,960
 And I'm going to advocate, both for research

1075
00:48:23,960 --> 00:48:28,000
 and for the pedagogical value of having things in class,

1076
00:48:28,000 --> 00:48:29,600
 that we--

1077
00:48:29,600 --> 00:48:32,160
 every time we build our systems, we do a little bit more work.

1078
00:48:32,160 --> 00:48:34,560
 And we use the difference and differential equation

1079
00:48:34,560 --> 00:48:37,880
 view of those systems.

1080
00:48:37,880 --> 00:48:40,080
 And that's going to allow better things

1081
00:48:40,080 --> 00:48:42,520
 to happen downstream.

1082
00:48:42,520 --> 00:48:45,080
 Like I said, you could rewind your simulation.

1083
00:48:45,080 --> 00:48:49,040
 You can do Monte Carlo testing, if you want.

1084
00:48:49,040 --> 00:48:50,680
 There's a lot of things that come just

1085
00:48:50,680 --> 00:48:52,800
 from having taken a little bit more work every time

1086
00:48:52,800 --> 00:48:55,080
 you build each component.

1087
00:48:55,080 --> 00:48:57,520
 I also don't want to help everybody install ROS.

1088
00:48:57,520 --> 00:49:01,920
 That's really not a fun way to teach a class.

1089
00:49:01,920 --> 00:49:05,000
 So we're going to just give one software thing that

1090
00:49:05,000 --> 00:49:06,960
 does this version of it.

1091
00:49:06,960 --> 00:49:10,680
 But it's modular in the same way that ROS is.

1092
00:49:10,680 --> 00:49:14,120
 But it's using the language of difference equations.

1093
00:49:14,120 --> 00:49:25,760
 These functions really do get complicated.

1094
00:49:25,760 --> 00:49:30,760
 And like I said, the fact that g is a renderer that's

1095
00:49:30,760 --> 00:49:33,040
 good enough to train a perception system.

1096
00:49:33,040 --> 00:49:35,520
 Or a neural network can fit in this framework, too.

1097
00:49:35,520 --> 00:49:39,120
 So one of these systems might be a neural network.

1098
00:49:39,120 --> 00:49:44,400
 They could take, for instance, RGB images in, or RGBD images,

1099
00:49:44,400 --> 00:49:47,200
 and spits out, let's say, a pose of the mug.

1100
00:49:47,200 --> 00:49:49,440
 But that's not the final story.

1101
00:49:49,440 --> 00:49:54,240
 So let's just think for a second.

1102
00:49:54,240 --> 00:49:56,520
 What if we put a big neural network in here?

1103
00:49:56,520 --> 00:50:02,240
 Is it useful to think about neural networks?

1104
00:50:02,240 --> 00:50:04,360
 I want to think about neural networks with PyTorch

1105
00:50:04,360 --> 00:50:05,040
 or something.

1106
00:50:05,040 --> 00:50:08,680
 I don't want to think about it as differential equations.

1107
00:50:08,680 --> 00:50:09,400
 That's not true.

1108
00:50:09,400 --> 00:50:11,480
 I want to think about it as differential equations.

1109
00:50:11,480 --> 00:50:12,880
 And I want to slowly convince you

1110
00:50:12,880 --> 00:50:15,960
 to think about it as differential equations.

1111
00:50:15,960 --> 00:50:18,600
 So if you're doing a feed-forward neural network,

1112
00:50:18,600 --> 00:50:21,080
 then you could write that as a simple function that

1113
00:50:21,080 --> 00:50:23,160
 has no state and just is a big--

1114
00:50:23,160 --> 00:50:24,620
 this is my neural network function

1115
00:50:24,620 --> 00:50:26,720
 that just takes inputs and outputs,

1116
00:50:26,720 --> 00:50:29,560
 the output of the network.

1117
00:50:29,560 --> 00:50:32,760
 If I have a recurrent network, then I do have a state.

1118
00:50:32,760 --> 00:50:34,560
 And I should tell my system about it.

1119
00:50:34,560 --> 00:50:37,360
 And that way, if I ever wanted to rewind the progress

1120
00:50:37,360 --> 00:50:43,200
 of my LSTM, for instance, or your favorite recurrent

1121
00:50:43,200 --> 00:50:46,160
 neural network, then I could declare that state.

1122
00:50:46,160 --> 00:50:47,760
 And I should declare that state if I'm

1123
00:50:47,760 --> 00:50:50,400
 trying to make more rigorous understanding

1124
00:50:50,400 --> 00:50:52,160
 of the complicated system.

1125
00:50:52,160 --> 00:50:54,080
 If you're a transformer, then maybe you just

1126
00:50:54,080 --> 00:50:58,840
 have really big input tapes, or you call this your buffer.

1127
00:50:58,840 --> 00:51:00,080
 But it all fits.

1128
00:51:00,080 --> 00:51:02,040
 Transformers fit fine into this framework.

1129
00:51:02,040 --> 00:51:05,440
 [AUDIO OUT]

1130
00:51:05,440 --> 00:51:15,040
 So I'll show a few examples of that here.

1131
00:51:15,040 --> 00:51:25,640
 But the software that we're going to use,

1132
00:51:25,640 --> 00:51:28,880
 because that's what I've been working on a lot,

1133
00:51:28,880 --> 00:51:30,400
 is called Drake.

1134
00:51:30,400 --> 00:51:35,000
 So a lot of people ask me what Drake is.

1135
00:51:35,000 --> 00:51:37,760
 And I think the simplest answer--

1136
00:51:37,760 --> 00:51:40,720
 how many people know Harry Potter?

1137
00:51:40,720 --> 00:51:42,960
 You know what a Horcrux is?

1138
00:51:42,960 --> 00:51:45,120
 I think Drake is kind of my Horcrux, probably.

1139
00:51:45,120 --> 00:51:48,560
 That's probably the most honest answer I can give you.

1140
00:51:48,560 --> 00:51:51,800
 It's kind of me trying to put my soul into a piece of software.

1141
00:51:51,800 --> 00:51:55,440
 And I've had some incredibly talented engineers

1142
00:51:55,440 --> 00:51:58,440
 that have been working on it and making the dynamics

1143
00:51:58,440 --> 00:51:59,240
 engine really good.

1144
00:51:59,240 --> 00:52:03,960
 And it's a passion for me, about trying

1145
00:52:03,960 --> 00:52:06,800
 to take some of this differential equation,

1146
00:52:06,800 --> 00:52:08,400
 difference equation view of the world,

1147
00:52:08,400 --> 00:52:11,360
 and make it solve extremely complicated physics

1148
00:52:11,360 --> 00:52:14,040
 and controls problems.

1149
00:52:14,040 --> 00:52:17,120
 And I think it's good enough to be used in the class.

1150
00:52:17,120 --> 00:52:19,720
 And it'll run in your browser with no installation

1151
00:52:19,720 --> 00:52:21,000
 and all that other stuff.

1152
00:52:21,000 --> 00:52:24,920
 So I won't dive too much into it today.

1153
00:52:24,920 --> 00:52:27,200
 But we'll try to work you through.

1154
00:52:27,200 --> 00:52:29,520
 I've gotten feedback over the years

1155
00:52:29,520 --> 00:52:32,640
 that actually a little bit more tutorials about Drake

1156
00:52:32,640 --> 00:52:34,920
 early on would help people with their homeworks

1157
00:52:34,920 --> 00:52:37,120
 and certainly help people with their projects.

1158
00:52:37,120 --> 00:52:38,880
 So we have a few problems that sort of

1159
00:52:38,880 --> 00:52:42,160
 ask you to explore the software a little bit, too.

1160
00:52:42,160 --> 00:52:44,880
 But it's really meant to build up three things.

1161
00:52:44,880 --> 00:52:47,480
 One of them is this modeling dynamical systems.

1162
00:52:47,480 --> 00:52:50,840
 So if you want to take this difference equation description

1163
00:52:50,840 --> 00:52:53,440
 and build really good robot models, really good

1164
00:52:53,440 --> 00:52:56,680
 neural network models, and this, whatever, then you can do that.

1165
00:52:56,680 --> 00:52:58,360
 And it has a block diagram language

1166
00:52:58,360 --> 00:53:00,240
 that you can say I'm going to add this system.

1167
00:53:00,240 --> 00:53:01,440
 I'm going to add this system.

1168
00:53:01,440 --> 00:53:04,480
 I'm going to connect the output port here to the input port

1169
00:53:04,480 --> 00:53:05,680
 here.

1170
00:53:05,680 --> 00:53:11,280
 And it's not only a toolbox for writing these,

1171
00:53:11,280 --> 00:53:13,040
 but it's a big collection of the systems

1172
00:53:13,040 --> 00:53:14,740
 that have already been written for you,

1173
00:53:14,740 --> 00:53:16,740
 so a big collection of different controllers

1174
00:53:16,740 --> 00:53:19,260
 and dynamical systems and the like.

1175
00:53:19,260 --> 00:53:22,680
 A lot of those dynamical systems in my world use optimization.

1176
00:53:22,680 --> 00:53:25,400
 So there's actually a really nice optimization library

1177
00:53:25,400 --> 00:53:27,080
 attached and built into Drake.

1178
00:53:27,080 --> 00:53:30,040
 So if you want to write a controller

1179
00:53:30,040 --> 00:53:33,360
 by solving a small convex optimization problem or whatever,

1180
00:53:33,360 --> 00:53:34,640
 that's very possible in Drake.

1181
00:53:34,640 --> 00:53:36,600
 That's kind of what it was built for, too.

1182
00:53:36,600 --> 00:53:40,160
 And then there's a lot of specific tools

1183
00:53:40,160 --> 00:53:43,120
 when you get into the physics engine of working

1184
00:53:43,120 --> 00:53:46,840
 with the dynamics of the system, solving kinematics problems,

1185
00:53:46,840 --> 00:53:48,960
 solving dynamics problems, asking

1186
00:53:48,960 --> 00:53:52,200
 what's the center of mass of this really complicated thing?

1187
00:53:52,200 --> 00:53:55,880
 What is the Jacobian of some strange quantity?

1188
00:53:55,880 --> 00:53:59,240
 It's really good at those kind of things.

1189
00:53:59,240 --> 00:54:01,480
 And it provides this level of abstraction.

1190
00:54:01,480 --> 00:54:03,960
 So the signals and system-- there's a lot of tutorials,

1191
00:54:03,960 --> 00:54:06,240
 by the way, online if you ever get stuck.

1192
00:54:06,240 --> 00:54:08,240
 A lot of people, I think, don't go back and look

1193
00:54:08,240 --> 00:54:10,560
 at the tutorials, but you can.

1194
00:54:10,560 --> 00:54:12,440
 And it's perfectly compatible with ROS.

1195
00:54:12,440 --> 00:54:15,860
 If you want to have your Drake diagrams live in your ROS

1196
00:54:15,860 --> 00:54:20,800
 ecosystem, that should just work, especially ROS 2.

1197
00:54:20,800 --> 00:54:25,480
 So let me give you an example here of Drake's version of this

1198
00:54:25,480 --> 00:54:28,520
 is you model these systems with difference or differential

1199
00:54:28,520 --> 00:54:29,920
 equations.

1200
00:54:29,920 --> 00:54:31,680
 And you can do that for very simple things,

1201
00:54:31,680 --> 00:54:34,360
 and you can do it for very complicated things.

1202
00:54:34,360 --> 00:54:37,480
 But if you get to the robot level,

1203
00:54:37,480 --> 00:54:40,400
 then we're going to see complicated systems here.

1204
00:54:40,400 --> 00:54:43,800
 So we have a particular system that you'll use a bunch.

1205
00:54:43,800 --> 00:54:45,880
 We're calling it the hardware station.

1206
00:54:45,880 --> 00:54:49,600
 Basically, every physical robot that you want to work with

1207
00:54:49,600 --> 00:54:52,080
 sort of have a digital twin, if you will,

1208
00:54:52,080 --> 00:54:56,480
 that's described in a YAML file and describes

1209
00:54:56,480 --> 00:54:58,840
 not only the physical elements of your robot

1210
00:54:58,840 --> 00:55:00,600
 and the objects it will interact with,

1211
00:55:00,600 --> 00:55:03,840
 but also the drivers that are on that robot.

1212
00:55:03,840 --> 00:55:07,440
 And that gets packaged up and provides encapsulation

1213
00:55:07,440 --> 00:55:10,800
 into one big system, which, for instance,

1214
00:55:10,800 --> 00:55:12,480
 if I have a KUKA IWA robot--

1215
00:55:12,480 --> 00:55:14,080
 we'll talk about our specific robots,

1216
00:55:14,080 --> 00:55:19,240
 but there's a particular type of robot called an IWA, I-I-W-A,

1217
00:55:19,240 --> 00:55:21,320
 and a particular type of gripper we'll use a bunch

1218
00:55:21,320 --> 00:55:23,840
 called the shunk WSG.

1219
00:55:23,840 --> 00:55:26,520
 So if you want to unpack these, if I

1220
00:55:26,520 --> 00:55:29,080
 take a particular hardware station

1221
00:55:29,080 --> 00:55:32,720
 and it has a IWA in it and a WSG,

1222
00:55:32,720 --> 00:55:37,040
 and the IWA driver is looking for a position command,

1223
00:55:37,040 --> 00:55:39,880
 possibly a torque command, feed forward torque,

1224
00:55:39,880 --> 00:55:42,520
 and the shunk driver is listening for a position

1225
00:55:42,520 --> 00:55:45,320
 command, maybe a force limit, those

1226
00:55:45,320 --> 00:55:47,360
 are the commands that the software

1227
00:55:47,360 --> 00:55:51,200
 we get from the manufacturer provide.

1228
00:55:51,200 --> 00:55:54,560
 And the Drake abstraction of this

1229
00:55:54,560 --> 00:55:57,600
 will give you input ports that are signals that

1230
00:55:57,600 --> 00:56:00,520
 are waiting for those commands and will send it

1231
00:56:00,520 --> 00:56:04,600
 to either a simulated version of the IWA and the shunk

1232
00:56:04,600 --> 00:56:07,960
 or the real hardware, depending on-- you just flip a switch

1233
00:56:07,960 --> 00:56:09,040
 and it'll change.

1234
00:56:09,040 --> 00:56:10,960
 And inside this, it'll do the message passing,

1235
00:56:10,960 --> 00:56:13,000
 just like in ROS.

1236
00:56:13,000 --> 00:56:15,200
 And on the other side, the IWA driver

1237
00:56:15,200 --> 00:56:16,700
 spits out a lot of different things.

1238
00:56:16,700 --> 00:56:20,080
 It says what position it got commanded, position measured,

1239
00:56:20,080 --> 00:56:21,080
 all these things.

1240
00:56:21,080 --> 00:56:25,280
 But this abstraction is exactly provided

1241
00:56:25,280 --> 00:56:27,560
 by the drivers and the real robot.

1242
00:56:27,560 --> 00:56:29,200
 That's the boundary layer.

1243
00:56:29,200 --> 00:56:31,880
 And by encapsulating it with the signals and systems

1244
00:56:31,880 --> 00:56:34,800
 of this block diagram, I can change the implementation

1245
00:56:34,800 --> 00:56:35,520
 underneath.

1246
00:56:35,520 --> 00:56:38,200
 But if you've written your control system just expecting

1247
00:56:38,200 --> 00:56:40,460
 to talk here, the same way in ROS,

1248
00:56:40,460 --> 00:56:42,320
 I have a very modular approach.

1249
00:56:42,320 --> 00:56:44,720
 I can do things like flip a switch

1250
00:56:44,720 --> 00:56:48,120
 and I've switched from simulation to the real robot.

1251
00:56:48,120 --> 00:56:49,920
 In particular, if you do want to convince me

1252
00:56:49,920 --> 00:56:52,600
 to run your code on the real robot at the end of the term,

1253
00:56:52,600 --> 00:56:54,100
 there's actually two steps we'll do.

1254
00:56:54,100 --> 00:56:58,620
 First, we'll make it run all in one simulation.

1255
00:56:58,620 --> 00:57:00,900
 And then we'll say, run on a remote robot.

1256
00:57:00,900 --> 00:57:02,520
 But I'm not going to turn on the robot.

1257
00:57:02,520 --> 00:57:05,000
 I'm going to turn on a simulator on another computer

1258
00:57:05,000 --> 00:57:07,400
 and make sure that it works on a remote simulator

1259
00:57:07,400 --> 00:57:10,180
 with all the message passing and nothing blows up.

1260
00:57:10,180 --> 00:57:12,220
 And then, if you're not going to break the robot,

1261
00:57:12,220 --> 00:57:13,960
 then we'll turn off that second simulator

1262
00:57:13,960 --> 00:57:17,240
 and turn on the robot and it'll all just work.

1263
00:57:17,240 --> 00:57:17,740
 OK.

1264
00:57:17,740 --> 00:57:19,880
 So in software engineering, you can sort of

1265
00:57:19,880 --> 00:57:23,560
 think of it as object-oriented programming.

1266
00:57:23,560 --> 00:57:27,440
 Classes provide levels, tools for encapsulation

1267
00:57:27,440 --> 00:57:28,240
 and abstraction.

1268
00:57:28,240 --> 00:57:30,120
 And when used properly, they can allow

1269
00:57:30,120 --> 00:57:32,880
 you to build incredibly complicated systems.

1270
00:57:32,880 --> 00:57:34,960
 In the dynamical systems world, which

1271
00:57:34,960 --> 00:57:37,640
 we are living in in the class here,

1272
00:57:37,640 --> 00:57:39,240
 it's signals and systems.

1273
00:57:39,240 --> 00:57:42,840
 Systems are what provide that similar level of encapsulation

1274
00:57:42,840 --> 00:57:44,040
 and abstraction.

1275
00:57:44,040 --> 00:57:46,040
 You tell me your inputs and your outputs,

1276
00:57:46,040 --> 00:57:49,120
 what's happening on the inside with differential equations,

1277
00:57:49,120 --> 00:57:51,280
 and we can do similar--

1278
00:57:51,280 --> 00:57:55,800
 build big, tall towers of complicated things.

1279
00:57:55,800 --> 00:57:58,040
 If you zoom inside that, then you'll actually

1280
00:57:58,040 --> 00:57:59,280
 see a lot of complexity.

1281
00:57:59,280 --> 00:58:10,040
 So when you're in simulator mode, for instance,

1282
00:58:10,040 --> 00:58:16,960
 that hardware station, abstraction

1283
00:58:16,960 --> 00:58:20,480
 is actually, in itself, a diagram.

1284
00:58:20,480 --> 00:58:23,520
 And if you look inside, what's happening with the EWA

1285
00:58:23,520 --> 00:58:28,040
 position, it's actually being fed

1286
00:58:28,040 --> 00:58:31,120
 to another system, which is an inverse dynamics

1287
00:58:31,120 --> 00:58:36,760
 controller, for instance, which then goes

1288
00:58:36,760 --> 00:58:41,680
 to our dynamics engine, which we call multibody plant.

1289
00:58:41,680 --> 00:58:51,360
 That's the physics engine.

1290
00:58:51,360 --> 00:58:54,920
 And it also goes to something we call the scene graph.

1291
00:58:54,920 --> 00:58:56,560
 You'll see you'll explore these things,

1292
00:58:56,560 --> 00:58:59,160
 but this is the rendering engine.

1293
00:58:59,160 --> 00:59:06,200
 And there's a variety of different systems

1294
00:59:06,200 --> 00:59:08,960
 that are inside here that ultimately puts out

1295
00:59:08,960 --> 00:59:13,160
 my ability to put a simulated camera image.

1296
00:59:13,160 --> 00:59:15,040
 And you can nest these diagrams and build up

1297
00:59:15,040 --> 00:59:18,840
 more and more complicated abstraction.

1298
00:59:18,840 --> 00:59:23,320
 I'll run a quick example here now.

1299
00:59:23,320 --> 00:59:30,680
 So this is the first intro notebook in the class.

1300
00:59:30,680 --> 00:59:31,440
 I hope you run it.

1301
00:59:31,440 --> 00:59:32,880
 I hope you play with it.

1302
00:59:32,880 --> 00:59:36,200
 You see that it'll always open up a browser.

1303
00:59:36,200 --> 00:59:42,240
 This is Meshcat, our browser.

1304
00:59:42,240 --> 00:59:44,640
 You don't have to install anything to run this.

1305
00:59:44,640 --> 00:59:46,840
 Even the notebook will run in the cloud.

1306
00:59:46,840 --> 00:59:51,440
 And you have a relatively simple script that describes--

1307
00:59:51,440 --> 00:59:53,800
 I'm going to add a model, which is the EWA.

1308
00:59:53,800 --> 00:59:56,480
 And it's described in this particular format.

1309
00:59:56,480 --> 01:00:02,480
 I'm going to add a different model that

1310
01:00:02,480 --> 01:00:06,560
 is the Shunk Gripper that's described in this place.

1311
01:00:06,560 --> 01:00:08,480
 And it's just a series of simple things.

1312
01:00:08,480 --> 01:00:10,720
 I'm going to add a brick to the world.

1313
01:00:10,720 --> 01:00:12,760
 And then I wire it all up.

1314
01:00:12,760 --> 01:00:18,480
 I get a simulator now that I can interact with and run and pick

1315
01:00:18,480 --> 01:00:20,000
 up the brick.

1316
01:00:20,000 --> 01:00:28,360
 The YAML is the description for that.

1317
01:00:28,360 --> 01:00:33,880
 And then it parses into a signals and systems thing.

1318
01:00:33,880 --> 01:00:36,280
 I hope you all just go home and run that and try it.

1319
01:00:36,280 --> 01:00:47,800
 Any questions about that?

1320
01:00:47,800 --> 01:00:50,560
 Yes?

1321
01:00:50,560 --> 01:00:53,880
 EWA is a strange name, all lowercase.

1322
01:00:53,880 --> 01:00:56,320
 I always want to capitalize it because it's a proper name.

1323
01:00:56,320 --> 01:00:57,280
 But no.

1324
01:00:57,280 --> 01:00:59,880
 The manufacturers call it EWA.

1325
01:00:59,880 --> 01:01:03,880
 And it's exactly that robot that was on the screen here.

1326
01:01:03,880 --> 01:01:06,360
 So KUKA is the manufacturer.

1327
01:01:06,360 --> 01:01:08,360
 And they build lots of robot arms.

1328
01:01:08,360 --> 01:01:12,600
 And one series is called the EWA, I-I-W-A.

1329
01:01:12,600 --> 01:01:14,880
 Thank you for asking this, by the way.

1330
01:01:14,880 --> 01:01:18,320
 And in particular, there's two that we'll use in class.

1331
01:01:18,320 --> 01:01:21,920
 There's an EWA-14 or an EWA-7, which refers to the payload

1332
01:01:21,920 --> 01:01:22,960
 that they have.

1333
01:01:22,960 --> 01:01:25,960
 And that's something you could buy.

1334
01:01:25,960 --> 01:01:30,200
 It's yours for only $85,000 or something like that.

1335
01:01:30,200 --> 01:01:32,200
 Or you can simulate it for free.

1336
01:01:32,200 --> 01:01:35,720
 And the drivers for that provide this abstraction

1337
01:01:35,720 --> 01:01:39,080
 that's to take position commands in or torque commands in

1338
01:01:39,080 --> 01:01:40,240
 and go through it.

1339
01:01:40,240 --> 01:01:42,700
 Our next lecture, we're going to talk through robot hardware.

1340
01:01:42,700 --> 01:01:45,480
 And you'll see how EWA compares to some of the other robots

1341
01:01:45,480 --> 01:01:46,480
 that are out there.

1342
01:01:46,480 --> 01:01:46,980
 Yes?

1343
01:01:46,980 --> 01:01:47,480
 [INAUDIBLE]

1344
01:01:47,480 --> 01:01:54,920
 We were going to put safety filters.

1345
01:01:54,920 --> 01:01:56,720
 He asked if he's worried about breaking my--

1346
01:01:56,720 --> 01:01:58,880
 or I'm glad you're worried about breaking my robot.

1347
01:01:58,880 --> 01:02:01,160
 We'll put the proper safety filters when we get there.

1348
01:02:01,160 --> 01:02:02,360
 Did you have a question, sir?

1349
01:02:02,360 --> 01:02:04,320
 [INAUDIBLE]

1350
01:02:04,320 --> 01:02:05,640
 Yeah, we don't want you to break the arm.

1351
01:02:05,640 --> 01:02:06,140
 Yeah.

1352
01:02:06,140 --> 01:02:06,640
 [INAUDIBLE]

1353
01:02:06,640 --> 01:02:11,100
 Yes.

1354
01:02:11,100 --> 01:02:11,600
 [INAUDIBLE]

1355
01:02:11,600 --> 01:02:24,080
 That's a really good question.

1356
01:02:24,080 --> 01:02:29,760
 So the abstraction should be exactly what you see

1357
01:02:29,760 --> 01:02:32,080
 if you were to turn on the robot.

1358
01:02:32,080 --> 01:02:36,960
 So the robot drivers output the EWA position and stuff

1359
01:02:36,960 --> 01:02:38,120
 like this.

1360
01:02:38,120 --> 01:02:39,760
 But if you have a camera in there,

1361
01:02:39,760 --> 01:02:42,720
 then they put out an RGB image.

1362
01:02:42,720 --> 01:02:45,260
 So inside here is the physics engine

1363
01:02:45,260 --> 01:02:47,680
 that is loaded with all of the objects.

1364
01:02:47,680 --> 01:02:49,720
 And the camera is in order to be able to render

1365
01:02:49,720 --> 01:02:52,880
 RGB images, which contain the mug or whatever.

1366
01:02:52,880 --> 01:02:54,640
 It has to be living in the physics engine

1367
01:02:54,640 --> 01:02:56,760
 here in order to provide the same abstraction which

1368
01:02:56,760 --> 01:03:00,040
 if I turn the robot on, yeah, it has there.

1369
01:03:00,040 --> 01:03:04,920
 Now, some of these orange ports, we call those cheat ports.

1370
01:03:04,920 --> 01:03:07,560
 If you use-- if you pull on the body poses,

1371
01:03:07,560 --> 01:03:09,200
 for development purposes, we give you

1372
01:03:09,200 --> 01:03:12,800
 access to the ground truth pose of the mug.

1373
01:03:12,800 --> 01:03:14,680
 But if you switch to hardware mode,

1374
01:03:14,680 --> 01:03:18,080
 that port is not going to be available.

1375
01:03:18,080 --> 01:03:19,800
 So when you're in simulation mode,

1376
01:03:19,800 --> 01:03:23,280
 you can get oracular information about the internal state

1377
01:03:23,280 --> 01:03:27,920
 of the world, which won't be available more generally.

1378
01:03:27,920 --> 01:03:28,420
 Yeah?

1379
01:03:28,420 --> 01:03:31,040
 [INAUDIBLE]

1380
01:03:31,040 --> 01:03:34,000
 Yeah, so ROS is an ecosystem where

1381
01:03:34,000 --> 01:03:36,720
 you make the different packages.

1382
01:03:36,720 --> 01:03:38,720
 Drake could be any one of-- you could write any one

1383
01:03:38,720 --> 01:03:40,760
 of your systems in Drake.

1384
01:03:40,760 --> 01:03:43,160
 Or you can try to write the entire thing in Drake

1385
01:03:43,160 --> 01:03:45,440
 and not use message passing.

1386
01:03:45,440 --> 01:03:49,760
 So ROS is really the communications layer,

1387
01:03:49,760 --> 01:03:52,280
 which enabled modular thinking.

1388
01:03:52,280 --> 01:03:54,440
 Drake similarly enables modular thinking because

1389
01:03:54,440 --> 01:03:56,280
 of the old controls lineage.

1390
01:03:56,280 --> 01:03:59,240
 [INAUDIBLE]

1391
01:03:59,240 --> 01:04:01,480
 One can use ROS without Drake.

1392
01:04:01,480 --> 01:04:02,280
 But you shouldn't.

1393
01:04:02,280 --> 01:04:03,280
 [INAUDIBLE]

1394
01:04:03,280 --> 01:04:04,480
 I'm just teasing.

1395
01:04:04,480 --> 01:04:04,980
 Yeah.

1396
01:04:04,980 --> 01:04:06,640
 [INAUDIBLE]

1397
01:04:06,640 --> 01:04:07,760
 That's not true either.

1398
01:04:07,760 --> 01:04:09,840
 So the question is, can you use Drake without ROS?

1399
01:04:09,840 --> 01:04:11,760
 You can run your entire simulation,

1400
01:04:11,760 --> 01:04:13,720
 and we will for most of the class, just to keep

1401
01:04:13,720 --> 01:04:16,840
 the complexity down, all in one process.

1402
01:04:16,840 --> 01:04:18,920
 And then if you want to run on hardware,

1403
01:04:18,920 --> 01:04:21,680
 and you've got a ROS driver, then you

1404
01:04:21,680 --> 01:04:23,840
 put one of the systems that you put inside here--

1405
01:04:23,840 --> 01:04:27,480
 so if I run it in hardware mode, if I just flip a switch,

1406
01:04:27,480 --> 01:04:28,760
 then this system--

1407
01:04:28,760 --> 01:04:34,200
 we call it the hardware station interface--

1408
01:04:34,200 --> 01:04:41,960
 takes the same inputs and outputs.

1409
01:04:41,960 --> 01:04:48,640
 But inside here is a ROS sender, ROS publisher.

1410
01:04:48,640 --> 01:04:55,520
 And ROS receivers, which handle the network messaging,

1411
01:04:55,520 --> 01:04:57,800
 provide the same input and output abstraction

1412
01:04:57,800 --> 01:05:00,280
 in the signals and systems world.

1413
01:05:00,280 --> 01:05:03,560
 And that's actually even right down here.

1414
01:05:03,560 --> 01:05:05,120
 That's the hardware station interface.

1415
01:05:05,120 --> 01:05:06,920
 It just won't have any of the cheat ports

1416
01:05:06,920 --> 01:05:10,600
 because the drivers can't give you that.

1417
01:05:10,600 --> 01:05:11,440
 Is that an answer?

1418
01:05:11,440 --> 01:05:11,940
 Yeah.

1419
01:05:11,940 --> 01:05:12,440
 [INAUDIBLE]

1420
01:05:12,440 --> 01:05:12,940
 Yeah.

1421
01:05:12,940 --> 01:05:13,440
 [INAUDIBLE]

1422
01:05:13,440 --> 01:05:31,940
 Yeah.

1423
01:05:31,940 --> 01:05:32,440
 [INAUDIBLE]

1424
01:05:32,440 --> 01:05:32,940
 Yeah.

1425
01:05:32,940 --> 01:05:33,440
 That's beautiful.

1426
01:05:33,440 --> 01:05:35,720
 So the question is about multiple robots use cases.

1427
01:05:35,720 --> 01:05:38,360
 If those robots need to interact on the physics level,

1428
01:05:38,360 --> 01:05:40,560
 then you actually make one hardware station that

1429
01:05:40,560 --> 01:05:43,560
 will have EWA1 position, EWA2 position, whatever.

1430
01:05:43,560 --> 01:05:45,560
 And then that way, the physics engine

1431
01:05:45,560 --> 01:05:48,080
 can have forces interacting and collisions and everything

1432
01:05:48,080 --> 01:05:48,580
 like that.

1433
01:05:48,580 --> 01:05:49,080
 Yeah.

1434
01:05:49,080 --> 01:05:49,580
 [INAUDIBLE]

1435
01:05:49,580 --> 01:05:50,080
 Yeah.

1436
01:05:50,080 --> 01:05:50,580
 [INAUDIBLE]

1437
01:05:50,580 --> 01:05:51,080
 Yeah.

1438
01:05:51,080 --> 01:05:51,580
 [INAUDIBLE]

1439
01:05:51,580 --> 01:05:52,080
 Yeah.

1440
01:05:52,080 --> 01:05:52,580
 [INAUDIBLE]

1441
01:05:52,580 --> 01:05:53,080
 Yeah.

1442
01:05:53,080 --> 01:05:53,580
 [INAUDIBLE]

1443
01:05:53,580 --> 01:05:54,080
 Yeah.

1444
01:05:54,080 --> 01:05:54,580
 [INAUDIBLE]

1445
01:05:54,580 --> 01:05:55,080
 Yeah.

1446
01:05:55,080 --> 01:05:55,580
 [INAUDIBLE]

1447
01:05:55,580 --> 01:05:56,080
 Yeah.

1448
01:05:56,080 --> 01:05:56,580
 [INAUDIBLE]

1449
01:05:56,580 --> 01:05:57,080
 Yeah.

1450
01:05:57,080 --> 01:05:57,580
 [INAUDIBLE]

1451
01:05:57,580 --> 01:05:58,080
 Yeah.

1452
01:05:58,080 --> 01:05:58,580
 [INAUDIBLE]

1453
01:05:58,580 --> 01:05:59,080
 Yeah.

1454
01:05:59,080 --> 01:05:59,580
 [INAUDIBLE]

1455
01:05:59,580 --> 01:06:00,080
 Yeah.

1456
01:06:00,080 --> 01:06:00,580
 [INAUDIBLE]

1457
01:06:00,580 --> 01:06:01,080
 Yeah.

1458
01:06:01,080 --> 01:06:01,580
 [INAUDIBLE]

1459
01:06:01,580 --> 01:06:02,080
 Yeah.

1460
01:06:02,080 --> 01:06:02,580
 [INAUDIBLE]

1461
01:06:02,580 --> 01:06:03,080
 Yeah.

1462
01:06:03,080 --> 01:06:03,580
 [INAUDIBLE]

1463
01:06:03,580 --> 01:06:04,080
 Yeah.

1464
01:06:04,080 --> 01:06:04,580
 [INAUDIBLE]

1465
01:06:04,580 --> 01:06:05,080
 Yeah.

1466
01:06:05,080 --> 01:06:05,580
 [INAUDIBLE]

1467
01:06:05,580 --> 01:06:06,080
 Yeah.

1468
01:06:06,080 --> 01:06:06,580
 [INAUDIBLE]

1469
01:06:06,580 --> 01:06:07,080
 Yeah.

1470
01:06:07,080 --> 01:06:07,580
 [INAUDIBLE]

1471
01:06:07,580 --> 01:06:08,080
 Yeah.

1472
01:06:08,080 --> 01:06:08,580
 [INAUDIBLE]

1473
01:06:08,580 --> 01:06:09,080
 Yeah.

1474
01:06:09,080 --> 01:06:09,580
 [INAUDIBLE]

1475
01:06:09,580 --> 01:06:10,080
 Yeah.

1476
01:06:10,080 --> 01:06:10,580
 [INAUDIBLE]

1477
01:06:10,580 --> 01:06:11,080
 Yeah.

1478
01:06:11,080 --> 01:06:11,580
 [INAUDIBLE]

1479
01:06:11,580 --> 01:06:12,080
 Yeah.

1480
01:06:12,080 --> 01:06:12,580
 [INAUDIBLE]

1481
01:06:12,580 --> 01:06:13,080
 Yeah.

1482
01:06:13,080 --> 01:06:13,580
 [INAUDIBLE]

1483
01:06:13,580 --> 01:06:14,080
 Yeah.

1484
01:06:14,080 --> 01:06:14,580
 [INAUDIBLE]

1485
01:06:14,580 --> 01:06:15,080
 Yeah.

1486
01:06:15,080 --> 01:06:15,580
 [INAUDIBLE]

1487
01:06:15,580 --> 01:06:16,080
 Yeah.

1488
01:06:16,080 --> 01:06:16,580
 [INAUDIBLE]

1489
01:06:16,580 --> 01:06:17,080
 Yeah.

1490
01:06:17,080 --> 01:06:17,580
 [INAUDIBLE]

1491
01:06:17,580 --> 01:06:18,080
 Yeah.

1492
01:06:18,080 --> 01:06:18,580
 [INAUDIBLE]

1493
01:06:18,580 --> 01:06:19,080
 Yeah.

1494
01:06:19,080 --> 01:06:19,580
 [INAUDIBLE]

1495
01:06:19,580 --> 01:06:20,080
 Yeah.

1496
01:06:20,080 --> 01:06:20,580
 [INAUDIBLE]

1497
01:06:20,580 --> 01:06:21,080
 Yeah.

1498
01:06:21,080 --> 01:06:21,580
 [INAUDIBLE]

1499
01:06:21,580 --> 01:06:22,080
 Yeah.

1500
01:06:22,080 --> 01:06:22,580
 [INAUDIBLE]

1501
01:06:22,580 --> 01:06:23,080
 Yeah.

1502
01:06:23,080 --> 01:06:23,580
 [INAUDIBLE]

1503
01:06:23,580 --> 01:06:24,080
 Yeah.

1504
01:06:24,080 --> 01:06:24,580
 [INAUDIBLE]

1505
01:06:24,580 --> 01:06:25,080
 Yeah.

1506
01:06:25,080 --> 01:06:25,580
 [INAUDIBLE]

1507
01:06:25,580 --> 01:06:26,080
 Yeah.

1508
01:06:26,080 --> 01:06:35,580
 [INAUDIBLE]

1509
01:06:35,580 --> 01:06:40,780
 So Drake tries to be actually-- so Drake started as a research

1510
01:06:40,780 --> 01:06:42,540
 project in my group.

1511
01:06:42,540 --> 01:06:44,660
 It grew when Toyota Research started.

1512
01:06:44,660 --> 01:06:47,180
 It became a professional software project.

1513
01:06:47,180 --> 01:06:51,100
 And now it's actually used by lots of companies also.

1514
01:06:51,100 --> 01:06:54,740
 Companies are much more conservative than academics

1515
01:06:54,740 --> 01:06:56,500
 about licenses and everything like this.

1516
01:06:56,500 --> 01:07:00,660
 So we use third-party tools when we can.

1517
01:07:00,660 --> 01:07:02,620
 But we're pretty strict about the licenses.

1518
01:07:02,620 --> 01:07:04,160
 So that does limit us to some extent.

1519
01:07:04,160 --> 01:07:07,060
 If someone GPLs their code, I won't use it in Drake,

1520
01:07:07,060 --> 01:07:08,140
 for instance.

1521
01:07:08,140 --> 01:07:11,820
 So we provide most everything you need,

1522
01:07:11,820 --> 01:07:13,480
 sometimes through third-party libraries

1523
01:07:13,480 --> 01:07:15,140
 that you shouldn't have to think about.

1524
01:07:15,140 --> 01:07:17,860
 And the course, all the perception planning and control

1525
01:07:17,860 --> 01:07:20,540
 stuff will live inside--

1526
01:07:20,540 --> 01:07:21,780
 will be available for you.

1527
01:07:21,780 --> 01:07:23,900
 You might find something that we can't do yet.

1528
01:07:23,900 --> 01:07:26,700
 But we can get through a lot of pretty cool stuff in the class

1529
01:07:26,700 --> 01:07:28,860
 with the provided functionality.

1530
01:07:28,860 --> 01:07:32,220
 PyTorch, for instance, you can make a thin wrapper

1531
01:07:32,220 --> 01:07:33,580
 around PyTorch, for instance.

1532
01:07:33,580 --> 01:07:34,840
 We didn't re-implement PyTorch.

1533
01:07:34,840 --> 01:07:37,820
 Right.

1534
01:07:37,820 --> 01:07:44,300
 [INAUDIBLE]

1535
01:07:44,300 --> 01:07:46,900
 Gazebo is the simulator component

1536
01:07:46,900 --> 01:07:48,500
 in the ROS ecosystem.

1537
01:07:48,500 --> 01:07:49,780
 It's the most famous one.

1538
01:07:49,780 --> 01:07:52,500
 Other things can plug into.

1539
01:07:52,500 --> 01:07:54,380
 Gazebo did a lot of important things.

1540
01:07:54,380 --> 01:07:57,700
 It helped us find different description formats

1541
01:07:57,700 --> 01:07:59,780
 and everything like that, and can import the scene

1542
01:07:59,780 --> 01:08:02,260
 and similarly send ROS messages.

1543
01:08:02,260 --> 01:08:05,940
 Drake could be used instead of Gazebo.

1544
01:08:05,940 --> 01:08:07,480
 We've been talking to those folks

1545
01:08:07,480 --> 01:08:09,860
 about possibly having Drake be the physics engine inside

1546
01:08:09,860 --> 01:08:10,380
 Gazebo.

1547
01:08:10,380 --> 01:08:12,300
 The relationship is-- they're solving

1548
01:08:12,300 --> 01:08:14,420
 similar parts of the problem.

1549
01:08:14,420 --> 01:08:15,860
 But you could just--

1550
01:08:15,860 --> 01:08:17,300
 we don't use Gazebo in the class.

1551
01:08:17,300 --> 01:08:20,340
 And we can do all the things that you would want to do.

1552
01:08:20,340 --> 01:08:24,060
 [INAUDIBLE]

1553
01:08:24,060 --> 01:08:25,260
 So for the class--

1554
01:08:25,260 --> 01:08:27,580
 so you can choose to download and install locally.

1555
01:08:27,580 --> 01:08:30,460
 It's actually probably a better experience in terms of like,

1556
01:08:30,460 --> 01:08:33,240
 you can use your local IDE, your software development

1557
01:08:33,240 --> 01:08:34,580
 environment.

1558
01:08:34,580 --> 01:08:38,100
 But for the class, we have it all using DeepNote.

1559
01:08:38,100 --> 01:08:41,400
 So it'll just run on a Python notebook in the sky,

1560
01:08:41,400 --> 01:08:43,020
 and you don't have to install anything.

1561
01:08:43,020 --> 01:08:46,020
 That way, no matter what people have for their computing

1562
01:08:46,020 --> 01:08:48,500
 devices, it'll work.

1563
01:08:48,500 --> 01:08:50,580
 But it'll typically-- a lot of things

1564
01:08:50,580 --> 01:08:53,220
 will run on a single core, unless you get fancier

1565
01:08:53,220 --> 01:08:55,660
 and run locally and turn on multithreading and stuff

1566
01:08:55,660 --> 01:08:57,860
 like that.

1567
01:08:57,860 --> 01:09:00,900
 There are limits to what we can do on DeepNote.

1568
01:09:00,900 --> 01:09:01,820
 Awesome questions.

1569
01:09:01,820 --> 01:09:02,420
 Thank you, guys.

1570
01:09:02,420 --> 01:09:03,220
 OK.

1571
01:09:03,220 --> 01:09:05,220
 Let me think about what I still have time for.

1572
01:09:05,220 --> 01:09:14,660
 OK, so I think that was a fair representation of the sort

1573
01:09:14,660 --> 01:09:19,340
 of why I'm trying to think about the complexity of manipulation

1574
01:09:19,340 --> 01:09:22,540
 through the signals and systems perspective.

1575
01:09:22,540 --> 01:09:25,660
 And I would say some people think

1576
01:09:25,660 --> 01:09:26,980
 that manipulation is too complex.

1577
01:09:26,980 --> 01:09:29,320
 You shouldn't bother trying to write differential equations

1578
01:09:29,320 --> 01:09:30,020
 to describe it.

1579
01:09:30,020 --> 01:09:31,700
 Like, what benefit are you going to have?

1580
01:09:31,700 --> 01:09:33,260
 It's just so complex.

1581
01:09:33,260 --> 01:09:36,100
 And I feel differently.

1582
01:09:36,100 --> 01:09:38,820
 I feel like it's so complex that we

1583
01:09:38,820 --> 01:09:41,780
 must be careful about writing the low-level systems.

1584
01:09:41,780 --> 01:09:43,220
 Otherwise, there's no chance we're

1585
01:09:43,220 --> 01:09:45,020
 going to understand the high-level systems.

1586
01:09:45,020 --> 01:09:47,420
 And I think as you get to greater levels of maturity,

1587
01:09:47,420 --> 01:09:48,420
 as companies--

1588
01:09:48,420 --> 01:09:50,380
 like, a lot of companies will start with ROS.

1589
01:09:50,380 --> 01:09:53,020
 I think-- so ROS 2 is trying to make a much harder case.

1590
01:09:53,020 --> 01:09:55,540
 But a lot of times, you can bring something up very quickly

1591
01:09:55,540 --> 01:09:56,340
 in ROS.

1592
01:09:56,340 --> 01:09:58,880
 But when you're trying to certify something or get

1593
01:09:58,880 --> 01:10:00,980
 to a higher level of maturity, then

1594
01:10:00,980 --> 01:10:03,220
 not being able to control message-passing rates

1595
01:10:03,220 --> 01:10:05,980
 or other thing in detail becomes a limitation.

1596
01:10:05,980 --> 01:10:08,420
 And if you get to a higher level of maturity,

1597
01:10:08,420 --> 01:10:10,340
 having all your state declared, knowing

1598
01:10:10,340 --> 01:10:12,860
 you're going to get exactly deterministic replays,

1599
01:10:12,860 --> 01:10:15,980
 that's a powerful feature that you just cannot get in ROS.

1600
01:10:15,980 --> 01:10:17,900
 So that's one thing--

1601
01:10:17,900 --> 01:10:20,900
 in Gazebo, in ROS, it's not a knock.

1602
01:10:20,900 --> 01:10:25,040
 It's just the nature of choosing that path

1603
01:10:25,040 --> 01:10:28,500
 is that you will probably never get the same simulation twice.

1604
01:10:28,500 --> 01:10:30,380
 Simulation should be repeatable, right?

1605
01:10:30,380 --> 01:10:33,980
 But if you put in the middle of it message-passing, which

1606
01:10:33,980 --> 01:10:36,940
 is depending on operating system threads coming in and out

1607
01:10:36,940 --> 01:10:40,100
 at certain timing, it is very hard.

1608
01:10:40,100 --> 01:10:42,540
 You can build wrappers around it to synchronize everything.

1609
01:10:42,540 --> 01:10:44,700
 It's a lot of work, but you can do that.

1610
01:10:44,700 --> 01:10:49,820
 But the fact is you can't run the same experiment twice.

1611
01:10:49,820 --> 01:10:52,020
 The simulation will be slightly different every time.

1612
01:10:52,020 --> 01:10:55,380
 So it makes it harder to debug, harder to certify.

1613
01:10:55,380 --> 01:10:57,740
 If you declare extra state and everything like this,

1614
01:10:57,740 --> 01:10:58,300
 then you can.

1615
01:10:58,300 --> 01:11:04,980
 OK, yeah, so the basic plan for the course is--

1616
01:11:04,980 --> 01:11:06,020
 I'll finish up here.

1617
01:11:06,020 --> 01:11:09,900
 Let me take one second to start the robot booting again

1618
01:11:09,900 --> 01:11:11,260
 so I don't have to wait too long.

1619
01:11:11,260 --> 01:11:18,340
 Takes too long to start.

1620
01:11:18,340 --> 01:11:38,860
 Cool, I'll be able to walk home in 10 minutes.

1621
01:11:38,860 --> 01:11:40,740
 OK, so the basic plan for the course

1622
01:11:40,740 --> 01:11:44,340
 is to go through that ladder of complexity.

1623
01:11:44,340 --> 01:11:48,460
 This is why I didn't leave it on the whole time.

1624
01:11:48,460 --> 01:11:51,260
 We're going to talk about perception systems,

1625
01:11:51,260 --> 01:11:54,620
 sometimes by themselves.

1626
01:11:54,620 --> 01:11:59,260
 But we'll try to break the distinction.

1627
01:11:59,260 --> 01:12:07,260
 We'll have some lectures on perception for sure.

1628
01:12:08,260 --> 01:12:12,620
 We'll do both the geometric perception,

1629
01:12:12,620 --> 01:12:14,820
 which can get you pretty far and gives you

1630
01:12:14,820 --> 01:12:21,460
 some of the core skills from kinematics and geometry

1631
01:12:21,460 --> 01:12:22,980
 that are relevant.

1632
01:12:22,980 --> 01:12:26,180
 Geometric perception is one way to think about it.

1633
01:12:26,180 --> 01:12:32,780
 And then deep learning based or data driven perception

1634
01:12:32,780 --> 01:12:36,300
 will certainly be a topic also.

1635
01:12:36,300 --> 01:12:39,580
 We'll do kinematics and dynamics and motion planning,

1636
01:12:39,580 --> 01:12:40,260
 for instance.

1637
01:12:40,260 --> 01:12:48,900
 We'll definitely talk about some dynamics and control.

1638
01:12:48,900 --> 01:13:00,580
 Spoiler alert, big robots touching small objects

1639
01:13:00,580 --> 01:13:01,860
 is pretty--

1640
01:13:01,860 --> 01:13:02,860
 gets pretty complicated.

1641
01:13:02,860 --> 01:13:04,740
 Contact mechanics is tough.

1642
01:13:04,740 --> 01:13:09,020
 We'll spend a bit diving into the contact mechanics world.

1643
01:13:09,020 --> 01:13:13,340
 And we'll do some higher level task planning.

1644
01:13:13,340 --> 01:13:21,740
 But my goal is not to just say the first quarter of the term

1645
01:13:21,740 --> 01:13:23,580
 is perception, the next quarter of the term

1646
01:13:23,580 --> 01:13:27,260
 is motion planning, and so on.

1647
01:13:27,260 --> 01:13:30,500
 What I'm going to try to do is build a manipulation system

1648
01:13:30,500 --> 01:13:34,300
 that can do a full stack task.

1649
01:13:34,300 --> 01:13:36,940
 Move all the objects in this bin over to this bin,

1650
01:13:36,940 --> 01:13:38,660
 even if you throw in random objects.

1651
01:13:38,660 --> 01:13:41,100
 That'll be one of the things we build up.

1652
01:13:41,100 --> 01:13:42,660
 And we'll build a basic competency

1653
01:13:42,660 --> 01:13:45,220
 of in perception, planning, dynamics, and control

1654
01:13:45,220 --> 01:13:47,340
 to accomplish that task.

1655
01:13:47,340 --> 01:13:48,980
 And then we'll spiral out.

1656
01:13:48,980 --> 01:13:52,460
 And we'll try to introduce the new concepts to do

1657
01:13:52,460 --> 01:13:55,820
 more complicated things if it makes our robot capable

1658
01:13:55,820 --> 01:13:59,140
 of doing something new.

1659
01:13:59,140 --> 01:14:02,140
 I'm going to try to put in more mobile manipulation this time,

1660
01:14:02,140 --> 01:14:03,380
 because I think it's awesome.

1661
01:14:03,380 --> 01:14:05,660
 You can do it on your project.

1662
01:14:05,660 --> 01:14:07,900
 And then at the end, we'll have a handful

1663
01:14:07,900 --> 01:14:10,620
 of lectures that are more like the research topics,

1664
01:14:10,620 --> 01:14:13,820
 the boutique lectures we call them.

1665
01:14:13,820 --> 01:14:15,780
 And I'll query you guys throughout the term

1666
01:14:15,780 --> 01:14:17,140
 about what you're interested in.

1667
01:14:17,140 --> 01:14:19,940
 But if we want to dive in and talk about what does it

1668
01:14:19,940 --> 01:14:22,020
 look like to think about belief space planning

1669
01:14:22,020 --> 01:14:23,620
 or manipulation?

1670
01:14:23,620 --> 01:14:26,120
 What does it look like if we're going to think about tactile

1671
01:14:26,120 --> 01:14:28,780
 sensors for a lecture?

1672
01:14:28,780 --> 01:14:30,300
 And we'll have a handful of options

1673
01:14:30,300 --> 01:14:32,540
 that we can pick from to do the last lectures

1674
01:14:32,540 --> 01:14:34,340
 while you're focused on your project

1675
01:14:34,340 --> 01:14:36,660
 and not listening to me so much.

1676
01:14:36,660 --> 01:14:40,060
 We'll talk about the more research threads.

1677
01:14:40,060 --> 01:14:41,380
 Cool?

1678
01:14:41,380 --> 01:14:42,300
 OK.

1679
01:14:42,300 --> 01:14:43,820
 That's the plan for the course.

1680
01:14:43,820 --> 01:14:44,780
 I hope you keep coming.

1681
01:14:44,780 --> 01:14:47,980
 Thank you for sitting in the crowded room.

1682
01:14:47,980 --> 01:14:50,900
 We'll see you next time.

1683
01:14:50,900 --> 01:14:52,820
 Make sure you sign on to Piazza, please.

1684
01:14:52,820 --> 01:15:00,060
 How's it going?

1685
01:15:00,060 --> 01:15:00,560
 It's good.

1686
01:15:00,560 --> 01:15:02,520
 I was wondering if you-- have you heard of RT2?

1687
01:15:02,520 --> 01:15:03,260
 I can't spell it.

1688
01:15:03,260 --> 01:15:04,020
 Of course, yeah.

1689
01:15:04,020 --> 01:15:07,140
 Do you think that's sort of the future of standard

1690
01:15:07,140 --> 01:15:08,780
 [INAUDIBLE]

1691
01:15:08,780 --> 01:15:11,820
 I think RT2 is good.

1692
01:15:11,820 --> 01:15:15,660
 But I think it's the beginning of a future.

1693
01:15:15,660 --> 01:15:17,660
 But I think we're still in the place where

1694
01:15:17,660 --> 01:15:20,280
 we're taking what's amazing about language models

1695
01:15:20,280 --> 01:15:22,540
 and kind of bolting on the robot.

1696
01:15:22,540 --> 01:15:25,940
 And I think there's going to be a future where the robot

1697
01:15:25,940 --> 01:15:29,780
 data plays a bigger role in the common sense understanding.

1698
01:15:29,780 --> 01:15:33,500
 So yeah, I think a lot of the world is seeing--

1699
01:15:33,500 --> 01:15:35,960
 I think that most of the good things that are good about RT2

1700
01:15:35,960 --> 01:15:37,580
 are good because of the language model.

1701
01:15:37,580 --> 01:15:38,580
 Yeah.

1702
01:15:38,580 --> 01:15:41,380
 And the robot hasn't added extra problems

1703
01:15:41,380 --> 01:15:44,220
 with information at some point.

