 (audience chattering)
 - Okay, welcome everybody.
 Thank you for approximately 60 of you showing up
 and thank you to those of you that put up with the fact
 that we don't have a big enough room today.
 We really are trying to resolve it.
 Everybody across, I mean, I've heard about 200 people
 classes that have a 60 person class.
 I've heard all kinds of different problems.
 The institute is trying to juggle,
 the department is certainly trying to juggle
 and I hope we have it resolved by Tuesday, we'll see.
 But thank you for putting up with this today.
 So I'm Russ Tedrick.
 It's actually nice to see,
 some of you I've seen only via Zoom
 and it's nice to see you in person.
 So you do exist and I exist.
 I'm really happy to be back in the room.
 I think just even with the masks,
 just to be able to see people's reactions
 and I will teach better I think
 when I can feel if you guys are getting it or not.
 Let me just start with a little bit of sort of course intro.
 So we're gonna be talking about robotic manipulation.
 I'm gonna tell you what I mean by manipulation,
 which is not obvious.
 Even if you're a robotics expert,
 I think people mean different things
 when they think about manipulation.
 But let me just start by introducing Rachel and Danny
 who are gonna be our TAs for the course.
 In fact, there's so many people that signed up
 that we could potentially have one more TA.
 We'll see if anybody, see how that plays out.
 But Rachel and Danny are fantastic.
 You will find them to be excellent resources.
 So hopefully you'll have found the website.
 It's not too hard to remember the name I hope.
 But we've put basically, we're doing paperless
 and all of the information, all the guidelines,
 the grading rubrics,
 the things that I am officially giving you today,
 I'm giving you through the website.
 One of the big things that changed,
 this is the first time the course has an official number.
 If you're an undergrad and signed up
 as the undergrad version of the class,
 then it's 6.800.
 If you're a grad student or if you're an undergrad
 who wanted to take the grad version of the class,
 it's 6.843.
 The amount of complexity I think,
 from your perspective I hope is very small.
 But from my perspective it was extremely large
 because there's getting all the different symbols
 of can it count for an AAGS, can it count for an II,
 can it count for, I think we got them all.
 If you have any questions about the logistics
 and does it count for X, Y, or Z, feel free to ask.
 I did my very best to get them all.
 One of the things that it does count for,
 which is a big deal for me,
 is that it counts as a CIM for undergrads.
 So it's a communication intensive class now.
 Now the reason for that if you're interested
 is because the department is changing.
 We now have electrical engineering, computer science,
 and a new fraction of the department called AI+D,
 artificial intelligence and decision making.
 And so if we look at our total coverage of classes
 in the department, we wanted to make sure
 that there were enough communication intensive classes
 in all of three and there weren't yet enough in AI+D.
 So we looked around and decided this would be a good class
 since we already have a project that is,
 I think a substantial part of the class.
 We can use our help from the communications department
 and the comparative media studies and writing.
 Laura and Nora will be helping us out
 on the Friday recitations.
 And we're basically, for undergrads taking the class
 of 6.800, think of it as doing a super project
 where we're gonna do a little bit more
 in terms of giving you feedback on the proposal,
 helping to shape the technical argument
 that you're gonna make throughout the actual course
 of the proposal, give you more feedback,
 and expect a higher quality of presentation
 in the final result and you get to count it
 as one of your communication requirements.
 There's also a little bit, before we start the project,
 there'll be a bit of a journal club
 to sort of even understand what it looks like
 to have a good paper.
 So I believe very much in how important it is
 to communicate clearly and I actually would say
 that I'm a little worried about the field right now
 as being kind of, it's exciting and new
 and everybody's publishing but the quality is
 a little bit, you know, in flux, let's say.
 So I actually think it's a great time for us to say,
 hey, what does it look like to have a good paper
 and how do you do an excellent piece of work
 in manipulation?
 So you will meet Laura and Nora soon.
 They probably stayed back because it was crowded today.
 So I hope that all of the distinctions
 between 800 and 843 are carefully articulated
 on the website.
 Try to get all those things right,
 including the slightly different rate distributions
 from 843 to the 800.
 If you were to even scroll up a little bit,
 you'll see there's all of the details about,
 you know, does it count for II, does it count for AGS?
 I tried to get them all on there, okay?
 So if you have any questions about that,
 by all means, just ask but I hope it's clear
 and I hope that it's minimal complexity
 from your perspective.
 I'm excited, I think it's a great opportunity
 for the class.
 Okay, so, you know, the base,
 I'm not gonna spend too much of our time here on logistics
 but just to put them up.
 So our primary means to broadcast to you is through Piazza.
 So you should be able to sign on automatically
 if you have an MIT email address,
 if you're registered for the course
 and you don't have an MIT email address,
 we can add you, no problem.
 You know, officially, I'm only distributing
 the course guidelines through the website.
 So please do take a minute to review them
 if you have any questions about anything,
 anything's unclear, by all means,
 we're ready to answer those questions now.
 I've done a lot of work to try to make
 the lecture notes interactive.
 Actually, some of the, you know,
 there's some advantages to having had a remote Zoom year.
 I spent a lot of time making like interactive graphics
 and things that would work over Zoom.
 And, you know, I don't get to use all of them this year
 but some of them I hope will still be
 a useful set of tools.
 But in particular, you'll see that the lecture notes
 are interactive, you can actually ask questions
 kind of like a Google Doc where you can comment
 and everything like that.
 You can ask questions right on the lecture notes.
 And the lecture notes have interactive simulations
 and visualizations that I hope will help you
 understand the material, that's my goal.
 The basic setup is we'll do a slightly higher cadence
 of smaller problem sets than I've done in the past
 where we'd like to have weekly problem sets
 that, you know, just kind of keep you thinking
 about the course but aren't as heavy
 as some of the previous versions.
 And the big focus for the course is really
 on the final project where we get,
 we're gonna try to give you, you know,
 a good set of examples to work from,
 but this is a chance to really explore
 the diverse range of possible projects and manipulation.
 This is just to show you what that annotation tool
 looks like and everything.
 If you were to look at the course notes,
 then you'll see a bunch of different features
 like the fact that you can comment in the top,
 on the, you know, in the top corner,
 this opens up the comments and you can highlight
 and add comments and the like as you look at the text.
 We'll see, I think it's still an experiment
 in terms of, you know, is that the great way to communicate?
 But I kind of believe that textbooks
 aren't gonna look the same in a few years as they do today,
 and this is maybe my experiment
 in trying to go halfway there.
 And let's, I'll just show you,
 if you click on launch in DeepNote, this is different.
 Some of you who've seen me before have tried Colab.
 I'm trying DeepNote this time.
 I wrote a lot of code in the last few weeks
 to try to make this work.
 There's a small chance that I don't,
 that I missed something or that DeepNote
 isn't quite as robust or something as I hoped,
 but let's hope that this works very, very well.
 I think it's, I hope it will be better
 for the class than Colab.
 And just to give you a quick preview
 of what that looks like,
 so if you were to run the notebook from the first,
 from the first lecture, from the first chapter,
 then you can just run the notebook.
 Your experience will be less haphazard than mine,
 but I'm doing it halfway here.
 Okay, so this is now running a simulation
 on the cloud in DeepNote,
 and it's a fully interactive, full physics simulation
 that you will be able to program and everything,
 but it's got, you know, you can tally operate
 and your robot in the first example,
 and just to prove to you
 that it's a full physics simulation,
 I will pick up the block.
 Oops.
 Maybe I won't, 'cause I jammed my hand into the thing, yeah.
 Anyhow.
 Oh!
 (audience laughing)
 I must have jammed it so hard that I knocked it sideways,
 and it's a planar simulation, but.
 It's also, it's actually a full 3D simulation.
 I think it'll load up now, the 3D version, as soon as I.
 So the fact that we can sort of do this,
 that we can have, there was a time
 where I was trying to put some of the software tools
 and make them available for class,
 and spent a long time working with people.
 How do you install this?
 How do you install that?
 Nowadays, you just open a website,
 and all of the controls and everything are just,
 you know, they're in your browser.
 No install whatsoever.
 You can just run everything remotely.
 You can collaborate in the notebooks in DeepNote
 in ways that you couldn't in Colab,
 but also it's just provisioned differently,
 and I hope I won't be chasing fires
 as Colab upgrades versions and stuff like this.
 I think DeepNote will be a better solution.
 So I hope that works great for you,
 and I would welcome your feedback.
 I would actually say the fact that simulation
 has gotten so good is one of the big reasons
 why I think it's a great time to teach this class,
 is that the fact that you can actually study
 manipulation in simulation, it's a new thing.
 I mean, just a few years ago, people would have said,
 "No way you can do a practical experiment
 "with manipulation.
 "It's too dependent on contact mechanics,
 "which we don't simulate well,
 "and it's too dependent on perception,
 "where we don't simulate cameras well."
 But I think between a combination
 of the contact simulation getting a lot better,
 and game quality engine rendering getting good enough,
 and people believing that you can actually
 train a perception system in simulated images,
 and have it work in reality, it has closed that gap.
 And now we really can do real work.
 In fact, most of our real work on robots,
 we do primarily in simulation,
 and it's only at the end do we actually make sure it works.
 And we're constantly working to close the gap,
 but increasingly more and more of our time
 is spent in simulation.
 So it's a good time.
 We actually do have hardware robots
 that look just like that upstairs in the room.
 We have quite a, not a ton,
 but we have quite a few of them thinking that we had,
 'cause there was an early version of this course
 that I taught with hardware as part of the experiments,
 or part of the, that we had labs.
 It was enrollment limited back then,
 because of limited hardware.
 So we decided to not limit enrollment this time,
 but if people get ambitious and have good projects,
 and wanna try some things on the real hardware,
 we do have robotic arms upstairs ready to go.
 And if you convince me in simulation
 that you're not gonna break my robot,
 then they are available.
 And this is just to show that those kind of simulations,
 they really just do run in the browser,
 and you can embed them in your slides if you want.
 And it was a lot of work,
 but I think it's a cool technology.
 Okay.
 That's the setup.
 So I wanna talk today about,
 what do I mean by manipulation?
 What are you gonna get out of the course?
 I wanna spend just a little bit of time
 talking about why, you know,
 some of the machinery that we will use
 from dynamical systems,
 to, and why I think it's the right machinery
 to span the spectrum from feedback control to perception,
 and even task level planning.
 And then once we have that machinery,
 I'll just give you a whirlwind of the kind of things
 we're gonna build on top of that machinery
 in terms of perception systems,
 and control systems, and the like.
 And end with some goals for the course,
 so you have a sense of what the roadmap is
 for the rest of the term.
 Okay, what do I mean by manipulation?
 Right, so Matt Mason, actually,
 who's one of the, you know, actually,
 yes, one of Rachel's former advisors in a way,
 and one of the founders in the field.
 He's at Carnegie Mellon these days,
 and Berkshire Gray.
 He wrote a great survey paper toward robotic manipulation.
 It's a, you know, it's a fantastic read.
 It's referenced also in the text.
 But one of the things I liked that he did in that paper
 was he tried to define manipulation,
 which people don't do so carefully, right?
 But he refused to give just one definition.
 He gave like five, and they were all, you know.
 I won't give all of them.
 But he started with just manipulation
 refers to activities performed by hands.
 Okay, that's sort of a simple one.
 By the way, I felt that I had to call
 the class robotic manipulation,
 just so that, you know, a non-roboticist
 who stumbled on the website didn't think we were,
 you know, trying to affect politics or anything like that.
 Right, so, but in this room,
 we'll just say manipulation and call it good.
 Let's see, so Matt Mason,
 and our manipulation is about activities performed by hands.
 And he gives a series of other sort of definitions,
 but they all kind of build up to this idea
 that really manipulation refers to an agent's control
 of its environment through selective contact.
 Okay, so some people debate about
 whether leg and locomotion and manipulation
 are the same thing, walking his legs upside down.
 You know, they do certainly have a lot in common.
 They also have different points of emphasis.
 I'm originally someone who worked a lot on legged robots,
 and I'm focusing on manipulation more these days.
 But that is a really, I think, good definition
 and important definition.
 I'd say even a defining definition, right?
 So compared to a lot of robotics,
 I mean, so our UAVs are just fantastically cool
 and good these days,
 and the things that you can do with a drone
 is just out of this world.
 But maybe we haven't fully realized the dream of robotics
 if we're not touching the world.
 You know, so making, you know,
 selective contact with the world,
 I think, is one of the charters of robotics.
 And I think compared to locomotion,
 I'll try to say in a few examples,
 I think compared to locomotion,
 the connections to perception for manipulation
 are much stronger, much deeper,
 and that'll be a big topic in the course.
 Now, another group of people, I think,
 hear manipulation and think of sort of this kind of example,
 the one I just sort of tele-opted badly,
 where you have, you know, a robot
 that's just picking and placing things in the world.
 Maybe the world is simple,
 like the old way that robots were in factories.
 Increasingly, we're trying to make them work
 in much messier situations.
 But for me, it's very important that you come away
 thinking that manipulation is much more than pick and place.
 Okay, so it is true that you can do manipulation
 by getting a situation where you can make
 what we call an enveloping grasp.
 You know, get your hand around and grab something
 and then roughly assume it's welded to your hand,
 move your robot around the way it did and drop it off.
 You've accomplished manipulation.
 But this is a small sliver
 of what humans can do with their hands
 and really not the full glory
 that we're trying to achieve in the class.
 I would like much more to come from our systems,
 you know, just as a fun example,
 you know, this is a lot more than pick and place, right?
 And we still don't have robots that can do this, right?
 So I'm not promising that this will be like lecture four,
 but this is tough stuff, right?
 And I mean, just even thinking about
 how I would simulate the string is pretty tough.
 The contact mechanics between those fingers
 and the string, the topological planning
 that we're doing here, you know,
 this is the good stuff, okay?
 And I would actually think,
 even, I mean, of course, tying your shoes
 is one thing that we do with our hands,
 but I would argue that most of the things
 you do with your hands have some of the characteristics
 of this and don't look as much like the, you know,
 grab the thing, make sure it's welded to my hand
 and move through the world.
 I think we're actually, as humans,
 rarely doing the simple version.
 (papers rustling)
 So one of the things that's great about manipulation
 is that it really does, if you care about AI,
 and you care about, and maybe believe like I do,
 that for AI to be complete,
 we have to somehow embody it in the world.
 Manipulation really connects a lot of the higher level
 task reasoning, scene understanding problems
 in artificial intelligence
 with some of the low level dynamics and controls
 that I love.
 So I can tell that quickly in just one example
 that we've spent a lot of time on,
 which is a robot that can load the dishwasher, okay?
 So if you just think, what would it take to program a system
 so that Siwon can dump whatever he wants in the sink,
 including some plates and some mugs and some spoons,
 and the robot could go from there to a robust system
 that can open and close the dishwasher,
 it can pull mugs and plates out of the sink,
 put the mugs in the top rack,
 put the plates in the bottom rack,
 put the silverware in the little slidey drawer thing
 that some of our dishwashers have these days,
 and discard anything else off to the side.
 There's a lot going on in here.
 I mean, first of all, you should ask,
 why is it even setting things down on the countertop?
 We'll talk more about that later,
 but actually, one of the biggest reasons for that
 is because the hand is too clunky.
 It's not a very dexterous hand.
 So it's very hard, you can't do in-hand reorientation
 very well with a two-fingered gripper.
 So we end up having to set it down
 in order to grab it again,
 in order to put it down in an orientation
 that's suitable for the dishwasher.
 Another reason for that is that the hand
 is just big and clunky,
 and it occludes all of our cameras
 when we stick it down into the sink.
 So sometimes we grab something,
 and we just wanna make sure we grab
 what we thought we grabbed, so we set it down,
 and we move our hand away,
 and make sure that the cameras can see it,
 and then we can finish.
 So to get a high level of robustness in that system,
 today, we needed to drop things off on the countertop
 in order to go all the way there.
 We've got versions that don't have to do that,
 but it's maybe a small window
 into how complex the problems are.
 There's a lot going on in that example.
 There's a lot of different,
 say, maybe feedback skills in terms of motion planning
 and control of how it has to open the dishwasher,
 how it can pick things up,
 how it can maybe nudge things out of the corner.
 That's another problem.
 The hand is so big that if there's an object
 down in the corner of the sink,
 it can't do an enveloping grasp.
 It has to nudge it back into the center,
 get its hand around it in order to pick it up.
 Okay?
 And there's some of this multi-contact selective contact
 that's pretty complicated, pretty subtle.
 So like the hand in order to pick up a plate from a stack
 has to kind of slide its fingers between the plates
 in order to do it.
 This is also a demonstration of how simulation and reality
 are increasingly close.
 (clears throat)
 And this is actually, I forgot to autoplay this.
 This is, so this is roughly the same kind of simulation,
 but it's rendered nicely this time.
 So when we're working on our feedback controllers,
 we don't bother to send the images
 through a blender rendering scheme.
 But if we're training our perception systems,
 then we do the extra step of trying to make
 a visually realistic render of the scene.
 And it's just incredible what you can do
 if you put all the tools together.
 So that's a dexterous hand picking up the plate,
 but that's a simulation.
 Looks pretty, to my eyes, it looks pretty darn good.
 There's like a few artifacts that you can see
 and realize it's a simulation,
 but it looks pretty darn good.
 And it's good enough to trick
 the deep learning systems these days.
 So that's, I guess, what matters, right?
 So it's a great time.
 And this is a fun, I think,
 a fun full stack manipulation example.
 It's also got some task level robustness
 in the sense that if it's doing one task
 and someone comes in and antagonizes it,
 it's not quite the same as a Boston Dynamics hockey stick,
 but something like that,
 that it's smart enough to set the mug down.
 So it's got a whole higher level reasoning system
 that's thinking about what it's doing.
 Is it still able to do what it was trying to do?
 And this is just another level of complexity,
 which is a more AI planning level of complexity
 sitting on top of all the feedback control
 and perceptions and everything like that.
 So I really think it does,
 manipulation does a beautiful job
 of forcing you to go up and down the entire stack.
 I made a ladder to say it, right?
 Task level planning at the high level,
 low level perception and control
 to do feedback at the low level.
 And it asks us to span that whole space.
 Right, in general, I think even just connecting
 learning and planning and reasoning systems to physics
 asks you to do, to answer some other basic questions
 that we don't often answer
 in our machine learning pipelines these days.
 Like, oftentimes we're collecting data,
 labeling it offline,
 letting the servers train on the data
 for however long it takes,
 and then taking the output and running it.
 But really cognition is a dynamical system, right?
 We're constant, we should be talking about
 the way that the data enters,
 how do we have a constant stream of data coming in?
 How do we adjust our parameters?
 And I think, you know, asking the questions
 of how does that component actually play out
 all the way down in the physics engine,
 and how do those work together?
 And what are the timing semantics?
 You know, it really begs some of the,
 I think, richer questions that we will be getting into
 as AI and machine learning continues to evolve.
 I come from a bit of a,
 more of dynamics and controls perspective.
 A few of you have taken underactuated with me,
 so from that perspective, you know,
 this class is gonna be different, you know,
 but I wanna make sure I tell you sort of what's,
 you know, point out some of those differences.
 Right, so I worked on humanoid robots.
 This is the Boston Dynamics early version
 of the Atlas robot.
 This is the big clunky one that the new sleek one
 is doing all the dancing and the parkour.
 But we trained it to, we programmed it, I would say,
 to do this disaster response scenario
 for the DARPA Robotics Challenge.
 And in doing that, you know,
 we thought a lot about planning and control,
 and that's, you know, we talk a lot about that
 in underactuated, my other graduate robotics class.
 This is just an example of the feedback control
 that the robot has to do as Andres and Lucas
 jump on the Polaris while the robot's trying to balance
 on one foot because that's how it had to get out
 of the Polaris.
 Okay, so there's a lot of work there
 about just even, you know, stability and balance
 and feedback control.
 Okay, and you might ask, you know,
 does that stuff matter for manipulation, right?
 I'm just picking up red blocks, right?
 And it's a fair question, actually,
 but one of the first things that's different
 is the way that manipulation demands more from you
 from perception.
 So when we were doing perception on Atlas,
 our perception system looked like this, right?
 It would kind of evaluate the world,
 but only in sort of a geometric way, right?
 So it was trying to reason about places it could step,
 places it couldn't step.
 But really, once it got sort of a physical understanding
 of the static world, it could do what it needed to do
 in order to, and it knew a lot about its own body.
 And the control system could be tuned for its own body.
 It can do a lot of what it needed to do.
 If you look at some of the newest videos coming out
 from Boss Dynamics, they're doing a way better job,
 but they're still able to do, they're in a regime,
 you know, this is, let's say, the Atlas doing parkour
 or the Ninja Warrior style gymnastics, right?
 They're still evaluating the world
 because that's all you need to do for locomotion,
 for a lot of locomotion,
 as kind of like understanding the geometry,
 finding the places you can throw your feet down, right?
 What's gonna support my weight?
 Think about, you know, loading the dishwasher, right?
 It's not as cool as doing parkour,
 but it demands a lot more from your perception system
 and the connection between perception and control.
 It just demands a lot more, right?
 So we have to not just understand
 this is the same sort of rendered simulation of the sink.
 There's a bunch of mugs in there.
 This is the output of the perception system
 that's trying to identify places,
 not only that there are mugs in there,
 so there's sort of an object recognition component
 that wasn't necessary for locomotion,
 but there's also, you have to understand
 something about the context of the mug.
 There's a handle over here, the top's on this side,
 the bottom's on this side, right?
 So you could say, oh, that's only a little bit more,
 but it gets way more complicated than that as you go on.
 First of all, the types of mugs you might have to experience
 are just way more diverse, right?
 This is just whatever mugs we found on Amazon,
 but that one's a cow, you know?
 There's, if you go to the Disney store,
 you find all kinds of weird ones, right?
 So how do you have that same level of understanding
 about what's a mug,
 but it has to work for all possible mugs, okay?
 And to do that sort of task
 in order to even just set the mug down
 in the right orientation all the time,
 or know that you can pick it up from a handle,
 that it will support your weight,
 or that you could put the handle on the peg,
 it demands a lot more understanding, if you will,
 between the perception system
 and the lower level control system,
 to the point where I think, from my perspective,
 for controls, I think it really,
 it's the next wave of what controls has to do.
 And I'll say it maybe in a little bit more dramatic fashion
 in a second, but.
 Oops, did that not, fast forward,
 I don't want their advertisement, I want.
 So I think there's still a question, though.
 I showed Atlas balancing,
 and thinking about stability and control.
 A lot of people don't talk
 about feedback control and manipulation.
 And it's a fair question about,
 is it really that important to do feedback control?
 'Cause people do have some incredibly clever designs
 for hands that allow you to do pick and place,
 basically with your eyes closed, and get the job done.
 Okay?
 So I think that is a viable approach
 to a huge class of useful manipulation,
 is to not worry so much about the dynamics of your mug,
 but build a really good end effector.
 And I think it's important,
 and commercially very valuable.
 Okay, but I also think there's a lot going on.
 If you look at human manipulation,
 this is an example, again, from Matt's world,
 of just a high-speed camera
 of somebody in a convenience store, okay?
 And if you watch all the little details
 that we don't even pay attention to,
 'cause it's sort of subconscious,
 but I think when she sets down the dentine,
 it's like, oops, she missed.
 And there's these adjustments that are constantly happening,
 that you see little sliding all the time.
 It's nothing like the (whooshing)
 and then move it around, right?
 It's a much more dynamic process,
 where there's constant tactile feedback, visual feedback,
 constant corrections.
 It makes us way more robust
 and way more diverse in our skills.
 You can find there's a whole bunch of examples,
 but these kind of manipulations,
 the way people manipulate is just so different
 than the way robots picking up red blocks manipulate,
 and we have to get there.
 (mouse clicking)
 So from a feedback control perspective,
 it's about where Atlas, the main job,
 was to figure out what is the state of my robot?
 How do I regulate the state of my robot
 to achieve some task, okay?
 Manipulation is about, okay,
 I do have to move the state of my robot,
 but that's kind of easy, honestly,
 for if I'm bolted to a table, it's not a big deal, okay?
 But I have to somehow control everything else in the world
 through my actuation, and I only get to touch,
 I only get to control the state of the mug through my hands,
 which is through contact.
 So the challenge there is just to extend our thinking
 about feedback control through a contact mechanics interface
 out into the world.
 It's awesome.
 Especially when I don't even know how to write down
 the state for some of these problems, right?
 So if I think about counting the links on my robot,
 that's easy, but if I think about
 what is the state space of the onion as I'm chopping it,
 and does it get bigger every time I make a cut?
 Am I supposed to be keeping track
 of every possible piece of onion
 in order to accomplish the task?
 Most of the things I know about control
 kind of just melt down,
 thinking about how would I do proper control
 on a problem like that?
 But it should be easy.
 Like, that's not a hard problem.
 So for me, I'm super excited about bringing
 some of the rigorous thinking of control theory
 up into the challenges that are just put in our face
 by relatively simple manipulation systems.
 I don't really wanna give robots sharp knives yet,
 but maybe next year.
 So we're seeing in the field,
 more and more examples of feedback control
 that is really using real-time camera perceptual input
 in order to do even relatively simple tasks.
 That wasn't part of the objective, right?
 But where you're starting to see feedback loops
 being controlled through non-trivial perception interfaces,
 where it's really constantly monitoring the environment,
 making feedback corrections, and it's very good.
 This one in particular is using a type of,
 it's a neural network that's looking at images
 through the camera, trying to find corresponding images
 in the new scene.
 We'll talk about the particular details of that
 when we're in the deep learning perception part of the world,
 part of the semester.
 But it's,
 when you do use camera feedback well,
 it can be incredibly robust.
 The same way, for me, this is, I know it's not as cool,
 but this is a little bit like, my network is lagging here.
 For me, this is a little bit like that atlas
 not falling down when we're jumping on the Polaris.
 I know it's just picking up a plate,
 but we're gonna see some, all kinds of variability,
 and the fact that it's doing this just from cameras
 as the primary feedback sensor,
 and it's doing it with all sorts of perturbations,
 and it's a multi-contact task,
 but it's able to be, you know,
 incredibly robust, despite Pete's best efforts
 to mess with it.
 So that's, I think, a humble example of something
 that I hope we see a lot more of in the future.
 If I were to show the less flattering videos
 from the DARPA challenge, you would see, you know,
 the sort of robot air balls, and so, you know,
 the robot going out to reach something,
 and just thinking it had it in its hand,
 continuing the motion, falling over, those kind of,
 you know, we don't want that anymore.
 We wanna close the loop between perception and control.
 And of course, reinforcement learning has come
 into the picture in a big way,
 in terms of how we do these things.
 You can do these kind of tasks.
 This is an example of banging on the simulation
 with a reinforcement learning algorithm
 to accomplish the same task,
 and we're gonna talk through, you know,
 how to understand RL approaches,
 where do they fit into the spectrum, in my view.
 I will admit up front that I don't think
 it solves the whole problem.
 I don't think it's just a matter of getting more data
 or running more simulations, or even if it was,
 you know, I don't think we wanna be in a place
 where programming a robot to load the dishwasher
 requires, you know, hundreds of thousands of dollars
 in an Amazon, you know, AWS bill, or something like that,
 where only the big companies can afford
 to train a system.
 I, we're already going that way in terms of, like,
 our language models and our perception models,
 but manipulation, this should be easy.
 This should totally be easy.
 So we should be able to have better solutions there
 that you can run on your desktop.
 Okay.
 That's what I mean by manipulation.
 Yeah, please.
 - This might be early, probably cover this later,
 but where does reinforcement learning fall?
 Like, what kind of problem does that solve?
 And then, you know, counter to the control problem?
 - Yeah, it's a great question.
 So I think some people, I would say it's a very natural fit
 at the low-level control.
 You could imagine, you know, if you want these controllers
 that are interacting with contact forces
 and coming up with, you know, a policy in RL parlance,
 then I think there's an active debate
 about whether it's better to do that
 with a reinforcement learning technique
 or a model-based technique.
 We'll talk about both.
 As you go up the hierarchy, I think the most,
 the most fully committed people in reinforcement learning
 would say even task-level planning,
 you could do with reinforcement learning.
 I don't go that high on the spectrum.
 I think the higher you go up,
 I think it begs for something that has some level
 of concepts and planning that are harder to represent
 in the reinforcement learning.
 Leslie Kelbling here likes to say, you know,
 if you want, I ask you to book a flight to Paris, right?
 You don't have a policy to book a flight to Paris.
 You're able to like put that, you've never done that before.
 You can do, you can put together new sequences
 that you've never experienced before.
 So I think that doesn't fit as well
 into the reinforcement learning paradigms
 that we have today.
 Now, there's no question that I think reinforcement learning
 encourages us to think about the data that's coming in,
 how do you make use of the data,
 how do you use trial and error?
 That's all good and we should be doing that at every level.
 Right?
 But I think the standard RL toolkit today
 probably fits best in the lower level skills.
 Other questions are good.
 I love questions.
 Cool.
 Let me ask you.
 So how many people have worked on manipulation before?
 Show of hands.
 How many in robotics before?
 How many people have done some other area
 of like, you know, computer vision
 or natural language or something
 and maybe it would be kind of fun
 if we could put that together with robotics.
 Okay, that's good.
 How about from the sort of more mechanical side?
 Few mechanical engineers.
 All right, cool.
 That's good.
 Well, I actually, I see it as a bit of a challenge,
 but I love actually that we get a diverse group
 of people in here.
 So, you know, every once in a while I'll say things
 that you'll have to just nod 'cause you already know that,
 but there's someone else in the room maybe that doesn't,
 but I try to do my best to, I think,
 hopefully always gives you guys something new.
 So, let me take a minute now to try to tell you
 about the sort of dynamical systems view
 of all that complexity.
 Like I just told you how complex the problem is.
 There's task level planning, there's perception,
 there's control, and I really have a goal for these notes
 and for the class to sort of put a relatively coherent
 framework for all of that together.
 It's a big task.
 The way I see it, systems theory,
 dynamical systems is a framework that we can talk about
 most of those components pretty naturally.
 There's a few things that you kind of have to shoehorn in,
 but we get pretty far thinking about things
 as a dynamical system.
 Okay, so we'll start modest,
 and some people who know dynamics and control very well
 will be bored for five minutes,
 but I hope you'll see how we're gonna build a framework,
 a toolkit of dynamical systems,
 thinking about even perception systems
 through the lens of dynamics,
 and get to something pretty good,
 I hope, by the end of the term.
 So for me, the starting point is, I guess, 18.03,
 if you've taken the undergrad version of it,
 but it's basic difference equations.
 So let's just think about, just remember,
 dust off the cobwebs of difference equations,
 and why do I wanna think about even a neural network
 as a difference equation when I'm in this class, okay?
 So.
 (marker tapping)
 The general form of a simple sort of state,
 space difference equation, you might start by saying,
 I've got some vector, a state vector, x,
 and a state update rule,
 equation F, and N is my time step.
 Okay?
 So, I mean, this is asking us to come,
 when we start thinking about perception and the like,
 this is asking us to say something
 about how our perception system is evolving in time,
 and we're gonna say that that's important
 in order to put these things together in a beautiful way.
 So the simplest examples of this would be,
 for instance,
 just a linear system, if I just had a constant,
 but if x was a scalar,
 and this was just a constant coefficient,
 then the way to think about this is that I can instantly
 do all kinds of analysis on this difference equation,
 because I can simulate it, first of all,
 if you give me x at time zero,
 then I can just roll it forward.
 I know that x1 is just a times x0,
 and x to the N, more generally,
 is just a to the N times x0.
 So I can forecast far into the future very quickly,
 because it's linear, okay?
 And actually, just by having written that,
 I could easily answer some pretty sophisticated questions
 about it, like, there's really only two things
 that this thing can do.
 It can either converge towards zero,
 or it can diverge towards infinity,
 or negative infinity, or both,
 if that's, it is negative, but.
 So you can answer long-term questions
 about stability, for instance.
 In this case, you can see that, for instance,
 if a is, let's say, strictly less than one,
 then xn will go to zero,
 as n goes to infinity.
 Okay, that's just dusting off the cobwebs here,
 but my claim is that we're gonna build,
 we're gonna complicate this,
 we're gonna use the full form of this,
 and we're gonna build a whole framework in the class
 of all the different systems, how they interact,
 using this as our starting point.
 (papers rustling)
 I'll scroll over here.
 (papers rustling)
 Okay, so now let's just make it
 a little bit more interesting.
 Let's think of it as an input-output dynamical system.
 (papers rustling)
 (papers rustling)
 Okay, so my robot isn't just evolving by itself, right?
 It has some, I typically write it as u coming in,
 y coming out.
 The internal dynamics are still with x.
 Okay, so now this is my inputs,
 which in this case might be motor commands for the robot.
 Y are my outputs.
 For instance, my sensors,
 could be cameras, could be joint sensors.
 (papers rustling)
 Pactal sensors are coming in of their own these days.
 This is still my speed vector,
 which in a simple case might just be,
 let's say the robot joint positions and velocities.
 But like I said, there'd be dragons there.
 If you're chopping an onion,
 I don't actually even know how to tell you what x is.
 Okay.
 And then the slightly more general form
 of the difference equations would be
 (papers rustling)
 something that looks like this.
 So I can tell you how the state evolves.
 I can still simulate this.
 If I say my current state, my current input,
 I'll tell you what the next state is.
 And my current output,
 this is the standard sort of state space form.
 I could say that given I know what the current state
 of the world is and possibly the inputs,
 there's not always a direct connection between you and y,
 but then I can tell you what the sensors
 are gonna look like.
 This would be a model.
 Okay, but while it's a long way from xn plus one
 equals a of xn, the framework still kind of holds.
 Now I might say that f is a full physics engine.
 (papers rustling)
 This is maybe a full game quality renderer
 or better blender sort of ray tracing rendering.
 It's a camera model.
 I have to like simulate photons, right?
 It's a lot more complicated than what we can tend
 to do our closed form analysis on,
 but actually many of the tools
 from systems theory still apply.
 We tend to attack these things more numerically
 with simulations, okay, than we do with our pen and paper.
 But the same fundamental questions should be asked.
 You should be able to give good answers.
 Sometimes the function is so complicated
 that it's hard to say something rigorous,
 but we're gonna walk that line whenever we can.
 (papers rustling)
 Okay, so what is the anatomy of a manipulation system?
 Well, first of all, we're gonna start putting models
 like this together.
 So I kind of caricatured a robot model,
 okay, with a physics engine and a renderer.
 But we can take those types of systems
 and put them together, right?
 So I can have my robot model
 with Y coming out here and U coming in,
 and maybe I write a controller, okay?
 And this is another dynamical system.
 It could even have internal state control, okay?
 And I can connect these systems in a block diagram, okay?
 And what's important is that if this is described
 by a difference equation,
 and this is described by a difference equation,
 then the dynamics of the whole diagram
 is just another difference equation
 that can be derived perfectly and simulated and analyzed
 in the same way as we did those smaller systems.
 The diagram is just another difference equation system.
 And it gets richer and more complicated
 when you have these things operating
 at different rates or whatever,
 but it all still kind of works.
 We have a theory to build up
 a lot of those different things.
 Okay, and I would say, for those of you
 that have taken underactuated or will take underactuated,
 this is sort of the view of the world
 for most of my controls class,
 and most controls classes you'll take,
 this is kind of the view of the world.
 You're given a plant or a robot,
 and you have to design a controller, okay?
 But that's not gonna get us
 where we need to go for manipulation.
 There's a whole bunch more going on here for manipulation.
 So we have perception models.
 Okay, so, and there's all kinds that we'll talk about.
 Yeah, please.
 So, there's a bunch of different ways to answer that.
 I wrote it as Y, and that would imply
 that you probably have a filter in here.
 So you have a dynamic controller
 that's estimating X inside here.
 In our full state feedback world,
 I might separate that out and say,
 like put a Kalman filter here to estimate X,
 or I might just cheat and give direct access to X, right?
 But it does, I think the view I like best of control
 is that this is really reading the raw sensors.
 It's doing any internal dynamics it needs
 to keep track and estimate,
 and it need not always estimate the full state.
 And then that becomes important to manipulation
 because what's the state of my shirt?
 Like if I need to estimate the full state of my shirt
 in order to button my shirt, I'm kind of,
 it's a bad way to go.
 So that's a great question, and we'll talk about it.
 So perception modules, there's all,
 we're gonna talk about two different flavors of perception.
 Right, we're gonna talk about some more geometric perception.
 That was dramatic.
 Oh, is that, yeah, no worries.
 And lighting changes are hell on a perception system.
 That's what always happens is you get your robot
 working perfectly, and then someone says,
 oh, I'm gonna bring a camera,
 and we're gonna take some beautiful footage
 of your robot doing it, right,
 and then they put a spotlight on it,
 and your perception system doesn't work.
 Yeah, it happens more than you'd think.
 Okay, so we're gonna talk about some geometric perception.
 So there's different kind of sensor models.
 So we could have just our RGB sensor,
 which might take somehow the state of the world,
 which we'll, I'll talk about more in a minute,
 but talk about our state of the world,
 and output, for instance, an RGB image.
 Right, green and blue being a standard color space,
 but just some, you know, some standard photograph image.
 Maybe that's the sensor that's coming out.
 And I might wanna build a perception system
 that, for instance, I don't know,
 estimates the position of the mug in the scene, right?
 So I might go from an RGB image to the pose of the mug,
 which implies that I already knew
 there was a mug in the scene, which is a fragility,
 but, you know, I could do a pose estimator here.
 And we'll talk about ways to do that.
 One way to do that would be to do,
 use a big convolutional neural network.
 And if you're doing a standard feed-forward neural network,
 then this is sort of the simplest form
 of a dynamical system where I really just have
 Y of N is some function G of U of N.
 I don't even have any state.
 But often in manipulation, you need to do better than that.
 That can maybe work for, you know, finding cats on Flickr,
 but, you know, in manipulation,
 you often need to like gather new information
 or take multiple camera images
 in order to build up your understanding of the scene.
 If I have to look around my computer
 to see what's behind it, right,
 it might be that I need a richer,
 I can't just make all my decisions
 based on the current input,
 the current image coming out of my camera.
 So that's where we get into people using, for instance,
 recurrent neural networks.
 (feet tapping)
 Which really do snap right into the
 dynamical systems view of the world.
 Where they are perfectly described by difference equations.
 (feet tapping)
 (feet tapping)
 But we're also gonna talk about
 less deep, more geometric approaches to perception.
 One of the great advances in robotics in the last,
 I don't know, 12 years or something,
 was the depth camera, right?
 The fact that we can have something
 that looks roughly in the form factor of a camera,
 but give not only RGB values at every pixel,
 but also a depth estimate at every pixel.
 They do it from various technologies,
 whether it's shining a dot pattern
 or having multiple cameras,
 or there's various different ways that we'll talk about
 when we get to perception.
 But a lot of times, our robots will have depth cameras.
 (feet tapping)
 Which takes the state of the world in
 and outputs an RGB
 D image, where you have an extra channel for depth.
 And you might have a system,
 we will build up systems that take RGBD plus camera pose.
 You have an estimate of where your camera is in the world,
 and you have potentially many RGBD cameras.
 You can make a point cloud reconstruction of the world.
 It might have history,
 you might take a history of those,
 and so it'd have internal state,
 where it might be a one-shot system,
 depending how many cameras you have.
 And then it can come out with a 3D point cloud,
 for instance.
 And once you have a 3D point cloud,
 you can put that into a neural network,
 and we're learning more and more about
 deep geometric 3D perception,
 and how do you use those properly in the neural network.
 But there's also a lot of more geometric direct reasoning,
 algorithms that you can do.
 We can do point cloud registration.
 You can do plane segmentation,
 you can do,
 there's a whole bunch of geometric algorithms
 that have relatively more maturity
 in terms of giving guarantees about performance
 against outliers and noise rejection,
 and these kind of things.
 So I find it,
 I think it's very important to talk about both the geometric,
 we'll do a section on the geometric perception,
 and we'll do a section on the deep perception,
 and we'll put them next to each other,
 and understand what's good and what.
 Running inside this,
 possibly answering your question about from Y to X,
 you can have state estimation,
 if you know about Kalman filters,
 we'll have some state estimation kind of algorithms
 happening in here.
 Typically, they're nonlinear observers,
 but just to give examples,
 we'll build up our tools
 for trying to do state estimation in this class.
 Something that I sweep under the rug in my controls class,
 but is essential, I think, for doing manipulation.
 And this may be,
 you can think of it as outputting an estimate of the state.
 So as we go,
 you can have a perfectly algebraic discussion
 of Kalman filters,
 and of point cloud algorithms,
 and stuff like this.
 We're gonna do the extra step of just saying,
 how does it fit into my systems framework toolkit?
 And we'll build up an arsenal of dynamical systems
 that we can then assemble into a big complicated diagram,
 and build that's how we're gonna,
 connect all the pieces together.
 I think it's essential for addressing the complexity
 of all the different pieces
 that we have flying around in a manipulation system,
 for me.
 Okay, and we're gonna be talking about
 planning and control algorithms.
 Control definitely fits directly into this.
 It's interesting to think about
 how a planning algorithm fits in.
 It gets more subtle, more complicated.
 But I still think it's essential
 to think about the semantics
 of how your planner is gonna interact
 with the real world clock.
 So maybe I have some sensors coming in,
 or my state estimate coming in,
 and I have some motion planner algorithm.
 Maybe it takes a long time
 for me to decide exactly how I'm gonna move my robot.
 And I only very slowly put out an entire motion plan,
 like a desired trajectory.
 (marker tapping)
 Okay, but then you need additional semantics,
 and additional tools to understand
 how I'm gonna execute that trajectory
 in a feedback controller that takes in
 my current sensors, X hat, right?
 It outputs my commands to my robot.
 (marker tapping)
 Okay, and onward and upward.
 So you get the idea, right?
 I think this idea of starting with difference equations,
 and understanding, using that as the glue
 to put all of our pieces together
 is kind of the way I wanna organize
 the diversity of topics we have in the class,
 and make you feel like, I hope,
 feel like you've got a pretty strong toolbox
 that you can compose lots of different systems
 and make them work together.
 Even at the control level,
 there's so many choices and so many details.
 We'll do differential inverse kinematics controllers.
 We'll do force control.
 We'll do impedance control, those kind of ideas.
 And they all fit into this sort of framework.
 Now, as we get deeper into the rabbit hole,
 even my X, N plus one is F of X, U,
 starts feeling inadequate.
 So we will generalize it a little bit more.
 But not a lot more, actually.
 And you get pretty far if you think about it
 as having X, having U.
 It's often very useful and meaningful
 to separate U that is sort of commanded by the controller
 versus random disturbances W.
 This would be disturbance inputs, or random.
 And then you can have some parameters P,
 which could be the size of the red cube, for instance.
 Or it could be the weights of my neural network.
 (markers tapping)
 Okay, maybe they have dynamics, but the way I wrote it,
 maybe they are fixed over the course of a simulation.
 Okay, and sometimes this might be a vector,
 just a vector of real numbers.
 (markers tapping)
 Say a vector in Rn, or could be a structured data,
 like an RGB image, which you could, of course, vectorize,
 but at some point you wanna start keeping around
 the structure of the data.
 Or a motion plan is another good example.
 (markers tapping)
 Okay, so the same language holds,
 but we're gonna take it in its full generality.
 There's some software that we'll use with the course
 that wraps all this up into code, okay?
 I wanna make this point because,
 so Drake is the name of the software.
 And one of the things it has is a way to compose
 and write these block diagrams.
 But because of the, it uses this sort of
 difference equation back end,
 but it wants to be able to support
 all the different possible permutations or variations
 or structured data that you want in here.
 We tend to wrap this up in code with something,
 we'll call that the context,
 which you can think of as just having some,
 let's say a vector X or a state X,
 and some vector U, maybe W, maybe P,
 okay, sorry for my silly pseudocode, okay?
 But you'll see me writing in code,
 you will write and I will write sometimes
 something that looks more like,
 I'm just gonna pass in a context,
 which is just the list of all the possible,
 even the time N might be in here,
 it could be time dependent.
 Okay, but if you see that, don't be alarmed,
 I'm still just talking about difference
 and differential equations,
 and we just lumped all of those into a structure.
 Okay, so the cool thing about having that language
 is that all of the fundamental questions
 of systems theory, and I would say maybe AI,
 can sort of be asked in a specific and clear way,
 given that basic language, right?
 So, simulation is what we did
 for the linear difference equation.
 You know, if you give me X zero and a point,
 and a bunch of, and my control inputs U,
 I use the dot for sort of a trajectory of U's,
 then I need to compute X at some future step.
 That's just evolving my difference equations in time,
 which was sort of natural to do for the linear systems,
 but you can do it even if it's a physics engine
 and a renderer, okay?
 Planning, right, is given,
 one form of planning is given X zero
 and some objective or goal cost function, say.
 You need to compute some series of U
 and maybe X also that minimizes my objective
 or obtains my goal, okay?
 You know, state estimation, it all fits.
 It's all just different questions to ask
 about the same set of difference equations, right?
 State estimation says, if you give me X zero
 or let's even Y zero to Yn, U zero to Un,
 you know, estimate X hat n or n plus one.
 The off by one can be (indistinct) sometimes.
 Stability analysis, verification, learning,
 system identification, they're all just variations
 of the same question.
 So system identification or model learning, if you will,
 is just given data of U, X, estimate P.
 Of U, X, estimate P, right?
 Even if it's a neural network
 and you wanna find the weights of P.
 All of these questions can be asked
 in a very rigorous or clear headed way
 about equations that look like that.
 And it really shouldn't matter that much.
 Part of my system is a neural network
 and part of it is a physics simulator
 or the whole thing is a neural network
 or any combination of the two, okay?
 So this for me is maybe the biggest reason
 to try to conceptualize clearly in the language
 of dynamical systems, the basic framework
 and to build up our library, our arsenal of tools,
 always connecting back to that framework
 because then you have a point cloud estimation algorithm.
 If you throw it in this language,
 I can still do system identification through it
 if that's what I wanted to do.
 That's a particularly weird one, but we could do it, okay?
 Questions about that?
 About that general philosophy?
 Yeah.
 - All right, could you explain again
 one more time what is W?
 - W is like a random disturbance input
 or any other random input.
 So people in reinforcement learning
 will do domain randomization.
 They'll try to change the lighting conditions
 on the robot or something like that.
 I would bring that in through W just to have clearly,
 because robustness analysis, for instance,
 would be to try to find a U and an X
 that works well for all W
 or over some expected value of W.
 So to be able to separate those out
 and ask the question clearly
 about what I'm trying to be robust to
 versus what I'm trying to allow to optimize.
 But in the diagram, you could actually pull them in
 through the same input.
 That's sort of the notation from robust control,
 but it works for our own.
 - Also, as a general note,
 when people are asking questions,
 try to speak up so we can pick you up on the streaming.
 - I should, it should be my burden.
 I should repeat the question.
 But that's an awesome, thank you.
 Yeah, I will repeat the question.
 So the question was, in that case, was what is W?
 Yes?
 - So I understand there is feedback in each nitro.
 - Potentially, yeah.
 - Is there like a channel system feedback
 that's going on between different--
 - I missed the middle word there.
 Is there what feedback?
 - Is there like a channel system feedback?
 - Yes.
 - Can there be feedback from motion planning to perception?
 - So each of those block,
 that's what you're gonna be revealing
 at the block diagram level.
 It forces you to be explicit about
 what data is flowing in what directions.
 Does my motion planning system have to have
 a streaming update of the camera or not?
 The block diagram sort of forces you
 to be explicit about that.
 And a little bit sparing, I think,
 in your use of the different,
 I think it's cleaner if you don't depend on everything.
 But absolutely, that information should flow.
 Okay, so the simulation framework in Drake
 encourages this behavior.
 It's not the standard in robotics, I would say.
 Well, certainly Drake is not the standard yet,
 but I would say the emphasis on writing out
 and declaring your state and declaring yourself
 in this sort of extra specific way
 is I'm asking more of you than what Ross,
 if you used Ross or something, would ask of you.
 But I think we get to do more pedagogical,
 and it's better for teaching,
 but it's also better for debugging and analysis
 and all these things.
 It will be able to ask more clear questions.
 In my mind, in fact, message passing systems,
 so for those of you that are doing robotics yet,
 oftentimes we actually run our controller
 and our perception system and our robot driver
 all on separate threads, at least,
 maybe separate computers, and we're just talking
 over some network message passing interface.
 Okay, that's yet another, I would model
 that message passing as another system,
 which has random delay and dropouts,
 and it's a whole bunch of complexity
 that if you wanna actually analyze this thing,
 you should embrace, right?
 And we tend to sweep it under the rug
 and get by a lot of the times
 until you have to really make something work
 100% of the time, and then it starts really getting you.
 It turns out a lot of people don't,
 so there's a simple property you would think you'd want,
 which is to be able to deterministically repeat
 your simulation, right?
 It's hard, a lot of things, a lot of our robotics tools
 don't permit that, to actually get the same answer twice.
 But for teaching, I want you to get the same answer twice.
 Right, if I wanna write a grade,
 I want it to come out with the same answer twice.
 Okay, let me take it home with, so that is,
 so Drake, the software you'll use,
 in the past, I have been a little bit shy
 about pushing Drake on people,
 and I feel the feedback I've gotten
 has been, at the end of the class,
 I wish you had just told me a little bit more about Drake
 so that I was more of an expert
 when it came time for my project.
 So we're gonna do a little bit more
 of sort of like explaining what's going on there.
 This idea of the context is one idea behind it,
 but Drake roughly is three big parts.
 One of them is this notion of assembling your systems
 in block diagrams and writing each of the systems out
 with their state and their control
 and their disturbance inputs and the like.
 There's tutorials, okay.
 There's a physics engine, which is, I think,
 world-class for simulating contact and the like,
 so you'll be able to do the very rich
 contact simulations like you saw.
 And then when we get to motion planning
 and optimization and system identification and learning,
 we'll be putting to use some of the optimization tools
 that are just like the third big component inside Drake.
 So, you know, the type of notation that you will see
 in there is it really just says,
 I'm gonna make a new system.
 I'm gonna declare my state to be some variable.
 I'm gonna declare my dynamics to have some dynamics.
 I'm gonna declare my output.
 This is like, we just codify the equations
 that I put on the board, okay.
 And it really does sort of follow the standard
 discrete difference equation or continuous
 or many mixture of the two sort of notation.
 And you can assemble big, complicated diagrams.
 This is actually, you know, an expandable diagram
 that I put in the notes, but this is what it took
 to run the little teleop interface,
 my little silly thing where I dram the robot
 into the table and it shot the brick to the left
 off the screen, right.
 That actually involved an inverse dynamics controller,
 a physics engine, a geometry engine for the perception
 for, you know, like a lot of pieces
 were assembled together to make that simple demo.
 And you're gonna be able to build on that
 and understand it.
 There's nothing, it's open source, right.
 So there's nothing that's hidden from you.
 You can choose to dig in or not.
 And there's sort of a commitment for me
 to be open source, right.
 So I think you'll see that throughout the class.
 Like actually, if you were to look really carefully
 right now at the visualization of that sliders
 that came down, the word open close gripper
 is truncated at grip because there was a bug in the,
 you know, in some, I decided to basically push open source.
 You know, I tried to push a fix upstream
 to like the GUI, the JavaScript GUI tool
 that I was using or whatever.
 And it's gonna take a few days for that to trickle through
 and for me to update my dependencies and whatever.
 But there's kind of like a commitment that you make
 when you live in the open source world
 to like try to make everything better
 every time you touch it, you know.
 And you'll see that commitment.
 Sometimes you'll be mad at me for that commitment, maybe.
 But I do my best to try to keep this, you know,
 very open Toyota Research Institute
 is putting a ton of effort into it and keeping it open,
 which was a great thing to have accomplished.
 And it's all connected into the notebook.
 So we'll see that here.
 So you'll see that, you know, I can,
 in the system's way of thinking,
 I can encapsulate an entire diagram
 and make some abstract powerful abstractions.
 So that my entire robot, which is a physics engine
 and a sensor simulation for a camera
 and a low level controller and everything like that.
 You know, we bottle that up into a, you know,
 a bigger system called the manipulation station.
 But, you know, it takes in just position commands,
 possibly feed forward torques, gripper commands.
 Inside it is a whole bunch of different components
 that make that thing tick.
 And it outputs a lot of different outputs,
 which were chosen because they are the same outputs
 that the real hardware outputs.
 And so there's an almost identical system
 called the manipulation station hardware interface,
 which presents the same inputs and outputs,
 except for a few cheap ports
 you're allowed to have in simulation, okay?
 But inside this system,
 there's just a bunch of driver code
 or message passing to the drivers or something like this.
 So you can take your big complicated perception control
 or whatever, train it up in simulation,
 pull that system out, put the robot,
 physical robot in effectively and be running immediately.
 So if we get you guys to the hardware,
 that's the way it makes it work.
 (whispering)
 Okay, so I mentioned it already,
 you know, the schedule's online,
 but we're gonna go through,
 not only are we gonna try to build up
 an arsenal of components that you can put together,
 but I wanna order it in a way
 that you're solving more and more complex tasks.
 And I don't wanna introduce a new technique
 unless it actually helps you do something cool
 that you couldn't do before.
 So we'll start off by just telling you
 about the hardware that we have in robotics
 and how we might model that a little bit,
 do some basic pick and place, even with that red cube,
 but that'll force us to think about kinematics,
 differential kinematics, some basic motion planning.
 Then we'll start doing the 3D geometric perception.
 Then we'll start making the scenes more cluttered
 and have to think about more complicated plans for grasping.
 How do you choose a collision-free grasp
 that's gonna get a good contact with my environment?
 We'll make a more and more complicated system
 in that respect.
 We'll start programming some higher level behaviors
 in that world.
 Then we'll get to deep perception.
 So we'll stop assuming that we know
 what objects are in the world
 and we'll have to detect objects when they happen.
 We'll have to segment the world
 into reasonable things for manipulation
 and build more interesting state representations of the world.
 We'll do some work on force control
 and trajectory tracking and motion planning
 that will allow our robots to do more dexterous things
 in those same kind of environments.
 We'll then take some of the things that we've already done
 and we can do a little better with reinforcement learning.
 I wanna compare and contrast those
 with the model-based approaches.
 And then we'll end the term,
 as you guys are deep in your projects,
 we will end the term with a few kind of boutique lectures,
 if you will, of some of the,
 what's hot in robotics right now.
 I'll give a lecture each on some of the hot topics.
 I'll take feedback even if you guys,
 if you think, oh, I'd really love to hear about this,
 it's not on your list.
 I'd say those last ones will do runtime decision.
 All right, so just to put that same slide up again,
 make sure you're on Piazza,
 take a look at the course guidelines,
 take a look at the lecture notes,
 run my little GUI slider 'cause I've heard,
 really heard of that.
 (audience laughing)
 I'm afraid no one's gonna hear.
 And if DeepNote doesn't work for you, tell me.
 That's like, that's the biggest uncertainty in my mind
 is like, I just changed the whole back end of that.
 The P-set's gonna be released tomorrow.
 There's a white P-set for this week
 that we're gonna start our Wednesday cadence of problem sets
 and start talking about final project.
 I promise.
 (audience chattering)
 (audience chattering)
 [BLANK_AUDIO]
