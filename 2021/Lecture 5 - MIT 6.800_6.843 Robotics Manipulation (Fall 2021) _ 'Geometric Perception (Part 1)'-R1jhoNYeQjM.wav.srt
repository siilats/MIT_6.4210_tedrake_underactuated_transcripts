1
00:00:00,000 --> 00:00:01,360
 [INAUDIBLE]

2
00:00:01,360 --> 00:00:02,200
 OK.

3
00:00:02,200 --> 00:00:02,880
 We ready?

4
00:00:02,880 --> 00:00:04,960
 We good?

5
00:00:04,960 --> 00:00:07,040
 Welcome back, everybody.

6
00:00:07,040 --> 00:00:10,080
 I just heard-- I guess I was in lecture prep mode,

7
00:00:10,080 --> 00:00:12,440
 and I wasn't on piazza.

8
00:00:12,440 --> 00:00:14,640
 But I just heard the deep note is having trouble,

9
00:00:14,640 --> 00:00:17,400
 so I will look at that right after class.

10
00:00:17,400 --> 00:00:19,880
 I didn't realize, but if you're struggling with that,

11
00:00:19,880 --> 00:00:20,320
 I will--

12
00:00:20,320 --> 00:00:20,640
 I don't know.

13
00:00:20,640 --> 00:00:22,640
 I'll do my best to look at it right after class.

14
00:00:22,640 --> 00:00:29,520
 So today, we are transitioning into the first perception

15
00:00:29,520 --> 00:00:30,480
 set of lectures.

16
00:00:30,480 --> 00:00:31,480
 OK.

17
00:00:31,480 --> 00:00:35,400
 Now, I mean, the basic setup, I guess,

18
00:00:35,400 --> 00:00:39,320
 I can do my standard setup, is that so far, we've

19
00:00:39,320 --> 00:00:42,320
 either assumed we knew where the block was immediately,

20
00:00:42,320 --> 00:00:44,120
 or I actually, in some of the notebooks,

21
00:00:44,120 --> 00:00:49,840
 I had the system pull on the output port that

22
00:00:49,840 --> 00:00:52,720
 was the cheat port, I call it, from the manipulation station.

23
00:00:52,720 --> 00:00:56,960
 So if you look closely at the manipulation station,

24
00:00:56,960 --> 00:00:59,500
 it tells you what you would get from the robot, which

25
00:00:59,500 --> 00:01:05,520
 are the IWA positions and the shunk positions.

26
00:01:05,520 --> 00:01:07,560
 It doesn't tell you directly--

27
00:01:07,560 --> 00:01:10,780
 I mean, there's no sensors saying where the block is yet.

28
00:01:10,780 --> 00:01:13,660
 But we have these cheat ports that

29
00:01:13,660 --> 00:01:16,060
 will tell you the position and the pose

30
00:01:16,060 --> 00:01:17,960
 of any object in the scene.

31
00:01:17,960 --> 00:01:20,040
 And so I was using that as a backdoor

32
00:01:20,040 --> 00:01:21,960
 to figure out where the brick started

33
00:01:21,960 --> 00:01:26,200
 and plan everything relative to that, or I just hardcoded it.

34
00:01:26,200 --> 00:01:28,080
 So today, we're going to stop using those.

35
00:01:28,080 --> 00:01:31,560
 We're going to instead use the cameras.

36
00:01:31,560 --> 00:01:34,320
 So the cameras are the sensors that we have available

37
00:01:34,320 --> 00:01:38,840
 to see the world and to figure out where that red brick is.

38
00:01:38,840 --> 00:01:43,760
 And thus begins the conversation for perception.

39
00:01:43,760 --> 00:01:47,600
 So I mean, maybe it goes without saying,

40
00:01:47,600 --> 00:01:50,160
 but computer vision is hard.

41
00:01:50,160 --> 00:01:51,400
 It's been hard for a long time.

42
00:01:51,400 --> 00:01:56,800
 It got a lot better in the last few years with deep learning.

43
00:01:56,800 --> 00:01:58,440
 But if you think about why it's hard

44
00:01:58,440 --> 00:02:03,360
 and why it breaks a lot of the optimization type approaches

45
00:02:03,360 --> 00:02:07,280
 like we saw for kinematics, I would

46
00:02:07,280 --> 00:02:11,360
 say is because if you take the color

47
00:02:11,360 --> 00:02:14,320
 values of the pixels in an image,

48
00:02:14,320 --> 00:02:17,120
 this is a very bad space.

49
00:02:17,120 --> 00:02:20,840
 So RGB, the red, green, blue space,

50
00:02:20,840 --> 00:02:24,960
 the color values in an image, they

51
00:02:24,960 --> 00:02:27,120
 don't satisfy the sort of--

52
00:02:27,120 --> 00:02:29,840
 it's hard to write optimization directly

53
00:02:29,840 --> 00:02:31,440
 against the RGB values.

54
00:02:31,440 --> 00:02:34,520
 So you can have very nearby RGB values

55
00:02:34,520 --> 00:02:36,400
 that mean very different things in terms

56
00:02:36,400 --> 00:02:39,240
 of the geometry in the world and vice versa.

57
00:02:39,240 --> 00:02:41,520
 So you can change the lighting a lot,

58
00:02:41,520 --> 00:02:44,320
 and the brick's still in the same scene.

59
00:02:44,320 --> 00:02:45,920
 The RGB values went all over the place.

60
00:02:45,920 --> 00:02:52,160
 So because of this, I would say there are two

61
00:02:52,160 --> 00:02:56,360
 major branches of perception for robotics.

62
00:02:56,360 --> 00:02:58,640
 One of them continues to use geometry

63
00:02:58,640 --> 00:03:01,480
 but uses a different type of cameras, which gives

64
00:03:01,480 --> 00:03:03,960
 direct geometry information.

65
00:03:03,960 --> 00:03:06,760
 I'm going to tell you a little bit about them.

66
00:03:06,760 --> 00:03:11,320
 And the other is now sort of the more deep learning-based work.

67
00:03:11,320 --> 00:03:13,640
 I've separated into deep perception.

68
00:03:13,640 --> 00:03:16,000
 Typically, it can work directly from RGB values,

69
00:03:16,000 --> 00:03:18,960
 and it's becoming highly effective.

70
00:03:18,960 --> 00:03:21,640
 Now, even in the last year or so,

71
00:03:21,640 --> 00:03:24,000
 we're starting to see those two worlds collapse again.

72
00:03:24,000 --> 00:03:27,760
 And people are doing like NERF, if people know what NERF is,

73
00:03:27,760 --> 00:03:29,440
 or deep SDF.

74
00:03:29,440 --> 00:03:33,560
 Or you're seeing deep learning using geometry representations

75
00:03:33,560 --> 00:03:35,880
 and trying to combine those two again.

76
00:03:35,880 --> 00:03:37,920
 So it's not a surprise, maybe, but I'd

77
00:03:37,920 --> 00:03:42,160
 say those two streams are interesting by themselves

78
00:03:42,160 --> 00:03:44,600
 and are going to be hopelessly intertwined into the future.

79
00:03:44,600 --> 00:03:50,520
 So I mean, I do think, though, it's important.

80
00:03:50,520 --> 00:03:53,480
 Some people say deep learning is all you need

81
00:03:53,480 --> 00:03:55,120
 to do for perception right now.

82
00:03:55,120 --> 00:03:56,580
 And I just don't think that's true.

83
00:03:56,580 --> 00:03:58,960
 I think there has been this other parallel revolution,

84
00:03:58,960 --> 00:03:59,720
 just as--

85
00:03:59,720 --> 00:04:02,080
 maybe not quite as dramatic as the deep learning.

86
00:04:02,080 --> 00:04:04,040
 But going on very much in parallel

87
00:04:04,040 --> 00:04:05,840
 and getting spectacular results has

88
00:04:05,840 --> 00:04:08,520
 been this geometric perception pipeline.

89
00:04:08,520 --> 00:04:14,160
 And that's sad, like really comically sad there.

90
00:04:14,160 --> 00:04:14,660
 OK.

91
00:04:14,660 --> 00:04:15,160
 Huh.

92
00:04:15,160 --> 00:04:24,500
 I'm sorry, I shouldn't have unplugged that one.

93
00:04:24,500 --> 00:04:27,980
 I just screwed up your stream, did I?

94
00:04:27,980 --> 00:04:29,180
 I meant to unplug this one.

95
00:04:42,980 --> 00:04:45,620
 Man, the number of technical problems I've managed to have.

96
00:04:45,700 --> 00:04:48,680
 [AUDIO OUT]

97
00:04:48,680 --> 00:05:16,280
, let's try.

98
00:05:16,280 --> 00:05:25,240
 [AUDIO OUT]

99
00:05:25,240 --> 00:05:26,700
 Kind of ruined my flow, didn't it?

100
00:05:26,700 --> 00:05:33,000
 [AUDIO OUT]

101
00:05:33,000 --> 00:05:54,560
 [AUDIO OUT]

102
00:05:54,560 --> 00:05:57,320
 It's going to make me register real quick.

103
00:05:57,320 --> 00:05:58,680
 That's what I didn't do, I think.

104
00:05:58,680 --> 00:06:11,160
 [AUDIO OUT]

105
00:06:11,160 --> 00:06:11,660
 Good Lord.

106
00:06:11,660 --> 00:06:41,640
 [AUDIO OUT]

107
00:06:41,640 --> 00:06:56,100
 [AUDIO OUT]

108
00:06:56,100 --> 00:06:58,100
 I'll just use my iPhone in a second here.

109
00:06:58,100 --> 00:07:28,080
 [AUDIO OUT]

110
00:07:28,080 --> 00:07:32,560
 [AUDIO OUT]

111
00:07:32,560 --> 00:07:34,060
 I'm going to lecture off my iPhone.

112
00:07:34,060 --> 00:07:35,040
 How about that?

113
00:07:35,040 --> 00:07:43,000
 [AUDIO OUT]

114
00:07:43,000 --> 00:07:44,000
 That works fine.

115
00:07:44,000 --> 00:07:48,480
 [AUDIO OUT]

116
00:07:48,480 --> 00:07:53,000
 It should not be better than the MIT network.

117
00:07:53,000 --> 00:07:53,500
 OK.

118
00:07:53,500 --> 00:07:55,640
 Sorry about that.

119
00:07:55,640 --> 00:07:57,980
 It's going to play the videos a little slower probably.

120
00:07:57,980 --> 00:07:59,040
 [AUDIO OUT]

121
00:07:59,040 --> 00:08:03,920
 OK, so there's a second revolution-- sorry for that--

122
00:08:03,920 --> 00:08:10,040
 based on geometric processing of the visual scene.

123
00:08:10,040 --> 00:08:13,520
 So you've probably seen incredible reconstructions

124
00:08:13,520 --> 00:08:15,560
 from autonomous driving, driving through town,

125
00:08:15,560 --> 00:08:17,320
 and building beautiful maps.

126
00:08:17,320 --> 00:08:22,040
 This is sort of the indoor equivalent of the SLAM,

127
00:08:22,040 --> 00:08:24,960
 if you know, the simultaneous localization and mapping.

128
00:08:24,960 --> 00:08:27,140
 This one is called dynamic fusion.

129
00:08:27,140 --> 00:08:30,360
 It's in particular tracking objects

130
00:08:30,360 --> 00:08:33,440
 that can change their shape or change their pose relative.

131
00:08:33,440 --> 00:08:35,520
 But it's just absolutely stunning

132
00:08:35,520 --> 00:08:38,040
 that a handful of years ago, people

133
00:08:38,040 --> 00:08:40,800
 started being able to build this sort of quality

134
00:08:40,800 --> 00:08:43,540
 reconstruction of a 3D world from a camera

135
00:08:43,540 --> 00:08:44,880
 that you can fit in your pocket.

136
00:08:44,880 --> 00:08:47,480
 In fact, I've got one in my pocket right here.

137
00:08:47,480 --> 00:08:48,400
 Yeah, look at that.

138
00:08:48,400 --> 00:08:49,800
 These kind of cameras, right?

139
00:08:49,800 --> 00:08:51,360
 I don't always have them in my pocket.

140
00:08:51,360 --> 00:08:55,600
 But-- oh, that's not true actually,

141
00:08:55,600 --> 00:08:58,400
 because I do always have one in my pocket.

142
00:08:58,400 --> 00:09:00,800
 There's one right there too, right?

143
00:09:00,800 --> 00:09:01,960
 Which is pretty awesome.

144
00:09:01,960 --> 00:09:08,920
 So that has been fueled by a lot of different things.

145
00:09:08,920 --> 00:09:10,760
 I mean, robotics is a good enterprise.

146
00:09:10,760 --> 00:09:12,640
 But I would say robotics by itself

147
00:09:12,640 --> 00:09:14,680
 might not have been enough fuel for this.

148
00:09:14,680 --> 00:09:17,840
 But now augmented reality, like Facebook Labs,

149
00:09:17,840 --> 00:09:19,280
 is working on this.

150
00:09:19,280 --> 00:09:20,640
 It was originally Oculus.

151
00:09:21,280 --> 00:09:26,120
 And the people that did this work became Oculus,

152
00:09:26,120 --> 00:09:28,360
 became Facebook Reality Labs.

153
00:09:28,360 --> 00:09:31,720
 So it's being powered by those kind of revolutions.

154
00:09:31,720 --> 00:09:42,200
 So let's just think a little bit about these different types

155
00:09:42,200 --> 00:09:44,460
 of sensors, and why are they different than a standard

156
00:09:44,460 --> 00:09:47,920
 camera, and why did they help robotics jump into the

157
00:09:47,920 --> 00:09:51,080
 perception age, I would say.

158
00:09:51,080 --> 00:09:52,880
 There's a couple different types out there.

159
00:09:52,880 --> 00:09:57,560
 You've probably heard of LIDAR, the laser range finders.

160
00:09:57,560 --> 00:10:00,480
 These are based on time of flight, where they're actually

161
00:10:00,480 --> 00:10:06,000
 shooting out an active laser, and then waiting for the

162
00:10:06,000 --> 00:10:08,200
 return, and measuring the distance.

163
00:10:08,200 --> 00:10:10,680
 And some of these are just crazy good, right?

164
00:10:10,680 --> 00:10:16,160
 So even a year ago, there was these 500 meter range luminars

165
00:10:16,160 --> 00:10:18,040
 coming out where a car can drive through it.

166
00:10:18,040 --> 00:10:20,480
 It can basically see the whole city, it feels like.

167
00:10:20,480 --> 00:10:25,120
 And it's just building highly accurate geometric models as

168
00:10:25,120 --> 00:10:27,480
 it's driving down the street.

169
00:10:27,480 --> 00:10:28,200
 It's crazy good.

170
00:10:28,200 --> 00:10:31,520
 And you see these kind of--

171
00:10:31,520 --> 00:10:33,840
 I don't know if that's actually processed, or that

172
00:10:33,840 --> 00:10:35,800
 could just be a raw return.

173
00:10:35,800 --> 00:10:37,840
 Some of the raw returns from these cameras

174
00:10:37,840 --> 00:10:40,240
 just look spectacular.

175
00:10:40,240 --> 00:10:43,800
 I mean, the resolution degrades the farther you go, but it's

176
00:10:43,800 --> 00:10:46,680
 still crazy good.

177
00:10:46,680 --> 00:10:51,440
 And when these started happening, this started

178
00:10:51,440 --> 00:10:54,760
 powering a lot of the geometric work in robotics

179
00:10:54,760 --> 00:10:57,160
 perception.

180
00:10:57,160 --> 00:11:01,280
 Stereo imaging is still a thing.

181
00:11:01,280 --> 00:11:05,640
 It's an important thing, where you'll see stereo heads that

182
00:11:05,640 --> 00:11:08,600
 were the classic approach to building

183
00:11:08,600 --> 00:11:10,800
 sensors for perception.

184
00:11:10,800 --> 00:11:13,400
 This is actually the Carnegie head, which is stuck in the

185
00:11:13,400 --> 00:11:16,720
 middle of Atlas, which is the humanoid robot from at least

186
00:11:16,720 --> 00:11:20,280
 the version of Atlas we have upstairs, carried around this

187
00:11:20,280 --> 00:11:22,560
 stereo pair head.

188
00:11:22,560 --> 00:11:27,160
 And basically, the basic principle, there's two cameras.

189
00:11:27,160 --> 00:11:33,200
 And it's comparing the two images, trying to find similar

190
00:11:33,200 --> 00:11:37,480
 blocks in the left and right image, and then saying how

191
00:11:37,480 --> 00:11:41,360
 different are those blocks in the image using the distance

192
00:11:41,360 --> 00:11:44,440
 between the lenses and figuring out the depth.

193
00:11:44,440 --> 00:11:47,560
 There's many different ways to do it, but basically, a simple

194
00:11:47,560 --> 00:11:52,520
 block matching stereo is a perfectly good way to do it.

195
00:11:52,520 --> 00:11:56,960
 Each of these have different pros and cons.

196
00:11:56,960 --> 00:11:58,720
 I'll tell you about the ones we picked.

197
00:11:58,720 --> 00:12:01,280
 I'll tell you most about the one we picked.

198
00:12:01,280 --> 00:12:03,400
 Structured light, it was the Microsoft

199
00:12:03,400 --> 00:12:06,040
 Kinect came out.

200
00:12:06,040 --> 00:12:09,280
 This was considered a major advance for indoor.

201
00:12:09,280 --> 00:12:11,480
 LiDAR was traditionally considered for outdoor

202
00:12:11,480 --> 00:12:14,720
 applications, and it works in natural light, whereas the

203
00:12:14,720 --> 00:12:17,920
 Kinect was one of the first things that powered the indoor

204
00:12:17,920 --> 00:12:20,520
 perception revolution.

205
00:12:20,520 --> 00:12:22,720
 And the fact that they became so cheap because they were

206
00:12:22,720 --> 00:12:25,400
 sold with game consoles was a big, big deal.

207
00:12:25,400 --> 00:12:28,440
 I think that really opened up the number of people that were

208
00:12:28,440 --> 00:12:32,120
 playing with them and just really

209
00:12:32,120 --> 00:12:34,680
 bootstrapped the research.

210
00:12:34,680 --> 00:12:37,520
 So the structured light approach is you're projecting

211
00:12:37,520 --> 00:12:41,200
 some image onto the scene, which allows you to then, by

212
00:12:41,200 --> 00:12:44,040
 taking a picture, have far more information than you

213
00:12:44,040 --> 00:12:51,800
 would have had with just random pixels coming in.

214
00:12:51,800 --> 00:12:53,480
 But the one that we're going to use that I have in my

215
00:12:53,480 --> 00:12:58,760
 pocket here is an Intel RealSense D415.

216
00:12:58,760 --> 00:13:01,120
 They're pretty small, pretty nice.

217
00:13:01,120 --> 00:13:04,200
 This is actually a projected texture stereo.

218
00:13:04,200 --> 00:13:06,640
 The RealSense line and the Intel line has a handful of

219
00:13:06,640 --> 00:13:10,240
 different technologies, but this is the projected texture

220
00:13:10,240 --> 00:13:11,480
 stereo version.

221
00:13:11,480 --> 00:13:18,600
 So it's basically a stereo camera, except that it's also

222
00:13:18,600 --> 00:13:20,440
 got a little projector, obviously, that's just pushing

223
00:13:20,440 --> 00:13:22,520
 out some pattern of light.

224
00:13:22,520 --> 00:13:24,240
 So that if you were to look at--

225
00:13:24,240 --> 00:13:27,760
 if you take stereo images of a purely white wall, then

226
00:13:27,760 --> 00:13:29,760
 there's nothing that it could possibly do to compare those

227
00:13:29,760 --> 00:13:32,440
 images to get a reasonable depth.

228
00:13:32,440 --> 00:13:35,920
 But if you project an invisible pattern, an IR pattern even,

229
00:13:35,920 --> 00:13:39,280
 on the wall, then there's still something that it can

230
00:13:39,280 --> 00:13:42,280
 see in order to get good depth information.

231
00:13:42,280 --> 00:13:45,480
 And in general, it reduces the reliance on the textures in

232
00:13:45,480 --> 00:13:47,880
 the world, because it's providing its own texture.

233
00:13:47,880 --> 00:13:54,160
 Compared to things like LiDAR and other time of flight

234
00:13:54,160 --> 00:13:57,360
 technologies, one of the reasons we like this is

235
00:13:57,360 --> 00:14:00,240
 because they don't interfere with each other.

236
00:14:00,240 --> 00:14:03,960
 So it actually doesn't care what the--

237
00:14:03,960 --> 00:14:06,120
 so compared to the structured light, where it's trying to

238
00:14:06,120 --> 00:14:08,560
 set up a certain pattern out, this one's just putting out

239
00:14:08,560 --> 00:14:09,440
 any old pattern.

240
00:14:09,440 --> 00:14:10,880
 It just wants to have texture.

241
00:14:10,880 --> 00:14:11,720
 It doesn't care--

242
00:14:11,720 --> 00:14:13,440
 it's not trying to match a specific pattern.

243
00:14:13,440 --> 00:14:15,800
 It's just trying to make sure that there's not

244
00:14:15,800 --> 00:14:17,360
 sameness everywhere.

245
00:14:17,360 --> 00:14:19,640
 So if you have two cameras pointing at the same scene,

246
00:14:19,640 --> 00:14:22,400
 and they're both projecting texture, no big deal.

247
00:14:22,400 --> 00:14:23,920
 It's still getting good returns.

248
00:14:23,920 --> 00:14:25,960
 Whereas a lot of the other cameras before that, you had

249
00:14:25,960 --> 00:14:28,720
 to really synchronize your multiple cameras to make sure

250
00:14:28,720 --> 00:14:30,240
 they weren't hitting--

251
00:14:30,240 --> 00:14:32,200
 sending active pulses at the same time.

252
00:14:32,200 --> 00:14:35,840
 It was a major, major pain.

253
00:14:35,840 --> 00:14:38,920
 And we do use multiple cameras.

254
00:14:38,920 --> 00:14:43,240
 I'll show you in a minute the number of cameras we put

255
00:14:43,240 --> 00:14:45,880
 around that dish-loading example.

256
00:14:45,880 --> 00:14:48,240
 But this is new news.

257
00:14:48,240 --> 00:14:50,400
 This is August 17th this year.

258
00:14:50,400 --> 00:14:52,040
 Super sad.

259
00:14:52,040 --> 00:14:54,760
 I don't really use emojis, but I almost put a sad emoji on

260
00:14:54,760 --> 00:14:56,840
 here, right?

261
00:14:56,840 --> 00:15:00,560
 I don't really know what I'm going to do.

262
00:15:00,560 --> 00:15:03,160
 But it's really bad news for the field.

263
00:15:03,160 --> 00:15:04,520
 I mean, we're bummed.

264
00:15:04,520 --> 00:15:05,920
 There's not a great replacement yet.

265
00:15:05,920 --> 00:15:08,080
 I mean, there's more technologies out there, but

266
00:15:08,080 --> 00:15:10,720
 the RealSense has become a favorite for sure.

267
00:15:10,720 --> 00:15:13,440
 And I think we're--

268
00:15:13,440 --> 00:15:13,760
 I don't know.

269
00:15:13,760 --> 00:15:17,160
 We're just too small as a field to matter.

270
00:15:17,160 --> 00:15:19,720
 But they're selling them, but I guess they're

271
00:15:19,720 --> 00:15:21,720
 not selling enough.

272
00:15:21,720 --> 00:15:23,880
 So I don't know what we'll be using next year in class.

273
00:15:23,880 --> 00:15:25,200
 But we've got a bunch of RealSenses.

274
00:15:25,200 --> 00:15:27,680
 We're going to hang on to them, keep using them as long

275
00:15:27,680 --> 00:15:28,920
 as we can.

276
00:15:29,920 --> 00:15:30,920
 OK.

277
00:15:30,920 --> 00:15:34,480
 So we have the ability to simulate these cameras, of

278
00:15:34,480 --> 00:15:36,760
 course, in the simulation.

279
00:15:36,760 --> 00:15:40,520
 But we simulate them in various levels of fidelity.

280
00:15:40,520 --> 00:15:40,800
 OK?

281
00:15:40,800 --> 00:15:44,240
 So the simplest one, and the one we'll use for most of the

282
00:15:44,240 --> 00:15:50,000
 class, is just a standard OpenGL renderer.

283
00:15:50,000 --> 00:15:50,320
 OK?

284
00:15:50,320 --> 00:15:54,680
 So OpenGL is sort of the basic graphics language that's

285
00:15:54,680 --> 00:15:56,640
 existed forever.

286
00:15:56,640 --> 00:16:02,080
 It's not particularly fancy in the way it does lighting.

287
00:16:02,080 --> 00:16:08,520
 Or it's capable, but not compared to the new game

288
00:16:08,520 --> 00:16:11,240
 engine quality technologies.

289
00:16:11,240 --> 00:16:12,160
 But it's fast.

290
00:16:12,160 --> 00:16:13,560
 And it's got GPU acceleration.

291
00:16:13,560 --> 00:16:19,240
 And it's definitely faster than real time.

292
00:16:19,240 --> 00:16:19,480
 OK.

293
00:16:19,480 --> 00:16:22,320
 So let me just step you through.

294
00:16:22,320 --> 00:16:26,520
 This is just a diagram from a very simple system that has an

295
00:16:26,520 --> 00:16:28,160
 object, a single object in the scene.

296
00:16:28,160 --> 00:16:31,320
 Turns out it's a mustard bottle.

297
00:16:31,320 --> 00:16:31,680
 OK.

298
00:16:31,680 --> 00:16:35,560
 And so we've got a multi-body plant, which is just holding

299
00:16:35,560 --> 00:16:37,800
 the mustard bottle, not doing anything interesting.

300
00:16:37,800 --> 00:16:41,200
 We've got the scene graph, which is the geometry engine.

301
00:16:41,200 --> 00:16:44,800
 And we now can take an RGB sensor and add a new sensor

302
00:16:44,800 --> 00:16:46,560
 into the diagram.

303
00:16:46,560 --> 00:16:49,160
 It hooks right up to the scene graph.

304
00:16:49,160 --> 00:16:49,680
 OK.

305
00:16:49,680 --> 00:16:51,680
 It's just another system.

306
00:16:51,680 --> 00:16:54,000
 It reads geometry.

307
00:16:54,000 --> 00:16:59,240
 It has a message passing with the scene graph to get the

308
00:16:59,240 --> 00:17:00,280
 geometry information.

309
00:17:00,280 --> 00:17:05,200
 And it spits out color image, but also depth image in a

310
00:17:05,200 --> 00:17:06,680
 couple different channels.

311
00:17:06,680 --> 00:17:09,520
 And a label image for when you want to train your machine

312
00:17:09,520 --> 00:17:10,240
 learning algorithms.

313
00:17:10,240 --> 00:17:16,240
 You can say per pixel what object is it associated with.

314
00:17:16,240 --> 00:17:19,640
 And you can have it spit out the pose of the sensor.

315
00:17:19,640 --> 00:17:20,400
 OK.

316
00:17:20,400 --> 00:17:24,520
 So RGBD for red, green, blue, and depth sensors.

317
00:17:24,520 --> 00:17:26,560
 It's just one more channel that gives you a

318
00:17:26,560 --> 00:17:28,040
 depth signal back.

319
00:17:28,040 --> 00:17:31,880
 OK.

320
00:17:31,880 --> 00:17:35,240
 And the images that come out are the standard--

321
00:17:35,240 --> 00:17:36,600
 you take the first three channels, the

322
00:17:36,600 --> 00:17:38,760
 standard RGB images.

323
00:17:38,760 --> 00:17:40,800
 You get something that looks like this out.

324
00:17:40,800 --> 00:17:42,280
 There's a little mustard bottle.

325
00:17:42,280 --> 00:17:44,680
 And then there's an image that's the same number of

326
00:17:44,680 --> 00:17:48,280
 pixels, the same size, which just says for every pixel,

327
00:17:48,280 --> 00:17:51,160
 what's the distance to the object in the scene?

328
00:17:51,160 --> 00:17:52,680
 The first return, right?

329
00:17:52,680 --> 00:17:56,000
 Or NAN if it's too far.

330
00:17:56,000 --> 00:17:57,640
 Actually, it's not NAN.

331
00:17:57,640 --> 00:18:02,840
 There's a particular integer for that.

332
00:18:02,840 --> 00:18:03,280
 OK.

333
00:18:03,280 --> 00:18:09,320
 So you'll see this come slowly into MeshCat here.

334
00:18:16,640 --> 00:18:20,360
 So in MeshCat, you can push the point clouds out to the

335
00:18:20,360 --> 00:18:21,040
 renderer, too.

336
00:18:21,040 --> 00:18:24,000
 So first of all, I drew the camera with the camera

337
00:18:24,000 --> 00:18:25,240
 coordinates here.

338
00:18:25,240 --> 00:18:29,240
 So you can see red, green, blue, remember?

339
00:18:29,240 --> 00:18:32,680
 So x, y, z.

340
00:18:32,680 --> 00:18:35,200
 Right?

341
00:18:35,200 --> 00:18:39,520
 So in order to get the images that we saw, we wanted the

342
00:18:39,520 --> 00:18:40,880
 camera oriented like this.

343
00:18:40,880 --> 00:18:42,200
 It's a little bit hard to think about.

344
00:18:42,200 --> 00:18:46,040
 I put it at a little bit of a tilt in order to get a little

345
00:18:46,040 --> 00:18:48,280
 bit of an angle on the shot.

346
00:18:48,280 --> 00:18:50,320
 OK?

347
00:18:50,320 --> 00:18:53,240
 But you can go in and navigate through MeshCat.

348
00:18:53,240 --> 00:18:57,720
 You can turn on and off the geometry from scene graph.

349
00:18:57,720 --> 00:18:59,600
 And you can turn on and off the point cloud.

350
00:18:59,600 --> 00:19:02,960
 But there's a point cloud in there giving you the same sort

351
00:19:02,960 --> 00:19:06,640
 of the raw information, I guess, from the cameras.

352
00:19:06,640 --> 00:19:08,880
 Right?

353
00:19:08,880 --> 00:19:11,880
 Now, the camera only sees one side of the object.

354
00:19:11,880 --> 00:19:12,200
 Right?

355
00:19:12,200 --> 00:19:14,800
 And that's a big part of what we have to take care of in

356
00:19:14,800 --> 00:19:18,480
 perception is the fact that we only get partial views.

357
00:19:18,480 --> 00:19:19,280
 Right?

358
00:19:19,280 --> 00:19:23,880
 So it's not going to be enough to assume you could see all

359
00:19:23,880 --> 00:19:27,000
 parts of the object and match all parts of the object.

360
00:19:27,000 --> 00:19:29,400
 When you have occlusions, when you have multiple objects in

361
00:19:29,400 --> 00:19:31,880
 the scene, it gets even worse.

362
00:19:31,880 --> 00:19:36,080
 And the best perception systems can do a lot with very

363
00:19:36,080 --> 00:19:37,320
 partial views.

364
00:19:37,320 --> 00:19:43,040
 OK.

365
00:19:43,040 --> 00:19:47,040
 I said we like to just not worry about the cameras

366
00:19:47,040 --> 00:19:48,160
 interfering.

367
00:19:48,160 --> 00:19:48,480
 OK?

368
00:19:48,480 --> 00:19:54,040
 But this is a little ridiculous, I would say.

369
00:19:54,040 --> 00:19:56,600
 We just didn't want to worry about whether we had enough

370
00:19:56,600 --> 00:20:00,000
 cameras or we wanted to avoid partial views as much as

371
00:20:00,000 --> 00:20:02,560
 possible, so we put a bunch of cameras all over the place.

372
00:20:02,560 --> 00:20:05,040
 And we would do things like use some cameras to train the

373
00:20:05,040 --> 00:20:06,520
 other cameras.

374
00:20:06,520 --> 00:20:09,840
 There were multiple reasons for it.

375
00:20:09,840 --> 00:20:14,040
 But we instrumented the world with plenty of cameras, OK?

376
00:20:14,040 --> 00:20:15,800
 Including two on the wrist.

377
00:20:15,800 --> 00:20:16,000
 Right?

378
00:20:16,000 --> 00:20:18,920
 So right on the wrist of the robot, there's

379
00:20:18,920 --> 00:20:21,080
 two right there.

380
00:20:21,080 --> 00:20:22,600
 We'll mount them in various places.

381
00:20:22,600 --> 00:20:26,760
 The robot that we tried to bring in--

382
00:20:26,760 --> 00:20:28,920
 we successfully brought the robot in, but the cage had to

383
00:20:28,920 --> 00:20:29,680
 be disassembled.

384
00:20:29,680 --> 00:20:31,240
 And the cage had--

385
00:20:31,240 --> 00:20:34,640
 the standard cage we had around it was there primarily to hold

386
00:20:34,640 --> 00:20:37,680
 the cameras in fixed locations and have a nice view down into

387
00:20:37,680 --> 00:20:43,560
 the scene.

388
00:20:43,560 --> 00:20:47,400
 So we're going to talk mostly today about relatively

389
00:20:47,400 --> 00:20:49,920
 simple-- like clean point clouds.

390
00:20:49,920 --> 00:20:52,840
 And thinking about what you do if the point clouds are giving

391
00:20:52,840 --> 00:20:55,800
 you pure geometry information.

392
00:20:55,800 --> 00:21:00,200
 But next time, we're going to go into the fact that the real

393
00:21:00,200 --> 00:21:01,520
 point clouds are pretty messy.

394
00:21:01,520 --> 00:21:01,960
 OK?

395
00:21:01,960 --> 00:21:02,880
 So I'm just--

396
00:21:02,880 --> 00:21:06,960
 introduce the idea of it here, but we're going to dig more

397
00:21:06,960 --> 00:21:09,480
 into it with our methods next time.

398
00:21:09,480 --> 00:21:15,120
 So this is a simulated depth return for

399
00:21:15,120 --> 00:21:16,840
 this kind of a scene.

400
00:21:16,840 --> 00:21:17,960
 OK?

401
00:21:17,960 --> 00:21:19,440
 And this is what you actually get out of

402
00:21:19,440 --> 00:21:20,920
 the real depth camera.

403
00:21:20,920 --> 00:21:24,920
 Now you notice it's not Gaussian noise.

404
00:21:24,920 --> 00:21:25,240
 OK?

405
00:21:25,240 --> 00:21:28,920
 So it's not like I take every pixel and I pull a random

406
00:21:28,920 --> 00:21:33,160
 number and I change the depth value by some Gaussian number.

407
00:21:33,160 --> 00:21:36,080
 It's much more stereotypical than that.

408
00:21:36,080 --> 00:21:39,040
 It tends to happen on the edges of objects, right?

409
00:21:39,040 --> 00:21:41,920
 Where the normals are not very incident to the camera.

410
00:21:41,920 --> 00:21:42,720
 OK?

411
00:21:42,720 --> 00:21:45,920
 That's a typical place where you don't get good returns or

412
00:21:45,920 --> 00:21:47,840
 don't get good depth images.

413
00:21:47,840 --> 00:21:50,760
 Or if one camera can't-- or if both cameras can't see the

414
00:21:50,760 --> 00:21:53,440
 side of an object or something like that.

415
00:21:53,440 --> 00:21:54,240
 There's other--

416
00:21:54,240 --> 00:21:59,000
 so transparent or reflective surfaces are all-- there's

417
00:21:59,000 --> 00:22:01,440
 things like this that are the canonical bad

418
00:22:01,440 --> 00:22:06,040
 cases for these cameras.

419
00:22:06,040 --> 00:22:09,360
 There was a great project actually by the same Facebook

420
00:22:09,360 --> 00:22:13,520
 group where they were mapping the inside of homes and they

421
00:22:13,520 --> 00:22:15,280
 wanted to build these beautiful 3D

422
00:22:15,280 --> 00:22:17,840
 maps of indoor homes.

423
00:22:17,840 --> 00:22:19,760
 And the problem is people have windows and

424
00:22:19,760 --> 00:22:20,600
 people have mirrors.

425
00:22:20,600 --> 00:22:21,640
 So they actually--

426
00:22:21,640 --> 00:22:22,800
 they had a very clever--

427
00:22:22,800 --> 00:22:24,280
 I'll actually talk about it later.

428
00:22:24,280 --> 00:22:27,720
 But they have a very clever trick for figuring out how to

429
00:22:27,720 --> 00:22:29,480
 work with mirrors and windows.

430
00:22:32,600 --> 00:22:36,520
 OK, so this is just an example--

431
00:22:36,520 --> 00:22:41,760
 another example of-- this is the D415 where Cooney is

432
00:22:41,760 --> 00:22:44,800
 looking at some Legos and vegetables and random stuff on

433
00:22:44,800 --> 00:22:46,520
 his table, OK?

434
00:22:46,520 --> 00:22:49,520
 But if you scroll around the 3D-- the same way I scrolled

435
00:22:49,520 --> 00:22:51,880
 around the mustard bottle, he's got the camera above.

436
00:22:51,880 --> 00:22:53,080
 The camera's not moving.

437
00:22:53,080 --> 00:22:55,360
 This is just looking at the point cloud that's coming out

438
00:22:55,360 --> 00:22:57,080
 from different angles.

439
00:22:57,080 --> 00:23:00,280
 I would say there's one word that everybody always uses

440
00:23:00,280 --> 00:23:03,800
 when they talk about the point clouds out of D415--

441
00:23:03,800 --> 00:23:05,120
 lumpy.

442
00:23:05,120 --> 00:23:06,160
 Everybody says lumpy.

443
00:23:06,160 --> 00:23:07,120
 It's like--

444
00:23:07,120 --> 00:23:08,600
 it doesn't seem like a word that would come to--

445
00:23:08,600 --> 00:23:11,080
 but I've heard a lot of people say, yeah, yeah, those are

446
00:23:11,080 --> 00:23:12,800
 lumpy point clouds.

447
00:23:12,800 --> 00:23:15,640
 And it just has this characteristic ripple, OK?

448
00:23:15,640 --> 00:23:19,140
 And if your carrots or whatever are like about the

449
00:23:19,140 --> 00:23:23,000
 same size as your lumps, things get pretty dicey.

450
00:23:23,000 --> 00:23:26,760
 So that wasn't meant to be a joke.

451
00:23:26,760 --> 00:23:27,640
 OK.

452
00:23:27,640 --> 00:23:32,640
 So that's our setup.

453
00:23:32,640 --> 00:23:36,960
 Let's start thinking about how to do work with point clouds

454
00:23:36,960 --> 00:23:40,860
 and how to go from depth to point clouds and why, as you

455
00:23:40,860 --> 00:23:45,920
 can see here, that thinking about point clouds is actually

456
00:23:45,920 --> 00:23:47,560
 a kinematics problem.

457
00:23:47,560 --> 00:23:49,920
 So I hope it blends nicely from what we did last time.

458
00:23:49,920 --> 00:23:54,580
 OK.

459
00:23:55,220 --> 00:23:56,460
 I'll start here.

460
00:23:56,460 --> 00:24:13,340
 So there's many representations of 3D data, of

461
00:24:13,340 --> 00:24:14,820
 3D geometry, let me say.

462
00:24:24,140 --> 00:24:25,500
 OK.

463
00:24:25,500 --> 00:24:28,940
 The one that we were just illustrating there is called a

464
00:24:28,940 --> 00:24:30,180
 point cloud.

465
00:24:30,180 --> 00:24:33,820
 OK.

466
00:24:33,820 --> 00:24:38,100
 So typically, this would be a--

467
00:24:38,100 --> 00:24:42,980
 let's say a 3 by n matrix, OK, where this is the x, y, z

468
00:24:42,980 --> 00:24:51,140
 positions in a Cartesian frame.

469
00:24:51,140 --> 00:25:00,980
 And this is the number of pixels or number of points.

470
00:25:00,980 --> 00:25:05,980
 OK.

471
00:25:05,980 --> 00:25:07,220
 It can also be--

472
00:25:07,220 --> 00:25:14,060
 you can also have RGB values.

473
00:25:14,060 --> 00:25:17,740
 You can also have normal information.

474
00:25:17,740 --> 00:25:20,540
 There are a couple other things that you can--

475
00:25:20,540 --> 00:25:22,700
 extra information you can add to the point cloud.

476
00:25:22,700 --> 00:25:27,340
 But the first thing we'll think about is just x, y, z

477
00:25:27,340 --> 00:25:31,980
 positions in space that are a point that I got from a--

478
00:25:31,980 --> 00:25:34,540
 indirectly from a depth camera.

479
00:25:34,540 --> 00:25:36,580
 OK.

480
00:25:36,580 --> 00:25:41,280
 I mean, a depth image, like we got directly out of the

481
00:25:41,280 --> 00:25:44,460
 camera, is also, in some sense, a

482
00:25:44,460 --> 00:25:46,220
 representation of 3D geometry.

483
00:25:46,220 --> 00:25:48,180
 But it's not enough by itself.

484
00:25:48,180 --> 00:25:53,060
 You also need to know, let's say, the camera info.

485
00:25:53,060 --> 00:25:54,820
 I'll get more detailed about that later.

486
00:25:54,820 --> 00:26:00,780
 But in order to turn that 2D image into a 3D point cloud,

487
00:26:00,780 --> 00:26:04,260
 you need to know something about the geometry of the

488
00:26:04,260 --> 00:26:06,660
 camera, and potentially even the location in space.

489
00:26:06,660 --> 00:26:13,420
 There are other representations of 3D

490
00:26:13,420 --> 00:26:14,780
 geometry, too.

491
00:26:14,780 --> 00:26:16,260
 I mean, you can do triangular meshes.

492
00:26:16,260 --> 00:26:25,820
 Some of you will have heard of signed distance

493
00:26:25,820 --> 00:26:27,060
 representations.

494
00:26:27,060 --> 00:26:42,420
 And this has led to things like NERF, which I will say

495
00:26:42,420 --> 00:26:43,660
 more carefully later.

496
00:26:44,660 --> 00:26:53,300
 Voxel grids are another one, or occupancy grids.

497
00:26:53,300 --> 00:27:01,020
 OK.

498
00:27:01,020 --> 00:27:05,140
 So for the most part, I want you to--

499
00:27:05,140 --> 00:27:07,740
 we're going to think about these kind of the same way we

500
00:27:07,740 --> 00:27:13,260
 thought about rotations, where there are many, many

501
00:27:13,260 --> 00:27:15,020
 different types of representations for the

502
00:27:15,020 --> 00:27:16,220
 geometry.

503
00:27:16,220 --> 00:27:19,260
 There are ways to go back and forth between them.

504
00:27:19,260 --> 00:27:24,180
 And for different algorithms, they have different virtues.

505
00:27:24,180 --> 00:27:26,340
 So sometimes we'll choose to use the point cloud directly.

506
00:27:26,340 --> 00:27:30,260
 Sometimes it's better to use the depth image or signed

507
00:27:30,260 --> 00:27:32,340
 distance function.

508
00:27:32,340 --> 00:27:35,700
 The only caveat, the only place that that analogy breaks is

509
00:27:35,700 --> 00:27:38,060
 that in the rotation representations, we could go

510
00:27:38,060 --> 00:27:40,660
 back and forth without any loss of information.

511
00:27:40,660 --> 00:27:42,780
 Whereas here, sometimes you have to be careful.

512
00:27:42,780 --> 00:27:45,060
 You might actually lose information when you go across

513
00:27:45,060 --> 00:27:47,460
 one of these boundaries.

514
00:27:47,460 --> 00:27:50,180
 But in general, I think the healthy attitude--

515
00:27:50,180 --> 00:27:52,660
 so oftentimes people will be like, oh, I have a new

516
00:27:52,660 --> 00:27:53,020
 algorithm.

517
00:27:53,020 --> 00:27:54,340
 I just realized you could do everything in

518
00:27:54,340 --> 00:27:55,220
 signed distance functions.

519
00:27:55,220 --> 00:27:57,420
 And I think the people that have thought about perception

520
00:27:57,420 --> 00:28:01,580
 a long time think, well, the representations are basically

521
00:28:01,580 --> 00:28:01,900
 the same.

522
00:28:01,900 --> 00:28:03,460
 You're not discovering something.

523
00:28:03,460 --> 00:28:06,100
 It's like, really just think about this as a library of

524
00:28:06,100 --> 00:28:08,020
 representations you can go back and forth between.

525
00:28:08,020 --> 00:28:14,900
 We're going to focus today on the point cloud

526
00:28:14,900 --> 00:28:18,500
 representation, because it plays very well with the

527
00:28:18,500 --> 00:28:22,220
 kinematics of finding an object, finding our red brick.

528
00:28:22,220 --> 00:28:43,140
 OK.

529
00:28:43,140 --> 00:28:43,780
 Here's the setup.

530
00:28:43,780 --> 00:28:49,420
 I've got some geometry in my world.

531
00:28:49,420 --> 00:28:52,620
 Got some multicolored chalk.

532
00:28:52,620 --> 00:28:54,140
 OK.

533
00:28:54,140 --> 00:28:55,980
 And let's say I've taken my camera.

534
00:28:55,980 --> 00:28:58,540
 I'm just going to do it in 2D, because I have a 2D blackboard.

535
00:28:58,540 --> 00:29:02,900
 But you can generalize it to 3D easily enough.

536
00:29:02,900 --> 00:29:04,180
 So I've got some camera.

537
00:29:04,180 --> 00:29:06,940
 And let's just say I was able to see all sides of it to

538
00:29:06,940 --> 00:29:08,180
 start.

539
00:29:08,180 --> 00:29:11,020
 We'll pretend we had maybe multiple cameras looking at it

540
00:29:11,020 --> 00:29:14,220
 and we assembled some point cloud where we got nice,

541
00:29:14,220 --> 00:29:25,620
 evenly distributed points from all over the object.

542
00:29:25,620 --> 00:29:25,900
 OK.

543
00:29:25,900 --> 00:29:35,700
 So we'll call our object O and our object frame O. OK.

544
00:29:35,700 --> 00:29:38,740
 So I want to distinguish between two sets of points.

545
00:29:38,740 --> 00:29:39,260
 OK.

546
00:29:39,260 --> 00:29:41,620
 We're going to think about the points.

547
00:29:41,620 --> 00:29:45,460
 Well, we're going to do two things.

548
00:29:45,460 --> 00:29:47,140
 We're going to have the points that are coming out of the

549
00:29:47,140 --> 00:29:49,940
 camera, which we tend to call those the scene points.

550
00:29:49,940 --> 00:29:50,900
 OK.

551
00:29:50,900 --> 00:29:56,620
 So if I have a camera and I've taken my depth camera and I've

552
00:29:56,620 --> 00:30:03,860
 projected the points into the 3D world, then I'm going to

553
00:30:03,860 --> 00:30:13,220
 have a bunch of scene points.

554
00:30:13,220 --> 00:30:15,340
 And they're going to come in the camera frame.

555
00:30:15,340 --> 00:30:23,040
 OK.

556
00:30:23,040 --> 00:30:28,620
 And our job, our task, is to try to figure out the pose of

557
00:30:28,620 --> 00:30:31,420
 this object using the scene points that

558
00:30:31,420 --> 00:30:32,680
 are coming in here.

559
00:30:32,680 --> 00:30:38,100
 Now, there's many ways to do it.

560
00:30:38,100 --> 00:30:40,820
 But we're going to start with an algorithm that, since we're

561
00:30:40,820 --> 00:30:43,700
 working with points on this side, we're going to go ahead

562
00:30:43,700 --> 00:30:45,540
 and represent our object.

563
00:30:45,540 --> 00:30:46,660
 Again, we have multiple--

564
00:30:46,660 --> 00:30:50,220
 you could think of it as represented as a mesh or by a

565
00:30:50,220 --> 00:30:53,140
 sine distance function or lots of different options.

566
00:30:53,140 --> 00:30:56,660
 But our object, our known geometry that we're looking

567
00:30:56,660 --> 00:31:00,140
 for, I'm going to go ahead and represent that geometry with a

568
00:31:00,140 --> 00:31:01,740
 set of points, too.

569
00:31:01,740 --> 00:31:03,580
 And we'll call that the model points.

570
00:31:03,580 --> 00:31:15,260
 And that's going to be represented in the object

571
00:31:15,260 --> 00:31:16,500
 frame.

572
00:31:16,500 --> 00:31:20,140
 So basically, you start off.

573
00:31:20,140 --> 00:31:22,020
 You know the thing you're looking for.

574
00:31:22,020 --> 00:31:25,020
 The way you describe it is by a set of points that I hope to

575
00:31:25,020 --> 00:31:26,780
 find in the world.

576
00:31:26,860 --> 00:31:30,620
 And then I'm getting scene points actually measured.

577
00:31:30,620 --> 00:31:33,740
 And my job is going to be to somehow find the relationship

578
00:31:33,740 --> 00:31:37,220
 between these scene points and the model points, both in

579
00:31:37,220 --> 00:31:42,300
 terms of the pose and in terms of mapping those two,

580
00:31:42,300 --> 00:31:44,380
 figuring out which scene point goes with which model point.

581
00:31:44,380 --> 00:31:51,860
 OK.

582
00:31:51,860 --> 00:31:56,620
 So let's assume that we know--

583
00:31:56,620 --> 00:31:58,260
 this is the camera's pose in the world.

584
00:31:58,260 --> 00:32:03,980
 Let's say we know that.

585
00:32:03,980 --> 00:32:07,260
 We can measure it.

586
00:32:07,260 --> 00:32:08,500
 We can calibrate it.

587
00:32:08,500 --> 00:32:19,780
 Our task is going to be to estimate the object's pose in

588
00:32:19,780 --> 00:32:21,020
 the world.

589
00:32:22,020 --> 00:32:34,700
 Right?

590
00:32:34,700 --> 00:32:36,300
 Camera's viewing the world, giving about a

591
00:32:36,300 --> 00:32:38,140
 bunch of depth returns.

592
00:32:38,140 --> 00:32:40,660
 Now, we're going to make a bunch of

593
00:32:40,660 --> 00:32:41,820
 assumptions to start.

594
00:32:41,820 --> 00:32:43,060
 OK.

595
00:32:43,060 --> 00:32:46,780
 We're going to assume that the only scene points that come in

596
00:32:46,780 --> 00:32:50,140
 that are in our point cloud are from the actual object.

597
00:32:50,140 --> 00:32:51,860
 It's never like that.

598
00:32:51,860 --> 00:32:53,580
 Normally, you have your object.

599
00:32:53,580 --> 00:32:54,420
 You have the table.

600
00:32:54,420 --> 00:32:57,540
 You have all these spurious points that are coming in.

601
00:32:57,540 --> 00:32:58,940
 It's never that simple.

602
00:32:58,940 --> 00:33:01,660
 But to start off, let's just assume that we have only the

603
00:33:01,660 --> 00:33:02,300
 scene points.

604
00:33:02,300 --> 00:33:05,500
 We'll talk about how to generalize that soon.

605
00:33:05,500 --> 00:33:08,060
 AUDIENCE: Are we assuming that we know the model points?

606
00:33:08,060 --> 00:33:10,340
 PROFESSOR: Yes, we assume that these are known.

607
00:33:10,340 --> 00:33:14,900
 This object is known.

608
00:33:14,900 --> 00:33:16,140
 Right?

609
00:33:18,220 --> 00:33:21,500
 So this would be finding a known object in the scene, not

610
00:33:21,500 --> 00:33:23,620
 understanding some new object you've never seen before.

611
00:33:23,620 --> 00:33:30,260
 And we're going to make another assumption, huge

612
00:33:30,260 --> 00:33:32,980
 assumption, but even this lecture will get around.

613
00:33:32,980 --> 00:33:34,220
 OK?

614
00:33:34,220 --> 00:33:38,460
 Let's assume that we know the correspondences.

615
00:33:38,660 --> 00:33:39,900
 OK?

616
00:33:39,900 --> 00:33:50,980
 What do we mean by correspondence?

617
00:33:50,980 --> 00:33:53,940
 That's an important word that's going to come up over

618
00:33:53,940 --> 00:33:57,340
 and over again.

619
00:33:57,340 --> 00:34:03,500
 If I have my canonical model, which has some number of

620
00:34:03,500 --> 00:34:13,740
 points, my model points, if I had enough colors, I would

621
00:34:13,740 --> 00:34:15,820
 make each of these different colors possibly.

622
00:34:15,820 --> 00:34:24,780
 But OK.

623
00:34:24,780 --> 00:34:27,220
 There's something you're doing immediately with your

624
00:34:27,220 --> 00:34:29,860
 impressive vision system is you're realizing that this

625
00:34:29,860 --> 00:34:31,460
 point goes with that point, this point

626
00:34:31,460 --> 00:34:32,500
 goes with that point.

627
00:34:32,500 --> 00:34:33,140
 Right?

628
00:34:33,140 --> 00:34:37,420
 You're corresponding the points based on your

629
00:34:37,420 --> 00:34:38,580
 understanding of the object.

630
00:34:38,580 --> 00:34:41,300
 OK?

631
00:34:41,300 --> 00:34:42,540
 These are the correspondences.

632
00:34:42,540 --> 00:34:48,820
 OK?

633
00:34:48,820 --> 00:34:50,700
 And I'm going to just assume, even just to keep the

634
00:34:50,700 --> 00:34:52,820
 notation the same, that this is--

635
00:34:52,820 --> 00:34:56,620
 I'll call this 0.1, 0.2, 0.3, go around, and I'll assume

636
00:34:56,620 --> 00:35:01,340
 that these are correctly ordered so that model point i

637
00:35:01,340 --> 00:35:05,540
 actually corresponds to scene point i.

638
00:35:05,540 --> 00:35:06,500
 Yeah?

639
00:35:06,500 --> 00:35:09,460
 Do you mean that if I line these up, that they actually

640
00:35:09,460 --> 00:35:13,300
 match up, or that there's just some relationship that

641
00:35:13,300 --> 00:35:16,620
 could satisfy the epsilon on top of--

642
00:35:16,620 --> 00:35:16,940
 Yeah, yeah.

643
00:35:16,940 --> 00:35:19,980
 So I'm starting with they actually line up, one to one

644
00:35:19,980 --> 00:35:22,340
 matching, and we're going to quickly

645
00:35:22,340 --> 00:35:24,980
 remove that assumption.

646
00:35:24,980 --> 00:35:25,900
 So it's crazy.

647
00:35:25,900 --> 00:35:27,140
 That's never going to happen.

648
00:35:27,140 --> 00:35:28,380
 OK.

649
00:35:28,380 --> 00:35:37,980
 Maybe I'll go over here.

650
00:35:37,980 --> 00:35:50,100
 So given our kinematics and our frames and our

651
00:35:50,100 --> 00:35:55,620
 understanding, we know that we can put everything into the

652
00:35:55,620 --> 00:35:56,620
 world frame, right?

653
00:35:56,620 --> 00:36:02,220
 So that the models--

654
00:36:02,220 --> 00:36:03,460
 let's see, I'll do--

655
00:36:03,460 --> 00:36:11,780
 I can take my model points, which are

656
00:36:11,780 --> 00:36:13,460
 specified in object frame.

657
00:36:13,460 --> 00:36:16,420
 There's some pose of the object that would transform me

658
00:36:16,420 --> 00:36:19,300
 into the world frame.

659
00:36:19,380 --> 00:36:28,500
 And similarly, I want that to match the scene points, one to

660
00:36:28,500 --> 00:36:31,900
 one matching because I've assumed correspondences.

661
00:36:31,900 --> 00:36:36,580
 And the scene points are given by this.

662
00:36:36,580 --> 00:36:41,020
 But I can go ahead and just--

663
00:36:41,020 --> 00:36:43,500
 because this is known and this is known, I can just

664
00:36:43,500 --> 00:36:45,900
 pre-compute that and just work with this as my object.

665
00:36:45,900 --> 00:36:52,220
 OK.

666
00:36:52,220 --> 00:36:55,540
 So given that, the question is, how do I

667
00:36:55,540 --> 00:37:01,140
 reconstruct xw, x, o, in w?

668
00:37:01,140 --> 00:37:08,420
 This is very much an inverse kinematics problem.

669
00:37:08,740 --> 00:37:09,980
 Right?

670
00:37:09,980 --> 00:37:25,620
 Right.

671
00:37:25,620 --> 00:37:29,220
 Given the end effectors, it's very much similar to if I had

672
00:37:29,220 --> 00:37:33,540
 my robot arm and I had my gripper desired end effector,

673
00:37:33,540 --> 00:37:36,620
 I need to figure out what the joint angles are.

674
00:37:36,620 --> 00:37:40,260
 OK, here I've got my points that are associated and I want

675
00:37:40,260 --> 00:37:44,540
 to figure out what the Q, or in this case it's represented

676
00:37:44,540 --> 00:37:47,820
 directly as a pose, of that object is.

677
00:37:47,820 --> 00:37:52,380
 Now last time we didn't actually do

678
00:37:52,380 --> 00:37:53,220
 inverse kinematics.

679
00:37:53,220 --> 00:37:53,540
 Right?

680
00:37:53,540 --> 00:37:56,260
 We did forward kinematics, then we did differential

681
00:37:56,260 --> 00:37:58,060
 kinematics, then we did differential inverse

682
00:37:58,060 --> 00:38:01,500
 kinematics, but we never did inverse kinematics.

683
00:38:01,500 --> 00:38:01,780
 Right?

684
00:38:01,780 --> 00:38:03,900
 So we did Jacobians, everything.

685
00:38:03,900 --> 00:38:05,940
 This time we're actually going to do inverse kinematics.

686
00:38:05,940 --> 00:38:07,340
 We're going to actually solve this directly.

687
00:38:07,340 --> 00:38:14,460
 Why not differential this time?

688
00:38:14,460 --> 00:38:24,540
 Why am I not going to immediately

689
00:38:24,540 --> 00:38:26,540
 talk about Jacobians?

690
00:38:26,540 --> 00:38:27,020
 Yeah?

691
00:38:27,020 --> 00:38:37,860
 [INAUDIBLE]

692
00:38:37,860 --> 00:38:38,140
 Right.

693
00:38:38,140 --> 00:38:40,980
 So what would be the closest notion?

694
00:38:40,980 --> 00:38:44,300
 So the comment there was that there's not an analogous

695
00:38:44,300 --> 00:38:47,780
 notion, I'm saying, that there's not an analogous

696
00:38:47,780 --> 00:38:51,500
 notion of the joint measurements, for instance, in

697
00:38:51,500 --> 00:38:53,620
 the camera space.

698
00:38:53,620 --> 00:39:01,780
 But if I had a current pose, I could ask, what is an

699
00:39:01,780 --> 00:39:05,380
 incremental change in my model points relative--

700
00:39:05,380 --> 00:39:07,700
 if I were to make an incremental change in this

701
00:39:07,700 --> 00:39:10,180
 pose, how do my scene points change?

702
00:39:10,180 --> 00:39:13,020
 I could still ask the differential question.

703
00:39:13,020 --> 00:39:17,660
 So I think it's possible we could still do differential

704
00:39:17,660 --> 00:39:19,100
 kinematics.

705
00:39:19,100 --> 00:39:22,020
 And in fact, we will do differential kinematics for

706
00:39:22,020 --> 00:39:24,420
 perception when we want to do things like tracking objects.

707
00:39:24,420 --> 00:39:30,020
 But unfortunately, we have to solve a harder problem for

708
00:39:30,020 --> 00:39:31,260
 perception to start.

709
00:39:31,260 --> 00:39:39,500
 The EWA, we always have joint measurements that tell me what

710
00:39:39,500 --> 00:39:40,500
 position I'm in right now.

711
00:39:40,500 --> 00:39:42,780
 And I can ask, given I'm in this position, what's an

712
00:39:42,780 --> 00:39:44,340
 increment going to do?

713
00:39:44,340 --> 00:39:47,060
 In the perception problem, the robot has to

714
00:39:47,060 --> 00:39:48,820
 wake up at some point.

715
00:39:48,820 --> 00:39:51,140
 And for the first time, look at a bunch of points and solve

716
00:39:51,140 --> 00:39:55,540
 a harder problem of figuring out where am I at all.

717
00:39:55,540 --> 00:39:58,220
 I can't do an incremental change until I have something

718
00:39:58,220 --> 00:39:59,940
 to start from.

719
00:39:59,940 --> 00:40:02,900
 So I have to solve this sort of more global problem first

720
00:40:02,900 --> 00:40:04,660
 in order to start this.

721
00:40:04,660 --> 00:40:14,140
 Did I say that well enough?

722
00:40:14,140 --> 00:40:16,620
 You guys didn't look totally with me on that.

723
00:40:16,620 --> 00:40:17,860
 OK.

724
00:40:17,860 --> 00:40:30,460
 Basically, I don't have an initial guess for the pose.

725
00:40:30,460 --> 00:40:37,900
 If I had an initial guess, I could say, if I change that

726
00:40:37,900 --> 00:40:41,300
 initial guess a little bit, then how would it change?

727
00:40:41,300 --> 00:40:45,340
 But I don't have a close initial guess such that local

728
00:40:45,340 --> 00:40:48,700
 changes of it are going to get me where I need to be.

729
00:40:48,700 --> 00:40:49,180
 Yeah?

730
00:40:49,180 --> 00:40:51,140
 AUDIENCE: Could you explain why this version of the problem

731
00:40:51,140 --> 00:40:53,620
 is harder compared to the differential version?

732
00:40:53,620 --> 00:40:56,580
 Is it computation complexity or something?

733
00:40:56,580 --> 00:41:02,620
 PROFESSOR: The question is, so why is this version of the

734
00:41:02,620 --> 00:41:03,260
 problem harder?

735
00:41:03,260 --> 00:41:07,580
 Why do I say this is the global problem which is harder?

736
00:41:07,580 --> 00:41:14,540
 So the short answer is that basically, the differential

737
00:41:14,540 --> 00:41:19,420
 problem is that locally, you're solving a bunch of

738
00:41:19,420 --> 00:41:20,740
 linear equations all the time.

739
00:41:20,740 --> 00:41:25,700
 And we did write convex problems in order to track it.

740
00:41:25,700 --> 00:41:28,860
 So our quadratic programming approach to differential

741
00:41:28,860 --> 00:41:33,020
 inverse kinematics was an excellent solution.

742
00:41:33,020 --> 00:41:35,420
 When you don't have that initial guess, then you have

743
00:41:35,420 --> 00:41:37,940
 to solve the harder problem where it might have multiple

744
00:41:37,940 --> 00:41:39,140
 local minima.

745
00:41:39,140 --> 00:41:42,660
 And in general, you have to find the needle

746
00:41:42,660 --> 00:41:43,900
 in the haystack.

747
00:41:43,900 --> 00:41:45,860
 It's not about tracking something that

748
00:41:45,860 --> 00:41:46,700
 you've already found.

749
00:41:46,700 --> 00:41:48,780
 It's about finding it for the first time.

750
00:41:48,780 --> 00:41:51,340
 And because there are lots of different--

751
00:41:51,340 --> 00:41:53,540
 we're going to see when we write the equations down why

752
00:41:53,540 --> 00:41:56,140
 there are local minima that come up.

753
00:41:56,140 --> 00:42:02,900
 But you might think, that clump of points over here is my

754
00:42:02,900 --> 00:42:04,420
 brick, no, that could be that point.

755
00:42:04,420 --> 00:42:06,900
 There could be something very different that would be close

756
00:42:06,900 --> 00:42:08,980
 matches to your points.

757
00:42:08,980 --> 00:42:10,660
 So it's a harder problem.

758
00:42:10,660 --> 00:42:12,700
 It does translate all the way down to computational

759
00:42:12,700 --> 00:42:15,820
 complexity, but that's not the simplest way to see it.

760
00:42:15,820 --> 00:42:30,580
 So let's think about this problem here.

761
00:42:30,580 --> 00:42:36,500
 I want you to see this as basically a linear problem.

762
00:42:36,500 --> 00:42:37,780
 So why is that a linear problem?

763
00:42:37,780 --> 00:42:48,100
 So I can write x w o o m i equals psi.

764
00:42:48,100 --> 00:42:49,340
 This is given.

765
00:42:49,340 --> 00:42:56,500
 We have to solve for this.

766
00:42:56,500 --> 00:43:04,340
 You can write this as p o w plus r o w p o m i.

767
00:43:05,340 --> 00:43:08,500
 OK.

768
00:43:08,500 --> 00:43:12,140
 Where this is the position of the frame,

769
00:43:12,140 --> 00:43:15,500
 and this is the rotation of that frame.

770
00:43:15,500 --> 00:43:25,460
 And in particular, if we now choose 3 by 3 rotation matrices

771
00:43:25,460 --> 00:43:29,580
 as a representation of this, then this equation

772
00:43:29,580 --> 00:43:30,980
 is actually a matrix equation.

773
00:43:30,980 --> 00:43:32,860
 I'm not just hiding behind spatial algebra

774
00:43:32,860 --> 00:43:33,980
 to make that true.

775
00:43:33,980 --> 00:43:36,620
 This is actually a matrix, a 3 by 3 matrix,

776
00:43:36,620 --> 00:43:39,700
 times a 3 by 1 vector.

777
00:43:39,700 --> 00:43:43,340
 And this equation should match.

778
00:43:43,340 --> 00:43:47,740
 So I can write this, this being multiplied

779
00:43:47,740 --> 00:43:51,380
 like this in this structure.

780
00:43:51,380 --> 00:43:54,460
 When I see that, I think the problem I'm trying to solve

781
00:43:54,460 --> 00:43:58,060
 is linear in my parameters, my decision parameters.

782
00:43:58,060 --> 00:44:01,180
 So I hope you see this as being Ax, maybe

783
00:44:01,180 --> 00:44:04,620
 equal to approximately equal to b.

784
00:44:04,620 --> 00:44:06,120
 But you have to be a little careful,

785
00:44:06,120 --> 00:44:09,620
 because what's in x?

786
00:44:09,620 --> 00:44:11,500
 What are the things I'm trying to solve for?

787
00:44:11,500 --> 00:44:17,900
 In order to write this out, you have

788
00:44:17,900 --> 00:44:21,100
 to shuffle and flip and reorient,

789
00:44:21,100 --> 00:44:28,580
 because x is actually holding inside it p w o and r w o

790
00:44:28,580 --> 00:44:32,700
 rolled out into a long vector.

791
00:44:32,700 --> 00:44:35,340
 A actually has-- what does it have?

792
00:44:35,340 --> 00:44:44,260
 It has this hiding inside the A plus a bunch of 1's

793
00:44:44,260 --> 00:44:46,900
 to get that term.

794
00:44:46,900 --> 00:44:50,140
 And b is that term.

795
00:44:53,460 --> 00:44:57,860
 But if I see this, I see a linear set of equations.

796
00:44:57,860 --> 00:45:07,880
 Now because, as Alex points out, it's

797
00:45:07,880 --> 00:45:10,340
 ridiculous to assume that you have exactly

798
00:45:10,340 --> 00:45:14,620
 overlap all the time, asking that to be exactly

799
00:45:14,620 --> 00:45:17,420
 equal for a whole bunch of points from a sensor

800
00:45:17,420 --> 00:45:20,580
 that we know is going to be a little bit noisy,

801
00:45:20,580 --> 00:45:23,660
 we know it's not going to match all the points.

802
00:45:23,660 --> 00:45:28,700
 It's too much to say, here's a bunch of equations,

803
00:45:28,700 --> 00:45:30,540
 make that equality hold.

804
00:45:30,540 --> 00:45:31,980
 So just like last time, we're going

805
00:45:31,980 --> 00:45:36,020
 to write the softer version of this as an optimization

806
00:45:36,020 --> 00:45:36,860
 problem.

807
00:45:36,860 --> 00:45:49,460
 So what I'd like to do instead is roughly this.

808
00:45:49,460 --> 00:45:50,700
 I'll see you in just a second.

809
00:45:50,700 --> 00:45:59,500
 I'll even just-- I can call my decision variables

810
00:45:59,500 --> 00:46:00,340
 whatever I like here.

811
00:46:00,340 --> 00:46:04,660
 So p r p plus r.

812
00:46:04,660 --> 00:46:16,200
 Yeah?

813
00:46:16,200 --> 00:46:16,700
 [INAUDIBLE]

814
00:46:16,700 --> 00:46:22,380
 Ah.

815
00:46:22,380 --> 00:46:23,960
 I'm going to get to that in a second.

816
00:46:23,960 --> 00:46:24,460
 Yeah.

817
00:46:24,460 --> 00:46:29,940
 OK, so we're close to this.

818
00:46:29,940 --> 00:46:30,920
 OK?

819
00:46:30,920 --> 00:46:32,620
 This is the direct translation from this.

820
00:46:32,620 --> 00:46:34,980
 Now Alex made an excellent point,

821
00:46:34,980 --> 00:46:36,380
 which I should have repeated, which

822
00:46:36,380 --> 00:46:39,360
 is that there's something wrong with the formulation

823
00:46:39,360 --> 00:46:40,580
 that I've written here.

824
00:46:40,580 --> 00:46:43,660
 If I search over all p's and all r's,

825
00:46:43,660 --> 00:46:45,620
 then there's nothing guaranteeing that I'll get

826
00:46:45,620 --> 00:46:47,380
 a rotation matrix out.

827
00:46:47,380 --> 00:46:50,380
 If I've chosen a 3 by 3 rotation matrices,

828
00:46:50,380 --> 00:46:52,420
 then I need something else to guarantee

829
00:46:52,420 --> 00:46:54,820
 that I'm going to actually get a rotation matrix out.

830
00:46:54,820 --> 00:46:57,060
 Right?

831
00:46:57,060 --> 00:47:01,300
 So the conditions to make a rotation matrix

832
00:47:01,300 --> 00:47:03,060
 are additional constraints, just like we

833
00:47:03,060 --> 00:47:10,260
 added in the QP formulation for the kinematics.

834
00:47:10,260 --> 00:47:13,340
 You can write it a bunch of different ways.

835
00:47:13,340 --> 00:47:17,100
 Roughly, you need r to be orthonormal.

836
00:47:17,100 --> 00:47:18,740
 OK?

837
00:47:18,740 --> 00:47:23,020
 And you need the determinant of r to be positive 1.

838
00:47:23,020 --> 00:47:34,940
 This is equivalent to saying that r transpose is r inverse.

839
00:47:34,940 --> 00:47:35,420
 OK?

840
00:47:35,420 --> 00:47:36,700
 But we'll use this form of it.

841
00:47:36,700 --> 00:47:39,980
 OK.

842
00:47:39,980 --> 00:47:43,620
 Those are the constraints that will guarantee

843
00:47:43,620 --> 00:47:46,100
 that if we solve this optimization problem subject

844
00:47:46,100 --> 00:47:50,580
 to those constraints, then we'll get a good rotation matrix.

845
00:47:50,580 --> 00:47:57,580
 Now this, because of this Ax minus b,

846
00:47:57,580 --> 00:48:02,580
 this is a nice quadratic objective in the sense

847
00:48:02,580 --> 00:48:03,940
 that it's convex.

848
00:48:08,260 --> 00:48:09,420
 Should just say convex.

849
00:48:09,420 --> 00:48:14,900
 What is this?

850
00:48:14,900 --> 00:48:26,780
 The decision variables are the elements of r.

851
00:48:26,780 --> 00:48:27,900
 OK?

852
00:48:27,900 --> 00:48:31,780
 So this is actually nine constraints

853
00:48:31,780 --> 00:48:33,660
 that I've written in this matrix form,

854
00:48:33,660 --> 00:48:36,020
 where all the elements of this thing

855
00:48:36,020 --> 00:48:38,420
 have to equal the elements of this thing.

856
00:48:38,420 --> 00:48:39,500
 OK?

857
00:48:39,500 --> 00:48:42,020
 And each of those nine constraints

858
00:48:42,020 --> 00:48:45,340
 is quadratic in the elements of r.

859
00:48:45,340 --> 00:48:49,700
 I get r1 times r1 plus whatever.

860
00:48:49,700 --> 00:48:50,200
 OK?

861
00:48:50,200 --> 00:48:57,100
 So this is nine quadratic equality constraints.

862
00:48:57,100 --> 00:49:10,340
 And then this one is actually worse.

863
00:49:10,340 --> 00:49:14,620
 Anybody know what the determinant of 3 by 3 matrix

864
00:49:14,620 --> 00:49:17,660
 r's are?

865
00:49:17,660 --> 00:49:22,460
 What degree-- how the coefficients of r enter that?

866
00:49:22,460 --> 00:49:24,180
 You can look up your determined formula,

867
00:49:24,180 --> 00:49:27,340
 and you can-- the 3 by 3 determinant

868
00:49:27,340 --> 00:49:31,660
 is just a sum of 2 by 2 determinants, whatever,

869
00:49:31,660 --> 00:49:32,160
 multiply.

870
00:49:32,160 --> 00:49:36,900
 But this is basically cubic in coefficients of r.

871
00:49:36,900 --> 00:49:44,300
 OK?

872
00:49:44,300 --> 00:49:45,820
 So this one's beautiful.

873
00:49:45,820 --> 00:49:48,060
 This up here, beautiful.

874
00:49:48,060 --> 00:49:50,420
 As with my optimization hat on, this is beautiful.

875
00:49:50,420 --> 00:49:52,500
 This one's like, eh, don't love that.

876
00:49:52,500 --> 00:49:54,500
 But we can maybe deal with that.

877
00:49:54,500 --> 00:49:58,300
 I know a bit about how to do quadratic equality constraints.

878
00:49:58,300 --> 00:50:00,500
 Cubic-- I hate that one.

879
00:50:00,500 --> 00:50:01,100
 OK?

880
00:50:01,100 --> 00:50:04,780
 So here's what most people do, is we're just going to--

881
00:50:04,780 --> 00:50:06,380
 let's pretend that one's not there,

882
00:50:06,380 --> 00:50:07,500
 and we'll deal with it later.

883
00:50:07,500 --> 00:50:08,560
 OK?

884
00:50:08,560 --> 00:50:10,720
 Because it really does make the optimization hard.

885
00:50:10,720 --> 00:50:14,980
 That's an ugly nonlinear constraint, the cubic one.

886
00:50:14,980 --> 00:50:19,260
 Fortunately, if this is true, if we satisfy this,

887
00:50:19,260 --> 00:50:21,900
 then the determinant can actually only be plus or minus

888
00:50:21,900 --> 00:50:24,060
 1.

889
00:50:24,060 --> 00:50:25,940
 So basically, we'll solve it.

890
00:50:25,940 --> 00:50:28,060
 We'll check if the determinant is plus or minus 1.

891
00:50:28,060 --> 00:50:31,180
 If it was minus 1, we'll make our correction and resolve.

892
00:50:31,180 --> 00:50:32,340
 OK?

893
00:50:32,340 --> 00:50:34,740
 And that works out.

894
00:50:34,740 --> 00:50:37,740
 Because writing that constraint directly is gross.

895
00:50:37,740 --> 00:50:48,580
 OK, so a couple questions, just to make

896
00:50:48,580 --> 00:50:50,380
 sure you're following with me.

897
00:50:50,380 --> 00:50:59,060
 So if I have 10 points from my object,

898
00:50:59,060 --> 00:51:00,700
 how many decision variables do I have?

899
00:51:00,700 --> 00:51:08,780
 Mi and Si are-- there's 10 points.

900
00:51:08,780 --> 00:51:13,240
 Yeah?

901
00:51:13,240 --> 00:51:17,640
 [INAUDIBLE]

902
00:51:17,640 --> 00:51:18,720
 Right.

903
00:51:18,720 --> 00:51:19,720
 Right.

904
00:51:19,720 --> 00:51:23,400
 The number of decision variables does not

905
00:51:23,400 --> 00:51:25,080
 change with the number of points.

906
00:51:25,080 --> 00:51:30,520
 I've got 3 by 3 matrix here, and 3 by 1 vector here.

907
00:51:30,520 --> 00:51:33,460
 All that I'm doing, if I have more variables,

908
00:51:33,460 --> 00:51:35,800
 I've just changed my objective function.

909
00:51:35,800 --> 00:51:37,320
 I have more terms in this.

910
00:51:37,320 --> 00:51:38,520
 They sum up.

911
00:51:38,520 --> 00:51:39,360
 OK?

912
00:51:39,360 --> 00:51:41,880
 But I still only have nine decision variables.

913
00:51:41,880 --> 00:51:43,240
 The number of decision variables does not

914
00:51:43,240 --> 00:51:45,080
 depend on the number of points in the scene.

915
00:51:45,080 --> 00:51:54,460
 OK.

916
00:51:54,460 --> 00:51:59,440
 So even this problem, the quadratically constrained

917
00:51:59,440 --> 00:52:02,600
 quadratic objective, that's not a great problem.

918
00:52:02,600 --> 00:52:03,240
 OK?

919
00:52:03,240 --> 00:52:06,040
 In general, we would have to relax it

920
00:52:06,040 --> 00:52:07,960
 to do nice work with it.

921
00:52:07,960 --> 00:52:09,700
 It turns out that this particular problem

922
00:52:09,700 --> 00:52:13,520
 has a beautiful solution, the closed form solution,

923
00:52:13,520 --> 00:52:16,680
 given the singular value decomposition.

924
00:52:16,680 --> 00:52:20,240
 It's one of those quirks where there's

925
00:52:20,240 --> 00:52:22,800
 a bunch of sets of things we know how to solve beautifully

926
00:52:22,800 --> 00:52:23,620
 with optimization.

927
00:52:23,620 --> 00:52:24,960
 There's a bunch of things we can solve

928
00:52:24,960 --> 00:52:26,040
 a bunch of different ways.

929
00:52:26,040 --> 00:52:27,280
 They're all the same set.

930
00:52:27,280 --> 00:52:29,880
 And then there's SVD, which solves these weird problems

931
00:52:29,880 --> 00:52:33,320
 that I don't know totally how to connect.

932
00:52:33,320 --> 00:52:36,000
 This problem, we are going to have a good solution for.

933
00:52:36,000 --> 00:52:39,440
 But I want you to have a little bit of geometric--

934
00:52:39,440 --> 00:52:42,400
 the same way I tried to draw the QPs last time,

935
00:52:42,400 --> 00:52:45,840
 I'm going to try to draw this optimization problem for you

936
00:52:45,840 --> 00:52:49,320
 so you can have some intuition about what's happening.

937
00:52:49,320 --> 00:52:52,240
 To do that, let's do it in 2D real quick.

938
00:52:52,240 --> 00:52:52,740
 OK?

939
00:52:52,740 --> 00:53:00,400
 I hope it will also help you work through the mechanics.

940
00:53:00,400 --> 00:53:01,560
 OK?

941
00:53:01,560 --> 00:53:04,640
 So in 2D, remember our rotation matrices

942
00:53:04,640 --> 00:53:05,800
 are now 2 by 2 matrices.

943
00:53:08,840 --> 00:53:11,960
 We know that they always have the canonical form, right?

944
00:53:11,960 --> 00:53:20,240
 The cosine theta, negative sine theta, sine theta, cos theta.

945
00:53:20,240 --> 00:53:22,160
 That's just background knowledge.

946
00:53:22,160 --> 00:53:23,080
 OK?

947
00:53:23,080 --> 00:53:29,640
 But I'm not going to use theta as my decision variables.

948
00:53:29,640 --> 00:53:33,120
 That would be a-- if I tried to search over thetas,

949
00:53:33,120 --> 00:53:35,480
 then I would have this nonlinear dependence

950
00:53:35,480 --> 00:53:37,520
 through cosine and sine of that.

951
00:53:37,520 --> 00:53:39,880
 And that would be a harder optimization.

952
00:53:39,880 --> 00:53:40,640
 OK?

953
00:53:40,640 --> 00:53:45,480
 I want to leverage the fact that this was a linear term here,

954
00:53:45,480 --> 00:53:49,000
 which turned into a quadratic objective.

955
00:53:49,000 --> 00:53:51,640
 So I have to use the coefficients of r, not theta.

956
00:53:51,640 --> 00:53:54,360
 You know, I can't make the coefficients of r

957
00:53:54,360 --> 00:53:56,640
 nonlinearly depend on my decisions.

958
00:53:56,640 --> 00:53:57,140
 OK?

959
00:53:57,140 --> 00:54:15,860
 So I could just do ABCD as my parameterization.

960
00:54:15,860 --> 00:54:22,340
 In general, in the 3 by 3 case, that is roughly what you do.

961
00:54:22,340 --> 00:54:25,020
 You would fill out the whole 3 by 3 matrix.

962
00:54:25,020 --> 00:54:25,520
 OK?

963
00:54:25,520 --> 00:54:29,020
 In this case, in 2 by 2, everything's better in 2D.

964
00:54:29,020 --> 00:54:29,520
 OK?

965
00:54:29,520 --> 00:54:32,700
 In 2D, you know if you have an orthonormal matrix,

966
00:54:32,700 --> 00:54:36,820
 then you have to have this relationship where I can say--

967
00:54:36,820 --> 00:54:45,940
 I know that's going to be true.

968
00:54:45,940 --> 00:54:48,060
 In order for the orthonormal vector--

969
00:54:48,060 --> 00:54:53,380
 there is exactly one orthonormal vector to this, and it's that.

970
00:54:53,380 --> 00:54:56,420
 OK?

971
00:54:56,420 --> 00:54:58,920
 So this is going to be my parameterization.

972
00:54:58,920 --> 00:55:06,100
 Let's assume that the position is 0 or known,

973
00:55:06,100 --> 00:55:07,780
 just so I can plot the--

974
00:55:07,780 --> 00:55:10,180
 I make a graph over--

975
00:55:10,180 --> 00:55:14,140
 I'm going to basically plot A and B,

976
00:55:14,140 --> 00:55:16,580
 and then I want to plot my objectives and my constraints

977
00:55:16,580 --> 00:55:17,300
 on top of that.

978
00:55:17,300 --> 00:55:17,800
 OK?

979
00:55:17,800 --> 00:55:30,440
 So the objective, we said, is going

980
00:55:30,440 --> 00:55:35,720
 to be quadratic in the coefficients of A and B.

981
00:55:35,720 --> 00:55:39,560
 So A and B, when I multiply things through here,

982
00:55:39,560 --> 00:55:42,600
 each term here is going to be linear until I square it.

983
00:55:42,600 --> 00:55:47,780
 So what's that going to look like as a function of A and B?

984
00:55:47,780 --> 00:55:50,440
 It's going to be a positive quadratic, because it's

985
00:55:50,440 --> 00:55:53,000
 this nice squared form.

986
00:55:53,000 --> 00:55:55,440
 It's going to look like a nice bowl somewhere in my state

987
00:55:55,440 --> 00:55:55,940
 space--

988
00:55:55,940 --> 00:56:02,680
 in my variable space here.

989
00:56:02,680 --> 00:56:05,640
 So I expect that to look like some bowl,

990
00:56:05,640 --> 00:56:06,680
 just like I had last time.

991
00:56:06,680 --> 00:56:11,240
 Now, what do the constraints look like?

992
00:56:14,040 --> 00:56:22,300
 If I have R, R transpose equals I, that's equivalent--

993
00:56:22,300 --> 00:56:23,100
 I write this out.

994
00:56:23,100 --> 00:56:33,100
 What is that going to be?

995
00:56:33,100 --> 00:56:37,740
 So that's going to give me two different constraints.

996
00:56:37,740 --> 00:56:41,780
 I get A squared plus B squared has to equal 1.

997
00:56:41,780 --> 00:56:43,700
 What's this guy here?

998
00:56:43,700 --> 00:56:47,180
 A squared plus B squared equals 1.

999
00:56:47,180 --> 00:56:50,460
 And the off-diagonal-- oops--

1000
00:56:50,460 --> 00:56:55,500
 the off-diagonal says that AB minus BA equals 0.

1001
00:56:55,500 --> 00:56:58,060
 That one's vacuously true, so we don't even

1002
00:56:58,060 --> 00:57:00,540
 need to include it in our optimization.

1003
00:57:00,540 --> 00:57:09,460
 It happens that saying the determinant of R

1004
00:57:09,460 --> 00:57:13,560
 equals plus 1 in 2D, it's just this quadratic again,

1005
00:57:13,560 --> 00:57:20,940
 and it gives me the same constraint.

1006
00:57:20,940 --> 00:57:23,500
 So I've already got that one covered.

1007
00:57:23,500 --> 00:57:26,620
 I'm guaranteed to have a determinant of plus 1

1008
00:57:26,620 --> 00:57:29,820
 because I did this trick.

1009
00:57:29,820 --> 00:57:31,860
 If I had independently parameterized those,

1010
00:57:31,860 --> 00:57:35,380
 I would need to have this constraint.

1011
00:57:35,380 --> 00:57:37,660
 When you have a determinant that's minus 1,

1012
00:57:37,660 --> 00:57:41,660
 that gives you these rotorotations, they're called.

1013
00:57:41,660 --> 00:57:47,560
 So that would be like my vector doing a rotation and a flip.

1014
00:57:47,560 --> 00:57:56,040
 And so by parameterizing this, this is like AB.

1015
00:57:56,040 --> 00:58:06,000
 This is, if you think about it, is A negative B, or negative BA.

1016
00:58:06,000 --> 00:58:08,660
 This is-- that's what I've done here,

1017
00:58:08,660 --> 00:58:11,420
 is parameterized those.

1018
00:58:11,420 --> 00:58:14,400
 This way, so that's only going to give me positive rotations.

1019
00:58:14,400 --> 00:58:16,280
 The rotor rotation would have been down here.

1020
00:58:16,280 --> 00:58:25,720
 I hope I'm not-- I hope I'm saying that well enough

1021
00:58:25,720 --> 00:58:26,320
 to be useful.

1022
00:58:26,320 --> 00:58:37,880
 Good, OK, so we have a quadratic objective over B and A.

1023
00:58:37,880 --> 00:58:41,280
 And we have a constraint, which is a quadratic constraint,

1024
00:58:41,280 --> 00:58:42,840
 A squared plus B squared equals 1.

1025
00:58:42,840 --> 00:58:53,200
 So that's going to be the circle, the unit circle on here.

1026
00:58:53,200 --> 00:58:57,880
 Now, remember that the number of points, that's true no matter

1027
00:58:57,880 --> 00:59:00,440
 how many scene points I put in.

1028
00:59:00,440 --> 00:59:03,920
 So I can make a problem, a real problem, in 2D

1029
00:59:03,920 --> 00:59:06,080
 and have lots of scene points and just build up

1030
00:59:06,080 --> 00:59:08,520
 this different quadratic objective

1031
00:59:08,520 --> 00:59:10,800
 and quadratic constraint.

1032
00:59:10,800 --> 00:59:12,120
 And that's what I've done here.

1033
00:59:12,120 --> 00:59:21,640
 So I've got a real object that I cast some scene points from.

1034
00:59:21,640 --> 00:59:25,920
 And I can turn the object, so I move the data points.

1035
00:59:25,920 --> 00:59:27,920
 I've got theta parameterizing my turn.

1036
00:59:27,920 --> 00:59:33,200
 That's just for my GUI, really, to change the problem data.

1037
00:59:33,200 --> 00:59:38,000
 And the quadratic form, in order to minimize that objective,

1038
00:59:38,000 --> 00:59:41,080
 is moving around.

1039
00:59:41,080 --> 00:59:45,080
 The cool thing is, it wants to be--

1040
00:59:45,080 --> 00:59:47,000
 can you see what's happening here?

1041
00:59:47,000 --> 00:59:51,240
 I hope I can do this without redefining anything.

1042
00:59:51,240 --> 00:59:52,200
 There we go.

1043
00:59:52,200 --> 00:59:53,440
 You see what's happening there?

1044
00:59:53,440 --> 00:59:57,920
 That's the-- that disk is the unit circle constraint just

1045
00:59:57,920 --> 01:00:00,200
 projected up.

1046
01:00:00,200 --> 01:00:06,680
 The minimum of that quadratic form, it wants to be at the--

1047
01:00:06,680 --> 01:00:09,320
 of course, because in order to make those points match

1048
01:00:09,320 --> 01:00:13,240
 through a rotation, it's going to find a rotation that is--

1049
01:00:13,240 --> 01:00:14,800
 in order to make those points match,

1050
01:00:14,800 --> 01:00:16,920
 it's going to find an actual rotation.

1051
01:00:16,920 --> 01:00:18,640
 It's not going to try to shrink anything.

1052
01:00:18,640 --> 01:00:21,640
 It's not going to try to expand anything.

1053
01:00:21,640 --> 01:00:25,800
 So in the noise-free case, it's beautiful and good.

1054
01:00:25,800 --> 01:00:30,040
 If I rotate the object, then I get a different quadratic form

1055
01:00:30,040 --> 01:00:31,560
 that moves around.

1056
01:00:31,560 --> 01:00:36,000
 And that constraint actually doesn't have to do any work.

1057
01:00:36,000 --> 01:00:38,080
 Now, as soon as you have noise, or you

1058
01:00:38,080 --> 01:00:41,760
 have bad correspondences, or anything like that,

1059
01:00:41,760 --> 01:00:43,920
 then what's going to happen is the objective,

1060
01:00:43,920 --> 01:00:46,680
 in order to match my data, the objective

1061
01:00:46,680 --> 01:00:48,440
 is going to get more complicated.

1062
01:00:48,440 --> 01:00:51,360
 And it could move away from the unit circle.

1063
01:00:51,360 --> 01:00:54,520
 And that constraint is going to pull me back.

1064
01:00:54,520 --> 01:00:56,600
 Now, we're going to come back to that later,

1065
01:00:56,600 --> 01:00:59,240
 when we think about a convex relaxation.

1066
01:00:59,240 --> 01:01:00,440
 Oh, that's cool.

1067
01:01:00,440 --> 01:01:01,440
 Didn't mean to do that.

1068
01:01:04,000 --> 01:01:06,160
 New trick.

1069
01:01:06,160 --> 01:01:08,800
 So in general, we might eventually

1070
01:01:08,800 --> 01:01:14,160
 relax the unit circle constraint to the unit disk.

1071
01:01:14,160 --> 01:01:16,600
 So it's easier to write an optimization problem that says

1072
01:01:16,600 --> 01:01:18,400
 I'm anywhere inside of the circle,

1073
01:01:18,400 --> 01:01:20,240
 not just on the boundary of the circle.

1074
01:01:20,240 --> 01:01:24,400
 The boundary of a circle is a non-convex set.

1075
01:01:24,400 --> 01:01:27,160
 But I can say I'm inside a circle,

1076
01:01:27,160 --> 01:01:29,080
 including the interior.

1077
01:01:29,080 --> 01:01:30,960
 And then we're going to see things

1078
01:01:30,960 --> 01:01:34,800
 like the optimization is tight.

1079
01:01:34,800 --> 01:01:37,480
 It will give me the right answer if the quadratic form is

1080
01:01:37,480 --> 01:01:40,440
 pulling me outside.

1081
01:01:40,440 --> 01:01:44,640
 But when it goes inside, I start getting some errors.

1082
01:01:44,640 --> 01:01:45,760
 And that's going to be--

1083
01:01:45,760 --> 01:01:48,680
 even in the most advanced, like, SDP relaxations-- sorry,

1084
01:01:48,680 --> 01:01:51,040
 the semi-definite programming relaxations of point cloud

1085
01:01:51,040 --> 01:01:55,480
 registration that you'll read in papers these years that

1086
01:01:55,480 --> 01:01:57,920
 are still coming out, you're going to see them saying,

1087
01:01:57,920 --> 01:01:59,440
 oh, it's tight often.

1088
01:01:59,440 --> 01:02:01,480
 But there's some cases where it's not tight.

1089
01:02:01,480 --> 01:02:03,040
 It's exactly this picture.

1090
01:02:03,040 --> 01:02:04,760
 It's when it's sliding inside.

1091
01:02:04,760 --> 01:02:06,120
 It's not.

1092
01:02:06,120 --> 01:02:07,960
 OK.

1093
01:02:07,960 --> 01:02:12,320
 Changing the number of points will change the shape

1094
01:02:12,320 --> 01:02:14,120
 of my quadratic bowl.

1095
01:02:14,120 --> 01:02:16,960
 But it doesn't move that constraint.

1096
01:02:16,960 --> 01:02:22,080
 And in the noise-free case, it's not going to move the minimum.

1097
01:02:22,080 --> 01:02:24,280
 So that's the picture I want you to have in your head.

1098
01:02:24,280 --> 01:02:24,780
 OK.

1099
01:02:24,780 --> 01:02:34,640
 Let's make sure you're fully with me here.

1100
01:02:34,640 --> 01:02:41,160
 So here's a couple immediate things that come to mind.

1101
01:02:41,160 --> 01:02:49,000
 My box is symmetric.

1102
01:02:49,000 --> 01:02:51,400
 It has rotational symmetry, especially--

1103
01:02:51,400 --> 01:02:53,680
 I mean, even if it's a rectangle,

1104
01:02:53,680 --> 01:02:54,640
 it's got some symmetry.

1105
01:02:54,640 --> 01:02:56,960
 If it's a cube, it's got lots of symmetry, right?

1106
01:02:56,960 --> 01:03:03,320
 So how do symmetries affect the algorithm?

1107
01:03:03,320 --> 01:03:05,440
 How would they change that picture?

1108
01:03:05,440 --> 01:03:14,520
 My object was suddenly symmetric, or even circular,

1109
01:03:14,520 --> 01:03:16,240
 or something.

1110
01:03:16,240 --> 01:03:17,920
 How would that change that picture?

1111
01:03:17,920 --> 01:03:29,400
 [INAUDIBLE]

1112
01:03:29,400 --> 01:03:29,900
 What's that?

1113
01:03:29,900 --> 01:03:32,880
 [INAUDIBLE]

1114
01:03:32,880 --> 01:03:35,600
 We have-- what would it have to do to that picture?

1115
01:03:35,600 --> 01:03:44,920
 The objective is quadratic.

1116
01:03:44,920 --> 01:03:48,080
 So it can't go up and then go back down.

1117
01:03:48,080 --> 01:03:54,540
 Yeah.

1118
01:03:54,540 --> 01:03:57,360
 [INAUDIBLE]

1119
01:03:57,360 --> 01:04:00,240
 So it's going across both places, right?

1120
01:04:00,240 --> 01:04:00,720
 Yeah.

1121
01:04:00,720 --> 01:04:03,080
 This is all the right stuff to think about.

1122
01:04:03,080 --> 01:04:05,360
 But it can never happen in this case,

1123
01:04:05,360 --> 01:04:09,320
 because we assumed correspondences.

1124
01:04:09,320 --> 01:04:11,200
 So there's no such thing as symmetry,

1125
01:04:11,200 --> 01:04:14,600
 because even if I draw a point that looks like this,

1126
01:04:14,600 --> 01:04:22,520
 the fact that I had a magic correspondence function,

1127
01:04:22,520 --> 01:04:25,240
 even if I were to rotate this, it would correspond to--

1128
01:04:25,240 --> 01:04:29,880
 I've already broken the symmetry by assigning a correspondence.

1129
01:04:29,880 --> 01:04:36,520
 So the pictures you have in your head about symmetries

1130
01:04:36,520 --> 01:04:39,440
 in the correspondence case are wrong.

1131
01:04:39,440 --> 01:04:43,980
 That sounded mean.

1132
01:04:43,980 --> 01:04:45,240
 We're going to solve the correspondence problem

1133
01:04:45,240 --> 01:04:46,440
 in a second.

1134
01:04:46,440 --> 01:04:49,280
 But when you think of that picture,

1135
01:04:49,280 --> 01:04:50,880
 I would immediately think, OK, how

1136
01:04:50,880 --> 01:04:52,440
 does it handle the symmetries case?

1137
01:04:52,440 --> 01:04:54,560
 And you don't have to handle the symmetries case.

1138
01:04:54,560 --> 01:04:56,240
 It does not handle the symmetries case.

1139
01:04:56,240 --> 01:05:00,480
 Another fun one.

1140
01:05:00,480 --> 01:05:02,640
 I won't belabor it, but you think

1141
01:05:02,640 --> 01:05:05,280
 about what's the minimum number of points

1142
01:05:05,280 --> 01:05:09,680
 that you need for this problem to have a unique solution.

1143
01:05:09,680 --> 01:05:11,040
 It's almost what you think, but it

1144
01:05:11,040 --> 01:05:14,980
 might be a little bit more or less than you think.

1145
01:05:14,980 --> 01:05:23,740
 You can do it by just counting the number of decision

1146
01:05:23,740 --> 01:05:27,100
 variables and counting the number of constraints.

1147
01:05:27,100 --> 01:05:29,100
 If you assume that the points are unique,

1148
01:05:29,100 --> 01:05:31,260
 so if the points landed on top of each other,

1149
01:05:31,260 --> 01:05:32,580
 that would be a degenerate case.

1150
01:05:32,580 --> 01:05:34,180
 But if you assume the points are unique,

1151
01:05:34,180 --> 01:05:35,740
 then you can just play a counting game

1152
01:05:35,740 --> 01:05:39,720
 and figure out how many parameters you need.

1153
01:05:39,720 --> 01:05:41,640
 And it'll give you a slightly different answer

1154
01:05:41,640 --> 01:05:44,060
 if you use this clever parameterization in 2D

1155
01:05:44,060 --> 01:05:47,100
 versus the four parameters.

1156
01:05:47,100 --> 01:05:50,580
 But it's all good.

1157
01:05:50,580 --> 01:05:54,420
 You can completely understand this.

1158
01:05:54,420 --> 01:05:56,660
 But let's dig into this a little bit more.

1159
01:05:56,660 --> 01:06:00,380
 So this correspondence function was just

1160
01:06:00,380 --> 01:06:02,940
 too big of an assumption.

1161
01:06:02,940 --> 01:06:06,300
 But that's what made our optimization magically good.

1162
01:06:06,300 --> 01:06:08,100
 The fact that you can solve that, in fact,

1163
01:06:08,100 --> 01:06:12,240
 in a closed form with a call to the singular value

1164
01:06:12,240 --> 01:06:15,920
 decomposition, which is as close as you get numerically,

1165
01:06:15,920 --> 01:06:19,560
 I guess, to a closed form solution.

1166
01:06:19,560 --> 01:06:20,840
 That's amazing.

1167
01:06:20,840 --> 01:06:23,680
 So let's lean on it and come up with an algorithm that

1168
01:06:23,680 --> 01:06:28,760
 solves for the correspondences and the poses simultaneously.

1169
01:06:37,440 --> 01:06:37,940
 OK.

1170
01:06:37,940 --> 01:06:54,000
 The case that we're going to use to think about it

1171
01:06:54,000 --> 01:06:56,520
 is imagine that you've gotten yourself

1172
01:06:56,520 --> 01:06:58,480
 close to the right answer.

1173
01:06:58,480 --> 01:07:05,320
 So I've got my real object and I've got my measured object.

1174
01:07:05,320 --> 01:07:08,360
 So let's say I'm sort of close.

1175
01:07:08,360 --> 01:07:10,280
 Then a reasonable heuristic would

1176
01:07:10,280 --> 01:07:17,960
 be to basically assign the correspondences based

1177
01:07:17,960 --> 01:07:22,600
 on what's close to me.

1178
01:07:22,600 --> 01:07:24,640
 The true correspondence is this.

1179
01:07:24,640 --> 01:07:27,160
 But let's just examine as a heuristic.

1180
01:07:27,160 --> 01:07:30,960
 Given my current guess, this goes back

1181
01:07:30,960 --> 01:07:33,120
 to the differential IK case.

1182
01:07:33,120 --> 01:07:37,440
 So let's think about it sort of in a differential way, where

1183
01:07:37,440 --> 01:07:40,800
 I've got an initial guess and I want to improve it.

1184
01:07:40,800 --> 01:07:43,920
 So what if I use as a heuristic--

1185
01:07:43,920 --> 01:07:46,920
 let me pretend that my correspondences are whichever

1186
01:07:46,920 --> 01:07:49,320
 point I find on the other one that is closest

1187
01:07:49,320 --> 01:07:52,720
 in a Euclidean sense.

1188
01:07:52,720 --> 01:07:55,040
 And maybe the mapping might not be unique.

1189
01:07:55,040 --> 01:07:58,400
 It could be that I map multiple points to the same--

1190
01:07:58,400 --> 01:08:01,600
 multiple model points to the same scene point or vice versa.

1191
01:08:01,600 --> 01:08:05,180
 Typically, you pick one because you search through--

1192
01:08:05,180 --> 01:08:06,980
 you search through either your model points

1193
01:08:06,980 --> 01:08:09,020
 and find the closest scene point or vice versa.

1194
01:08:09,020 --> 01:08:11,040
 OK?

1195
01:08:11,040 --> 01:08:11,760
 All right.

1196
01:08:11,760 --> 01:08:15,120
 So let's say we just assign the correspondences that way,

1197
01:08:15,120 --> 01:08:17,120
 based on the closest points.

1198
01:08:17,120 --> 01:08:19,880
 What would that look like in our optimization?

1199
01:08:19,880 --> 01:08:23,360
 Well, in this, we need a slightly refined notation

1200
01:08:23,360 --> 01:08:23,840
 here.

1201
01:08:23,840 --> 01:08:34,800
 If I write-- let me call it Cj or Ci for correspondence i

1202
01:08:34,800 --> 01:08:36,040
 equals j.

1203
01:08:36,040 --> 01:08:36,800
 OK?

1204
01:08:36,800 --> 01:08:53,520
 This is a model point i corresponds to scene point j

1205
01:08:53,520 --> 01:09:01,360
 that I can write that my thing that I'm searching for here--

1206
01:09:01,360 --> 01:09:05,160
 model-- I'm going to just use the Ci here--

1207
01:09:05,160 --> 01:09:20,720
 minus Pwsi squared as my objective.

1208
01:09:20,720 --> 01:09:23,200
 This is just the Euclidean distance.

1209
01:09:23,200 --> 01:09:23,700
 Right?

1210
01:09:23,700 --> 01:09:31,880
 So for each C-- for each of these model points,

1211
01:09:31,880 --> 01:09:33,920
 I can just look through this.

1212
01:09:33,920 --> 01:09:36,960
 I can just try all of my possible correspondences

1213
01:09:36,960 --> 01:09:40,280
 and find the closest point.

1214
01:09:40,280 --> 01:09:45,120
 That would be something like saying that Ci is like an arg

1215
01:09:45,120 --> 01:09:54,960
 min over j of Mj.

1216
01:09:54,960 --> 01:09:55,440
 OK?

1217
01:09:55,440 --> 01:09:59,040
 So just look through the points, find the closest one,

1218
01:09:59,040 --> 01:10:02,240
 and write it into Ci.

1219
01:10:02,240 --> 01:10:02,740
 OK?

1220
01:10:02,740 --> 01:10:05,080
 This is the closest point.

1221
01:10:05,080 --> 01:10:12,560
 Now, I don't need any constraints here,

1222
01:10:12,560 --> 01:10:16,640
 because in this case, now this is the decision variable,

1223
01:10:16,640 --> 01:10:17,360
 and this is fixed.

1224
01:10:17,360 --> 01:10:20,380
 Right?

1225
01:10:20,380 --> 01:10:22,240
 So that's not-- I don't have to worry about that not

1226
01:10:22,240 --> 01:10:23,240
 being a rotation matrix.

1227
01:10:23,240 --> 01:10:24,160
 That's just fixed.

1228
01:10:24,160 --> 01:10:24,920
 It's a constant.

1229
01:10:24,920 --> 01:10:32,000
 OK.

1230
01:10:32,000 --> 01:10:33,800
 The iterative closest point algorithm,

1231
01:10:33,800 --> 01:10:38,160
 one of the most famous algorithms in point

1232
01:10:38,160 --> 01:10:41,560
 registration, is just this.

1233
01:10:41,560 --> 01:10:51,120
 It's called ICP.

1234
01:10:51,120 --> 01:10:52,080
 OK?

1235
01:10:52,080 --> 01:10:57,960
 It just says, take an initial guess of my pose,

1236
01:10:57,960 --> 01:10:59,480
 solve this problem, OK?

1237
01:10:59,480 --> 01:11:04,040
 Find the correspondences, then solve that problem,

1238
01:11:04,040 --> 01:11:06,920
 then solve this problem, then solve that problem.

1239
01:11:06,920 --> 01:11:07,720
 OK?

1240
01:11:07,720 --> 01:11:10,360
 And iterate until convergence.

1241
01:11:10,360 --> 01:11:13,080
 Convergence is simple.

1242
01:11:13,080 --> 01:11:15,160
 It's an integer-based convergence, right?

1243
01:11:15,160 --> 01:11:18,000
 Once my correspondences don't change,

1244
01:11:18,000 --> 01:11:20,480
 because that solves to global optimality,

1245
01:11:20,480 --> 01:11:22,240
 if the correspondences don't change,

1246
01:11:22,240 --> 01:11:23,960
 then that one's not going to do any work.

1247
01:11:23,960 --> 01:11:27,040
 So you have a complete-- it's not like a floating point

1248
01:11:27,040 --> 01:11:27,600
 convergence.

1249
01:11:27,600 --> 01:11:30,520
 It's like iterations are done.

1250
01:11:30,520 --> 01:11:32,040
 No more work to do.

1251
01:11:32,040 --> 01:11:33,080
 Convergence.

1252
01:11:33,080 --> 01:11:34,560
 Yes?

1253
01:11:34,920 --> 01:11:37,840
 Is it a chance to always converge?

1254
01:11:37,840 --> 01:11:40,520
 Is it guaranteed to always converge?

1255
01:11:40,520 --> 01:11:42,480
 It is certainly not guaranteed to always converge

1256
01:11:42,480 --> 01:11:44,080
 to the right solution.

1257
01:11:44,080 --> 01:11:45,200
 There are local minima.

1258
01:11:45,200 --> 01:11:50,600
 You can find yourself attached, corresponding

1259
01:11:50,600 --> 01:11:53,840
 to the wrong points, and unable to get out.

1260
01:11:53,840 --> 01:11:55,480
 It should always converge, I think.

1261
01:11:55,480 --> 01:11:58,360
 I can't imagine a case where-- is there a way it would

1262
01:11:58,360 --> 01:11:59,800
 oscillate?

1263
01:11:59,800 --> 01:12:00,640
 It's a good question.

1264
01:12:00,640 --> 01:12:01,520
 I don't know for sure.

1265
01:12:01,520 --> 01:12:03,000
 But I think the most important point

1266
01:12:03,000 --> 01:12:06,920
 is it won't necessarily converge to the right solution.

1267
01:12:06,920 --> 01:12:09,280
 So you can certainly get yourself into traps.

1268
01:12:09,280 --> 01:12:19,200
 OK, this is a real algorithm.

1269
01:12:19,200 --> 01:12:23,360
 People use it all the time.

1270
01:12:23,360 --> 01:12:25,640
 No, not on this side.

1271
01:12:25,640 --> 01:12:28,440
 This is one step of the algorithm

1272
01:12:28,440 --> 01:12:31,080
 would be just find the closest points.

1273
01:12:31,080 --> 01:12:35,240
 I have a shaded blue object, and the other object

1274
01:12:35,240 --> 01:12:38,560
 being the transformed object in the pink.

1275
01:12:38,560 --> 01:12:40,240
 Just find the closest point.

1276
01:12:40,240 --> 01:12:43,760
 And if you're-- this is with known correspondences, I guess.

1277
01:12:43,760 --> 01:12:45,920
 Then the match is correct, and it

1278
01:12:45,920 --> 01:12:49,680
 solves the global optimization.

1279
01:12:49,680 --> 01:12:53,320
 And I made a bunch of cutesy animations.

1280
01:12:53,320 --> 01:12:54,480
 Oh, that's not mine.

1281
01:12:54,480 --> 01:12:57,440
 This is the Stanford bunny.

1282
01:12:57,440 --> 01:13:01,080
 But that's the classic iterative closest point graphic

1283
01:13:01,080 --> 01:13:03,640
 you could find all over the place.

1284
01:13:03,640 --> 01:13:06,720
 So there's a lot of points there.

1285
01:13:06,720 --> 01:13:07,840
 You can do this at scale.

1286
01:13:07,840 --> 01:13:13,840
 I forgot to stick in my cutesy graphics.

1287
01:13:13,840 --> 01:13:16,000
 Shoot.

1288
01:13:16,000 --> 01:13:18,320
 But you can do this at scale.

1289
01:13:18,320 --> 01:13:21,320
 In order to scale it up, that problem, again,

1290
01:13:21,320 --> 01:13:23,100
 doesn't get bigger.

1291
01:13:23,100 --> 01:13:25,440
 The objective gets-- there's more terms in the objective.

1292
01:13:25,440 --> 01:13:27,200
 But the decision variables doesn't change.

1293
01:13:27,200 --> 01:13:29,080
 That's fine.

1294
01:13:29,080 --> 01:13:30,640
 This one, the only thing you want to do

1295
01:13:30,640 --> 01:13:33,240
 is make that closest point query faster.

1296
01:13:33,240 --> 01:13:35,320
 So you use clever data structures

1297
01:13:35,320 --> 01:13:39,160
 to make that closest point query faster.

1298
01:13:39,160 --> 01:13:41,520
 In particular, we'll use FLAN, which

1299
01:13:41,520 --> 01:13:46,560
 is a Fast Nearest Neighbor algorithm,

1300
01:13:46,560 --> 01:13:48,320
 in order to make that work.

1301
01:13:48,320 --> 01:13:51,000
 But once you do that, it scales to big problems.

1302
01:13:51,000 --> 01:13:52,680
 And it's practically useful.

1303
01:13:52,680 --> 01:13:57,840
 So this is a close-up view of the wrist

1304
01:13:57,840 --> 01:14:00,720
 camera of the dish-loading robot when it's picking up a mug.

1305
01:14:00,720 --> 01:14:09,720
 Now, why do you think--

1306
01:14:09,720 --> 01:14:11,000
 right here.

1307
01:14:11,000 --> 01:14:13,080
 It stops.

1308
01:14:13,080 --> 01:14:15,560
 You see that little chuk-chuk-chuk-chuk?

1309
01:14:15,560 --> 01:14:16,640
 And then it goes?

1310
01:14:16,640 --> 01:14:20,040
 What do you think's happening there?

1311
01:14:20,040 --> 01:14:23,640
 So it's got a deep perception system, finding mugs,

1312
01:14:23,640 --> 01:14:24,800
 doing planning.

1313
01:14:24,800 --> 01:14:25,800
 Gets all close.

1314
01:14:25,800 --> 01:14:27,800
 But before it picks anything up, it

1315
01:14:27,800 --> 01:14:30,440
 takes a nice shot with the wrist-mounted camera.

1316
01:14:30,440 --> 01:14:32,680
 And it does some ICP registration

1317
01:14:32,680 --> 01:14:34,920
 to align the point clouds right in the hand frame,

1318
01:14:34,920 --> 01:14:37,720
 kik-kik-kik-kik, in order to grab.

1319
01:14:37,720 --> 01:14:41,880
 So for real applications, if you will--

1320
01:14:41,880 --> 01:14:44,400
 I mean, almost real applications, right?

1321
01:14:44,400 --> 01:14:48,040
 Then this is actually a very good algorithm for--

1322
01:14:48,040 --> 01:14:50,240
 especially when you are close to a good solution

1323
01:14:50,240 --> 01:14:53,400
 and you want to refine it.

1324
01:14:53,400 --> 01:14:56,600
 In general, the deep perception approaches

1325
01:14:56,600 --> 01:14:58,800
 are going to do better at the global problem of,

1326
01:14:58,800 --> 01:15:00,800
 I've got-- I don't know where it is in the scene.

1327
01:15:00,800 --> 01:15:03,240
 But for the local problems, the geometric often

1328
01:15:03,240 --> 01:15:04,560
 are still state of the art.

1329
01:15:04,560 --> 01:15:13,880
 And I should say, a couple of things

1330
01:15:13,880 --> 01:15:15,160
 to note about that application.

1331
01:15:15,160 --> 01:15:18,120
 So you have to be careful.

1332
01:15:18,120 --> 01:15:20,760
 Why don't you just get right close to picking the mug up

1333
01:15:20,760 --> 01:15:21,760
 when you do that, right?

1334
01:15:21,760 --> 01:15:24,840
 So as you get closer to the geometry,

1335
01:15:24,840 --> 01:15:28,320
 the depth cameras have a minimum throw, a minimum range, right?

1336
01:15:28,320 --> 01:15:30,160
 So if you get too close, things start

1337
01:15:30,160 --> 01:15:31,600
 disappearing from your point cloud.

1338
01:15:31,600 --> 01:15:32,640
 It's kind of frustrating.

1339
01:15:32,640 --> 01:15:35,080
 You think, oh, the perfect place for a camera?

1340
01:15:35,080 --> 01:15:35,720
 I'll put it in my hand.

1341
01:15:35,720 --> 01:15:37,520
 And then it's like, you can't see anything

1342
01:15:37,520 --> 01:15:40,400
 because you've got a minimum range, OK?

1343
01:15:40,400 --> 01:15:42,400
 So there's some sweet spot where you get just--

1344
01:15:42,400 --> 01:15:44,120
 depending on which camera you've mounted on your hand,

1345
01:15:44,120 --> 01:15:45,160
 you get to a certain distance.

1346
01:15:45,160 --> 01:15:50,160
 You take your best possible point cloud, and off you go.

1347
01:15:50,160 --> 01:15:53,320
 But even when we use-- we still use these kind of algorithms

1348
01:15:53,320 --> 01:15:56,000
 even for our deep learning pipeline.

1349
01:15:56,000 --> 01:15:59,400
 So this is an early version of a tool

1350
01:15:59,400 --> 01:16:04,000
 that has gotten very mature in many labs nowadays,

1351
01:16:04,000 --> 01:16:06,840
 where in order to train a deep learning system, which

1352
01:16:06,840 --> 01:16:11,000
 we will do, we have some CAD models.

1353
01:16:11,000 --> 01:16:12,520
 We have some raw perception data.

1354
01:16:12,520 --> 01:16:16,080
 Like, we took our drill and put it in the space.

1355
01:16:16,080 --> 01:16:18,280
 And we just want to come up with ground truth labels

1356
01:16:18,280 --> 01:16:20,560
 of real world data.

1357
01:16:20,560 --> 01:16:23,960
 We have a human give our initial guess.

1358
01:16:23,960 --> 01:16:27,720
 So the human says, it's around here, here, here, three clicks.

1359
01:16:27,720 --> 01:16:29,760
 And then that's a good enough initial guess

1360
01:16:29,760 --> 01:16:33,320
 that our ICP can go in and do the rest of the work.

1361
01:16:33,320 --> 01:16:35,760
 We label the images as saying that I

1362
01:16:35,760 --> 01:16:39,160
 know that I have pixels there that correspond to the drill.

1363
01:16:39,160 --> 01:16:41,780
 And then I can back out actually all of the different frames

1364
01:16:41,780 --> 01:16:44,320
 that I took now know exactly where the drill is.

1365
01:16:44,320 --> 01:16:46,520
 And you can label-- with a few clicks from the human,

1366
01:16:46,520 --> 01:16:49,120
 you can give a huge training set to a deep network.

1367
01:16:49,120 --> 01:16:57,280
 So it really is-- even though it's our starter algorithm,

1368
01:16:57,280 --> 01:17:01,000
 it really is still a useful algorithm.

1369
01:17:01,000 --> 01:17:03,800
 Let me just end by pointing out a couple things for today.

1370
01:17:03,800 --> 01:17:06,960
 We're going to talk more about the noisy case soon.

1371
01:17:06,960 --> 01:17:09,120
 But let me just-- I think right here on the board,

1372
01:17:09,120 --> 01:17:10,700
 we already have a couple examples that

1373
01:17:11,160 --> 01:17:12,800
 would show some of its limitations.

1374
01:17:12,800 --> 01:17:18,160
 One of those limitations is extreme sensitivity

1375
01:17:18,160 --> 01:17:20,520
 to outliers.

1376
01:17:20,520 --> 01:17:24,400
 If I happen to have a beautiful point cloud

1377
01:17:24,400 --> 01:17:28,800
 around my measured object, and then, I don't know,

1378
01:17:28,800 --> 01:17:33,360
 two extra points way over here, then in my quadratic form,

1379
01:17:33,360 --> 01:17:35,400
 I'm going to-- well, sorry.

1380
01:17:35,400 --> 01:17:39,260
 The original thing-- so if it never corresponds to that,

1381
01:17:39,260 --> 01:17:39,920
 you're fine.

1382
01:17:39,920 --> 01:17:42,720
 But if you get to the point where this thing is pulling you

1383
01:17:42,720 --> 01:17:45,440
 in the wrong direction, then you can

1384
01:17:45,440 --> 01:17:49,120
 have what looks like a pretty good point cloud,

1385
01:17:49,120 --> 01:17:51,840
 have one point pulling me in the wrong direction,

1386
01:17:51,840 --> 01:17:55,400
 totally skew my objective and compromise my results.

1387
01:17:55,400 --> 01:17:58,040
 So there is a sensitivity of the outliers.

1388
01:17:58,040 --> 01:18:01,240
 As soon as you get inside where your argmin is only

1389
01:18:01,240 --> 01:18:04,640
 matching the real object, then things tend to be fairly OK.

1390
01:18:04,640 --> 01:18:09,800
 But if your closest point captures some outlier,

1391
01:18:09,800 --> 01:18:12,600
 then things get bad.

1392
01:18:12,600 --> 01:18:16,040
 And especially because the cost of the outliers,

1393
01:18:16,040 --> 01:18:19,320
 the cost you penalize basically by the length of these rubber

1394
01:18:19,320 --> 01:18:21,520
 bands, roughly.

1395
01:18:21,520 --> 01:18:23,520
 So the bigger the rubber band, the bigger

1396
01:18:23,520 --> 01:18:25,560
 the relative contribution of a single point.

1397
01:18:25,560 --> 01:18:34,120
 And we'll talk about some of the other--

1398
01:18:34,120 --> 01:18:35,760
 what happens in the noisy case and how

1399
01:18:35,760 --> 01:18:38,320
 you can make it more robust next time, too.

1400
01:18:38,320 --> 01:18:40,240
 But let me just say that this one,

1401
01:18:40,240 --> 01:18:41,640
 if we ask the question again, what

1402
01:18:41,640 --> 01:18:53,280
 happens on a rotationally symmetric object,

1403
01:18:53,280 --> 01:18:56,200
 this time it's going to be exactly what we

1404
01:18:56,200 --> 01:18:57,240
 were saying before.

1405
01:18:57,240 --> 01:18:58,240
 Yeah?

1406
01:18:58,240 --> 01:18:58,740
 [INAUDIBLE]

1407
01:18:58,740 --> 01:19:06,280
 Yeah, yeah.

1408
01:19:06,280 --> 01:19:10,080
 I mean, this SVD formulation is beautiful in L2.

1409
01:19:10,080 --> 01:19:12,040
 It's harder in L1.

1410
01:19:12,040 --> 01:19:13,560
 I think what people end up doing--

1411
01:19:13,560 --> 01:19:16,440
 the question was, why not change this to an L1 objective

1412
01:19:16,440 --> 01:19:21,000
 so it's less sensitive to outliers?

1413
01:19:21,000 --> 01:19:25,760
 So if you just did the absolute value, for instance.

1414
01:19:25,760 --> 01:19:28,120
 So it makes the optimization problem a little bit harder.

1415
01:19:28,120 --> 01:19:31,760
 What people tend to do is truncated least squares.

1416
01:19:31,760 --> 01:19:34,120
 So you can solve that as a-- and there's various approaches

1417
01:19:34,120 --> 01:19:35,760
 to solving for that.

1418
01:19:35,760 --> 01:19:38,640
 Or you even, in your closest point algorithm,

1419
01:19:38,640 --> 01:19:41,320
 try to explicitly reject outliers.

1420
01:19:41,320 --> 01:19:43,560
 Also, we'll talk about RANSAC as another--

1421
01:19:43,560 --> 01:19:45,200
 there's a couple different approaches.

1422
01:19:45,200 --> 01:19:47,600
 But normally, it's stick with that.

1423
01:19:47,600 --> 01:19:49,600
 It's a workhorse.

1424
01:19:49,600 --> 01:19:52,160
 And do what you need to to clean it up before you hand it to

1425
01:19:52,160 --> 01:19:52,660
 that.

1426
01:19:52,660 --> 01:19:58,040
 Think about how the iterative closest point algorithm works

1427
01:19:58,040 --> 01:20:00,680
 now for a rotationally symmetric.

1428
01:20:00,680 --> 01:20:04,040
 If I'm off by 90 degrees or 180 degrees,

1429
01:20:04,040 --> 01:20:05,440
 it's going to find matches.

1430
01:20:05,440 --> 01:20:07,440
 They're going to be the wrong matches.

1431
01:20:07,440 --> 01:20:10,200
 But it'll lock itself in and it'll be stuck.

1432
01:20:10,200 --> 01:20:12,040
 So if you don't care, if you don't

1433
01:20:12,040 --> 01:20:15,040
 mind rotational symmetries in your answer, that's fine.

1434
01:20:15,040 --> 01:20:17,560
 But if you were looking for a canonical pose,

1435
01:20:17,560 --> 01:20:18,640
 ICP won't give it to you.

1436
01:20:18,640 --> 01:20:24,320
 Cool.

1437
01:20:24,320 --> 01:20:28,520
 So parts of perception are just kinematics.

1438
01:20:28,520 --> 01:20:31,000
 And this is our first version of the algorithm.

1439
01:20:31,000 --> 01:20:35,120
 We'll get more fancy with it in the next couple lectures.

1440
01:20:35,120 --> 01:20:37,200
 I will go look at DeepNote right now,

