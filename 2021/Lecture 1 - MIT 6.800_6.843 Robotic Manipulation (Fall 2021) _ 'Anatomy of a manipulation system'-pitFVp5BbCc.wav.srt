1
00:00:00,000 --> 00:00:03,160
 (audience chattering)

2
00:00:03,160 --> 00:00:06,300
 - Okay, welcome everybody.

3
00:00:06,300 --> 00:00:09,520
 Thank you for approximately 60 of you showing up

4
00:00:09,520 --> 00:00:12,840
 and thank you to those of you that put up with the fact

5
00:00:12,840 --> 00:00:14,760
 that we don't have a big enough room today.

6
00:00:14,760 --> 00:00:16,520
 We really are trying to resolve it.

7
00:00:16,520 --> 00:00:19,880
 Everybody across, I mean, I've heard about 200 people

8
00:00:19,880 --> 00:00:21,540
 classes that have a 60 person class.

9
00:00:21,540 --> 00:00:24,920
 I've heard all kinds of different problems.

10
00:00:24,920 --> 00:00:26,320
 The institute is trying to juggle,

11
00:00:26,320 --> 00:00:28,280
 the department is certainly trying to juggle

12
00:00:28,280 --> 00:00:30,920
 and I hope we have it resolved by Tuesday, we'll see.

13
00:00:30,920 --> 00:00:35,280
 But thank you for putting up with this today.

14
00:00:35,280 --> 00:00:36,480
 So I'm Russ Tedrick.

15
00:00:36,480 --> 00:00:38,080
 It's actually nice to see,

16
00:00:38,080 --> 00:00:39,760
 some of you I've seen only via Zoom

17
00:00:39,760 --> 00:00:41,380
 and it's nice to see you in person.

18
00:00:41,380 --> 00:00:45,720
 So you do exist and I exist.

19
00:00:45,720 --> 00:00:47,260
 I'm really happy to be back in the room.

20
00:00:47,260 --> 00:00:49,440
 I think just even with the masks,

21
00:00:49,440 --> 00:00:51,280
 just to be able to see people's reactions

22
00:00:51,280 --> 00:00:53,560
 and I will teach better I think

23
00:00:53,560 --> 00:00:57,080
 when I can feel if you guys are getting it or not.

24
00:00:58,080 --> 00:01:02,400
 Let me just start with a little bit of sort of course intro.

25
00:01:02,400 --> 00:01:04,640
 So we're gonna be talking about robotic manipulation.

26
00:01:04,640 --> 00:01:07,080
 I'm gonna tell you what I mean by manipulation,

27
00:01:07,080 --> 00:01:09,560
 which is not obvious.

28
00:01:09,560 --> 00:01:10,760
 Even if you're a robotics expert,

29
00:01:10,760 --> 00:01:13,080
 I think people mean different things

30
00:01:13,080 --> 00:01:15,080
 when they think about manipulation.

31
00:01:15,080 --> 00:01:18,400
 But let me just start by introducing Rachel and Danny

32
00:01:18,400 --> 00:01:21,120
 who are gonna be our TAs for the course.

33
00:01:21,120 --> 00:01:23,180
 In fact, there's so many people that signed up

34
00:01:23,180 --> 00:01:25,160
 that we could potentially have one more TA.

35
00:01:25,160 --> 00:01:28,200
 We'll see if anybody, see how that plays out.

36
00:01:28,200 --> 00:01:32,520
 But Rachel and Danny are fantastic.

37
00:01:32,520 --> 00:01:34,860
 You will find them to be excellent resources.

38
00:01:34,860 --> 00:01:39,160
 So hopefully you'll have found the website.

39
00:01:39,160 --> 00:01:42,240
 It's not too hard to remember the name I hope.

40
00:01:42,240 --> 00:01:46,680
 But we've put basically, we're doing paperless

41
00:01:46,680 --> 00:01:49,120
 and all of the information, all the guidelines,

42
00:01:49,120 --> 00:01:50,500
 the grading rubrics,

43
00:01:50,500 --> 00:01:52,520
 the things that I am officially giving you today,

44
00:01:52,520 --> 00:01:54,240
 I'm giving you through the website.

45
00:01:55,240 --> 00:01:57,840
 One of the big things that changed,

46
00:01:57,840 --> 00:02:00,480
 this is the first time the course has an official number.

47
00:02:00,480 --> 00:02:02,620
 If you're an undergrad and signed up

48
00:02:02,620 --> 00:02:04,080
 as the undergrad version of the class,

49
00:02:04,080 --> 00:02:06,040
 then it's 6.800.

50
00:02:06,040 --> 00:02:07,760
 If you're a grad student or if you're an undergrad

51
00:02:07,760 --> 00:02:09,300
 who wanted to take the grad version of the class,

52
00:02:09,300 --> 00:02:10,740
 it's 6.843.

53
00:02:10,740 --> 00:02:13,520
 The amount of complexity I think,

54
00:02:13,520 --> 00:02:15,120
 from your perspective I hope is very small.

55
00:02:15,120 --> 00:02:17,960
 But from my perspective it was extremely large

56
00:02:17,960 --> 00:02:21,040
 because there's getting all the different symbols

57
00:02:21,040 --> 00:02:23,900
 of can it count for an AAGS, can it count for an II,

58
00:02:23,900 --> 00:02:26,080
 can it count for, I think we got them all.

59
00:02:26,080 --> 00:02:28,480
 If you have any questions about the logistics

60
00:02:28,480 --> 00:02:31,800
 and does it count for X, Y, or Z, feel free to ask.

61
00:02:31,800 --> 00:02:33,740
 I did my very best to get them all.

62
00:02:33,740 --> 00:02:36,960
 One of the things that it does count for,

63
00:02:36,960 --> 00:02:38,400
 which is a big deal for me,

64
00:02:38,400 --> 00:02:41,920
 is that it counts as a CIM for undergrads.

65
00:02:41,920 --> 00:02:46,180
 So it's a communication intensive class now.

66
00:02:46,180 --> 00:02:48,000
 Now the reason for that if you're interested

67
00:02:48,000 --> 00:02:50,200
 is because the department is changing.

68
00:02:50,200 --> 00:02:53,280
 We now have electrical engineering, computer science,

69
00:02:53,280 --> 00:02:56,960
 and a new fraction of the department called AI+D,

70
00:02:56,960 --> 00:02:59,400
 artificial intelligence and decision making.

71
00:02:59,400 --> 00:03:02,340
 And so if we look at our total coverage of classes

72
00:03:02,340 --> 00:03:04,680
 in the department, we wanted to make sure

73
00:03:04,680 --> 00:03:06,820
 that there were enough communication intensive classes

74
00:03:06,820 --> 00:03:10,920
 in all of three and there weren't yet enough in AI+D.

75
00:03:10,920 --> 00:03:13,680
 So we looked around and decided this would be a good class

76
00:03:13,680 --> 00:03:16,040
 since we already have a project that is,

77
00:03:16,040 --> 00:03:20,560
 I think a substantial part of the class.

78
00:03:20,560 --> 00:03:24,160
 We can use our help from the communications department

79
00:03:24,160 --> 00:03:26,580
 and the comparative media studies and writing.

80
00:03:26,580 --> 00:03:28,520
 Laura and Nora will be helping us out

81
00:03:28,520 --> 00:03:29,880
 on the Friday recitations.

82
00:03:29,880 --> 00:03:32,800
 And we're basically, for undergrads taking the class

83
00:03:32,800 --> 00:03:36,560
 of 6.800, think of it as doing a super project

84
00:03:36,560 --> 00:03:38,100
 where we're gonna do a little bit more

85
00:03:38,100 --> 00:03:40,560
 in terms of giving you feedback on the proposal,

86
00:03:40,560 --> 00:03:42,540
 helping to shape the technical argument

87
00:03:42,540 --> 00:03:45,340
 that you're gonna make throughout the actual course

88
00:03:45,340 --> 00:03:47,560
 of the proposal, give you more feedback,

89
00:03:47,560 --> 00:03:51,120
 and expect a higher quality of presentation

90
00:03:51,120 --> 00:03:53,080
 in the final result and you get to count it

91
00:03:53,080 --> 00:03:55,240
 as one of your communication requirements.

92
00:03:55,240 --> 00:03:57,120
 There's also a little bit, before we start the project,

93
00:03:57,120 --> 00:03:58,720
 there'll be a bit of a journal club

94
00:03:58,720 --> 00:04:01,060
 to sort of even understand what it looks like

95
00:04:01,060 --> 00:04:03,140
 to have a good paper.

96
00:04:03,140 --> 00:04:06,460
 So I believe very much in how important it is

97
00:04:06,460 --> 00:04:10,000
 to communicate clearly and I actually would say

98
00:04:10,000 --> 00:04:13,020
 that I'm a little worried about the field right now

99
00:04:13,020 --> 00:04:15,200
 as being kind of, it's exciting and new

100
00:04:15,200 --> 00:04:17,680
 and everybody's publishing but the quality is

101
00:04:17,680 --> 00:04:21,760
 a little bit, you know, in flux, let's say.

102
00:04:21,760 --> 00:04:24,280
 So I actually think it's a great time for us to say,

103
00:04:24,280 --> 00:04:25,880
 hey, what does it look like to have a good paper

104
00:04:25,880 --> 00:04:29,160
 and how do you do an excellent piece of work

105
00:04:29,160 --> 00:04:30,400
 in manipulation?

106
00:04:30,400 --> 00:04:33,360
 So you will meet Laura and Nora soon.

107
00:04:33,360 --> 00:04:36,120
 They probably stayed back because it was crowded today.

108
00:04:36,120 --> 00:04:40,440
 So I hope that all of the distinctions

109
00:04:40,440 --> 00:04:43,880
 between 800 and 843 are carefully articulated

110
00:04:43,880 --> 00:04:44,720
 on the website.

111
00:04:44,720 --> 00:04:46,440
 Try to get all those things right,

112
00:04:46,440 --> 00:04:50,040
 including the slightly different rate distributions

113
00:04:50,040 --> 00:04:53,240
 from 843 to the 800.

114
00:04:53,240 --> 00:04:54,680
 If you were to even scroll up a little bit,

115
00:04:54,680 --> 00:04:58,720
 you'll see there's all of the details about,

116
00:04:58,720 --> 00:05:03,960
 you know, does it count for II, does it count for AGS?

117
00:05:03,960 --> 00:05:06,040
 I tried to get them all on there, okay?

118
00:05:06,040 --> 00:05:08,800
 So if you have any questions about that,

119
00:05:08,800 --> 00:05:12,160
 by all means, just ask but I hope it's clear

120
00:05:12,160 --> 00:05:13,840
 and I hope that it's minimal complexity

121
00:05:13,840 --> 00:05:14,920
 from your perspective.

122
00:05:14,920 --> 00:05:17,760
 I'm excited, I think it's a great opportunity

123
00:05:17,760 --> 00:05:18,600
 for the class.

124
00:05:18,600 --> 00:05:24,080
 Okay, so, you know, the base,

125
00:05:24,080 --> 00:05:26,480
 I'm not gonna spend too much of our time here on logistics

126
00:05:26,480 --> 00:05:27,440
 but just to put them up.

127
00:05:27,440 --> 00:05:32,400
 So our primary means to broadcast to you is through Piazza.

128
00:05:32,400 --> 00:05:35,200
 So you should be able to sign on automatically

129
00:05:35,200 --> 00:05:37,240
 if you have an MIT email address,

130
00:05:37,240 --> 00:05:38,720
 if you're registered for the course

131
00:05:38,720 --> 00:05:41,600
 and you don't have an MIT email address,

132
00:05:41,600 --> 00:05:43,400
 we can add you, no problem.

133
00:05:43,400 --> 00:05:46,320
 You know, officially, I'm only distributing

134
00:05:46,320 --> 00:05:48,080
 the course guidelines through the website.

135
00:05:48,080 --> 00:05:50,000
 So please do take a minute to review them

136
00:05:50,000 --> 00:05:51,720
 if you have any questions about anything,

137
00:05:51,720 --> 00:05:53,800
 anything's unclear, by all means,

138
00:05:53,800 --> 00:05:55,880
 we're ready to answer those questions now.

139
00:05:55,880 --> 00:05:59,780
 I've done a lot of work to try to make

140
00:05:59,780 --> 00:06:02,180
 the lecture notes interactive.

141
00:06:02,180 --> 00:06:04,240
 Actually, some of the, you know,

142
00:06:04,240 --> 00:06:07,600
 there's some advantages to having had a remote Zoom year.

143
00:06:07,600 --> 00:06:10,240
 I spent a lot of time making like interactive graphics

144
00:06:10,240 --> 00:06:12,200
 and things that would work over Zoom.

145
00:06:12,200 --> 00:06:14,880
 And, you know, I don't get to use all of them this year

146
00:06:14,880 --> 00:06:16,840
 but some of them I hope will still be

147
00:06:16,840 --> 00:06:18,640
 a useful set of tools.

148
00:06:18,640 --> 00:06:21,400
 But in particular, you'll see that the lecture notes

149
00:06:21,400 --> 00:06:23,940
 are interactive, you can actually ask questions

150
00:06:23,940 --> 00:06:25,760
 kind of like a Google Doc where you can comment

151
00:06:25,760 --> 00:06:26,900
 and everything like that.

152
00:06:26,900 --> 00:06:29,040
 You can ask questions right on the lecture notes.

153
00:06:29,040 --> 00:06:31,760
 And the lecture notes have interactive simulations

154
00:06:31,760 --> 00:06:35,540
 and visualizations that I hope will help you

155
00:06:35,540 --> 00:06:37,540
 understand the material, that's my goal.

156
00:06:38,600 --> 00:06:43,600
 The basic setup is we'll do a slightly higher cadence

157
00:06:43,600 --> 00:06:47,080
 of smaller problem sets than I've done in the past

158
00:06:47,080 --> 00:06:49,760
 where we'd like to have weekly problem sets

159
00:06:49,760 --> 00:06:51,880
 that, you know, just kind of keep you thinking

160
00:06:51,880 --> 00:06:54,480
 about the course but aren't as heavy

161
00:06:54,480 --> 00:06:56,480
 as some of the previous versions.

162
00:06:56,480 --> 00:06:58,440
 And the big focus for the course is really

163
00:06:58,440 --> 00:07:00,480
 on the final project where we get,

164
00:07:00,480 --> 00:07:01,560
 we're gonna try to give you, you know,

165
00:07:01,560 --> 00:07:04,620
 a good set of examples to work from,

166
00:07:04,620 --> 00:07:07,480
 but this is a chance to really explore

167
00:07:07,480 --> 00:07:10,280
 the diverse range of possible projects and manipulation.

168
00:07:10,280 --> 00:07:16,520
 This is just to show you what that annotation tool

169
00:07:16,520 --> 00:07:17,360
 looks like and everything.

170
00:07:17,360 --> 00:07:19,520
 If you were to look at the course notes,

171
00:07:19,520 --> 00:07:21,820
 then you'll see a bunch of different features

172
00:07:21,820 --> 00:07:25,680
 like the fact that you can comment in the top,

173
00:07:25,680 --> 00:07:27,520
 on the, you know, in the top corner,

174
00:07:27,520 --> 00:07:30,280
 this opens up the comments and you can highlight

175
00:07:30,280 --> 00:07:35,280
 and add comments and the like as you look at the text.

176
00:07:37,360 --> 00:07:39,920
 We'll see, I think it's still an experiment

177
00:07:39,920 --> 00:07:43,400
 in terms of, you know, is that the great way to communicate?

178
00:07:43,400 --> 00:07:45,520
 But I kind of believe that textbooks

179
00:07:45,520 --> 00:07:48,540
 aren't gonna look the same in a few years as they do today,

180
00:07:48,540 --> 00:07:50,040
 and this is maybe my experiment

181
00:07:50,040 --> 00:07:52,080
 in trying to go halfway there.

182
00:07:52,080 --> 00:07:55,240
 And let's, I'll just show you,

183
00:07:55,240 --> 00:07:59,880
 if you click on launch in DeepNote, this is different.

184
00:07:59,880 --> 00:08:03,600
 Some of you who've seen me before have tried Colab.

185
00:08:03,600 --> 00:08:05,100
 I'm trying DeepNote this time.

186
00:08:06,560 --> 00:08:08,440
 I wrote a lot of code in the last few weeks

187
00:08:08,440 --> 00:08:09,960
 to try to make this work.

188
00:08:09,960 --> 00:08:11,960
 There's a small chance that I don't,

189
00:08:11,960 --> 00:08:14,280
 that I missed something or that DeepNote

190
00:08:14,280 --> 00:08:17,000
 isn't quite as robust or something as I hoped,

191
00:08:17,000 --> 00:08:19,660
 but let's hope that this works very, very well.

192
00:08:19,660 --> 00:08:23,280
 I think it's, I hope it will be better

193
00:08:23,280 --> 00:08:25,280
 for the class than Colab.

194
00:08:25,280 --> 00:08:28,440
 And just to give you a quick preview

195
00:08:28,440 --> 00:08:29,320
 of what that looks like,

196
00:08:29,320 --> 00:08:32,260
 so if you were to run the notebook from the first,

197
00:08:33,640 --> 00:08:37,120
 from the first lecture, from the first chapter,

198
00:08:37,120 --> 00:08:41,440
 then you can just run the notebook.

199
00:08:41,440 --> 00:08:47,660
 Your experience will be less haphazard than mine,

200
00:08:47,660 --> 00:08:50,920
 but I'm doing it halfway here.

201
00:08:50,920 --> 00:08:55,920
 Okay, so this is now running a simulation

202
00:08:55,920 --> 00:08:58,560
 on the cloud in DeepNote,

203
00:08:58,560 --> 00:09:02,520
 and it's a fully interactive, full physics simulation

204
00:09:02,520 --> 00:09:04,400
 that you will be able to program and everything,

205
00:09:04,400 --> 00:09:08,360
 but it's got, you know, you can tally operate

206
00:09:08,360 --> 00:09:10,880
 and your robot in the first example,

207
00:09:10,880 --> 00:09:12,080
 and just to prove to you

208
00:09:12,080 --> 00:09:14,600
 that it's a full physics simulation,

209
00:09:14,600 --> 00:09:15,960
 I will pick up the block.

210
00:09:15,960 --> 00:09:17,980
 Oops.

211
00:09:17,980 --> 00:09:23,960
 Maybe I won't, 'cause I jammed my hand into the thing, yeah.

212
00:09:23,960 --> 00:09:24,960
 Anyhow.

213
00:09:24,960 --> 00:09:25,800
 Oh!

214
00:09:25,800 --> 00:09:27,400
 (audience laughing)

215
00:09:27,400 --> 00:09:29,480
 I must have jammed it so hard that I knocked it sideways,

216
00:09:29,480 --> 00:09:31,180
 and it's a planar simulation, but.

217
00:09:31,860 --> 00:09:35,940
 It's also, it's actually a full 3D simulation.

218
00:09:35,940 --> 00:09:39,220
 I think it'll load up now, the 3D version, as soon as I.

219
00:09:39,220 --> 00:09:49,780
 So the fact that we can sort of do this,

220
00:09:49,780 --> 00:09:51,900
 that we can have, there was a time

221
00:09:51,900 --> 00:09:54,260
 where I was trying to put some of the software tools

222
00:09:54,260 --> 00:09:55,460
 and make them available for class,

223
00:09:55,460 --> 00:09:57,500
 and spent a long time working with people.

224
00:09:57,500 --> 00:09:58,380
 How do you install this?

225
00:09:58,380 --> 00:09:59,540
 How do you install that?

226
00:09:59,540 --> 00:10:01,860
 Nowadays, you just open a website,

227
00:10:01,860 --> 00:10:06,360
 and all of the controls and everything are just,

228
00:10:06,360 --> 00:10:09,300
 you know, they're in your browser.

229
00:10:09,300 --> 00:10:11,140
 No install whatsoever.

230
00:10:11,140 --> 00:10:13,580
 You can just run everything remotely.

231
00:10:13,580 --> 00:10:15,540
 You can collaborate in the notebooks in DeepNote

232
00:10:15,540 --> 00:10:17,160
 in ways that you couldn't in Colab,

233
00:10:17,160 --> 00:10:19,020
 but also it's just provisioned differently,

234
00:10:19,020 --> 00:10:21,500
 and I hope I won't be chasing fires

235
00:10:21,500 --> 00:10:23,860
 as Colab upgrades versions and stuff like this.

236
00:10:23,860 --> 00:10:26,340
 I think DeepNote will be a better solution.

237
00:10:26,340 --> 00:10:27,560
 So I hope that works great for you,

238
00:10:27,560 --> 00:10:29,860
 and I would welcome your feedback.

239
00:10:29,860 --> 00:10:33,300
 I would actually say the fact that simulation

240
00:10:33,300 --> 00:10:35,980
 has gotten so good is one of the big reasons

241
00:10:35,980 --> 00:10:37,860
 why I think it's a great time to teach this class,

242
00:10:37,860 --> 00:10:40,060
 is that the fact that you can actually study

243
00:10:40,060 --> 00:10:43,340
 manipulation in simulation, it's a new thing.

244
00:10:43,340 --> 00:10:45,340
 I mean, just a few years ago, people would have said,

245
00:10:45,340 --> 00:10:48,020
 "No way you can do a practical experiment

246
00:10:48,020 --> 00:10:48,860
 "with manipulation.

247
00:10:48,860 --> 00:10:51,380
 "It's too dependent on contact mechanics,

248
00:10:51,380 --> 00:10:52,820
 "which we don't simulate well,

249
00:10:52,820 --> 00:10:55,220
 "and it's too dependent on perception,

250
00:10:55,220 --> 00:10:57,020
 "where we don't simulate cameras well."

251
00:10:57,020 --> 00:10:59,360
 But I think between a combination

252
00:10:59,360 --> 00:11:02,200
 of the contact simulation getting a lot better,

253
00:11:02,200 --> 00:11:05,880
 and game quality engine rendering getting good enough,

254
00:11:05,880 --> 00:11:08,020
 and people believing that you can actually

255
00:11:08,020 --> 00:11:10,380
 train a perception system in simulated images,

256
00:11:10,380 --> 00:11:13,580
 and have it work in reality, it has closed that gap.

257
00:11:13,580 --> 00:11:17,800
 And now we really can do real work.

258
00:11:17,800 --> 00:11:19,580
 In fact, most of our real work on robots,

259
00:11:19,580 --> 00:11:21,680
 we do primarily in simulation,

260
00:11:21,680 --> 00:11:24,360
 and it's only at the end do we actually make sure it works.

261
00:11:24,360 --> 00:11:26,120
 And we're constantly working to close the gap,

262
00:11:26,120 --> 00:11:28,840
 but increasingly more and more of our time

263
00:11:28,840 --> 00:11:30,020
 is spent in simulation.

264
00:11:30,020 --> 00:11:33,720
 So it's a good time.

265
00:11:33,720 --> 00:11:37,400
 We actually do have hardware robots

266
00:11:37,400 --> 00:11:39,600
 that look just like that upstairs in the room.

267
00:11:39,600 --> 00:11:42,280
 We have quite a, not a ton,

268
00:11:42,280 --> 00:11:45,040
 but we have quite a few of them thinking that we had,

269
00:11:45,040 --> 00:11:46,700
 'cause there was an early version of this course

270
00:11:46,700 --> 00:11:50,800
 that I taught with hardware as part of the experiments,

271
00:11:50,800 --> 00:11:52,880
 or part of the, that we had labs.

272
00:11:53,720 --> 00:11:57,240
 It was enrollment limited back then,

273
00:11:57,240 --> 00:11:59,200
 because of limited hardware.

274
00:11:59,200 --> 00:12:02,300
 So we decided to not limit enrollment this time,

275
00:12:02,300 --> 00:12:05,000
 but if people get ambitious and have good projects,

276
00:12:05,000 --> 00:12:06,800
 and wanna try some things on the real hardware,

277
00:12:06,800 --> 00:12:09,760
 we do have robotic arms upstairs ready to go.

278
00:12:09,760 --> 00:12:11,100
 And if you convince me in simulation

279
00:12:11,100 --> 00:12:12,320
 that you're not gonna break my robot,

280
00:12:12,320 --> 00:12:14,980
 then they are available.

281
00:12:22,000 --> 00:12:26,000
 And this is just to show that those kind of simulations,

282
00:12:26,000 --> 00:12:27,440
 they really just do run in the browser,

283
00:12:27,440 --> 00:12:30,700
 and you can embed them in your slides if you want.

284
00:12:30,700 --> 00:12:33,120
 And it was a lot of work,

285
00:12:33,120 --> 00:12:34,880
 but I think it's a cool technology.

286
00:12:34,880 --> 00:12:37,880
 Okay.

287
00:12:37,880 --> 00:12:41,240
 That's the setup.

288
00:12:41,240 --> 00:12:44,240
 So I wanna talk today about,

289
00:12:44,240 --> 00:12:45,600
 what do I mean by manipulation?

290
00:12:45,600 --> 00:12:47,600
 What are you gonna get out of the course?

291
00:12:47,600 --> 00:12:49,840
 I wanna spend just a little bit of time

292
00:12:49,840 --> 00:12:52,060
 talking about why, you know,

293
00:12:52,060 --> 00:12:54,800
 some of the machinery that we will use

294
00:12:54,800 --> 00:12:56,960
 from dynamical systems,

295
00:12:56,960 --> 00:12:59,320
 to, and why I think it's the right machinery

296
00:12:59,320 --> 00:13:03,920
 to span the spectrum from feedback control to perception,

297
00:13:03,920 --> 00:13:05,360
 and even task level planning.

298
00:13:05,360 --> 00:13:08,120
 And then once we have that machinery,

299
00:13:08,120 --> 00:13:10,360
 I'll just give you a whirlwind of the kind of things

300
00:13:10,360 --> 00:13:11,800
 we're gonna build on top of that machinery

301
00:13:11,800 --> 00:13:13,200
 in terms of perception systems,

302
00:13:13,200 --> 00:13:15,480
 and control systems, and the like.

303
00:13:15,480 --> 00:13:18,160
 And end with some goals for the course,

304
00:13:18,160 --> 00:13:19,840
 so you have a sense of what the roadmap is

305
00:13:19,840 --> 00:13:21,080
 for the rest of the term.

306
00:13:21,080 --> 00:13:25,000
 Okay, what do I mean by manipulation?

307
00:13:25,000 --> 00:13:27,040
 Right, so Matt Mason, actually,

308
00:13:27,040 --> 00:13:29,320
 who's one of the, you know, actually,

309
00:13:29,320 --> 00:13:33,040
 yes, one of Rachel's former advisors in a way,

310
00:13:33,040 --> 00:13:35,560
 and one of the founders in the field.

311
00:13:35,560 --> 00:13:37,800
 He's at Carnegie Mellon these days,

312
00:13:37,800 --> 00:13:38,740
 and Berkshire Gray.

313
00:13:38,740 --> 00:13:44,360
 He wrote a great survey paper toward robotic manipulation.

314
00:13:44,360 --> 00:13:49,240
 It's a, you know, it's a fantastic read.

315
00:13:49,240 --> 00:13:51,680
 It's referenced also in the text.

316
00:13:51,680 --> 00:13:53,800
 But one of the things I liked that he did in that paper

317
00:13:53,800 --> 00:13:55,840
 was he tried to define manipulation,

318
00:13:55,840 --> 00:13:58,240
 which people don't do so carefully, right?

319
00:13:58,240 --> 00:14:00,960
 But he refused to give just one definition.

320
00:14:00,960 --> 00:14:03,240
 He gave like five, and they were all, you know.

321
00:14:03,240 --> 00:14:04,600
 I won't give all of them.

322
00:14:04,600 --> 00:14:08,840
 But he started with just manipulation

323
00:14:08,840 --> 00:14:12,080
 refers to activities performed by hands.

324
00:14:12,080 --> 00:14:13,760
 Okay, that's sort of a simple one.

325
00:14:14,760 --> 00:14:16,600
 By the way, I felt that I had to call

326
00:14:16,600 --> 00:14:18,640
 the class robotic manipulation,

327
00:14:18,640 --> 00:14:20,880
 just so that, you know, a non-roboticist

328
00:14:20,880 --> 00:14:22,920
 who stumbled on the website didn't think we were,

329
00:14:22,920 --> 00:14:27,200
 you know, trying to affect politics or anything like that.

330
00:14:27,200 --> 00:14:30,720
 Right, so, but in this room,

331
00:14:30,720 --> 00:14:32,960
 we'll just say manipulation and call it good.

332
00:14:32,960 --> 00:14:35,640
 Let's see, so Matt Mason,

333
00:14:35,640 --> 00:14:39,440
 and our manipulation is about activities performed by hands.

334
00:14:39,440 --> 00:14:43,040
 And he gives a series of other sort of definitions,

335
00:14:43,040 --> 00:14:45,080
 but they all kind of build up to this idea

336
00:14:45,080 --> 00:14:49,200
 that really manipulation refers to an agent's control

337
00:14:49,200 --> 00:14:53,960
 of its environment through selective contact.

338
00:14:53,960 --> 00:14:56,400
 Okay, so some people debate about

339
00:14:56,400 --> 00:14:58,320
 whether leg and locomotion and manipulation

340
00:14:58,320 --> 00:15:00,880
 are the same thing, walking his legs upside down.

341
00:15:00,880 --> 00:15:03,200
 You know, they do certainly have a lot in common.

342
00:15:03,200 --> 00:15:06,920
 They also have different points of emphasis.

343
00:15:06,920 --> 00:15:10,040
 I'm originally someone who worked a lot on legged robots,

344
00:15:10,040 --> 00:15:12,480
 and I'm focusing on manipulation more these days.

345
00:15:13,320 --> 00:15:17,240
 But that is a really, I think, good definition

346
00:15:17,240 --> 00:15:18,880
 and important definition.

347
00:15:18,880 --> 00:15:21,200
 I'd say even a defining definition, right?

348
00:15:21,200 --> 00:15:23,840
 So compared to a lot of robotics,

349
00:15:23,840 --> 00:15:26,600
 I mean, so our UAVs are just fantastically cool

350
00:15:26,600 --> 00:15:28,080
 and good these days,

351
00:15:28,080 --> 00:15:29,840
 and the things that you can do with a drone

352
00:15:29,840 --> 00:15:31,360
 is just out of this world.

353
00:15:31,360 --> 00:15:34,360
 But maybe we haven't fully realized the dream of robotics

354
00:15:34,360 --> 00:15:36,680
 if we're not touching the world.

355
00:15:36,680 --> 00:15:40,000
 You know, so making, you know,

356
00:15:40,000 --> 00:15:41,480
 selective contact with the world,

357
00:15:41,480 --> 00:15:45,440
 I think, is one of the charters of robotics.

358
00:15:45,440 --> 00:15:47,240
 And I think compared to locomotion,

359
00:15:47,240 --> 00:15:49,720
 I'll try to say in a few examples,

360
00:15:49,720 --> 00:15:51,240
 I think compared to locomotion,

361
00:15:51,240 --> 00:15:54,160
 the connections to perception for manipulation

362
00:15:54,160 --> 00:15:56,880
 are much stronger, much deeper,

363
00:15:56,880 --> 00:15:58,920
 and that'll be a big topic in the course.

364
00:15:58,920 --> 00:16:03,680
 Now, another group of people, I think,

365
00:16:03,680 --> 00:16:06,360
 hear manipulation and think of sort of this kind of example,

366
00:16:06,360 --> 00:16:08,480
 the one I just sort of tele-opted badly,

367
00:16:09,360 --> 00:16:11,480
 where you have, you know, a robot

368
00:16:11,480 --> 00:16:15,120
 that's just picking and placing things in the world.

369
00:16:15,120 --> 00:16:16,520
 Maybe the world is simple,

370
00:16:16,520 --> 00:16:20,200
 like the old way that robots were in factories.

371
00:16:20,200 --> 00:16:22,320
 Increasingly, we're trying to make them work

372
00:16:22,320 --> 00:16:24,760
 in much messier situations.

373
00:16:24,760 --> 00:16:28,960
 But for me, it's very important that you come away

374
00:16:28,960 --> 00:16:32,800
 thinking that manipulation is much more than pick and place.

375
00:16:32,800 --> 00:16:36,560
 Okay, so it is true that you can do manipulation

376
00:16:36,560 --> 00:16:39,200
 by getting a situation where you can make

377
00:16:39,200 --> 00:16:41,840
 what we call an enveloping grasp.

378
00:16:41,840 --> 00:16:44,360
 You know, get your hand around and grab something

379
00:16:44,360 --> 00:16:47,120
 and then roughly assume it's welded to your hand,

380
00:16:47,120 --> 00:16:50,160
 move your robot around the way it did and drop it off.

381
00:16:50,160 --> 00:16:51,920
 You've accomplished manipulation.

382
00:16:51,920 --> 00:16:54,360
 But this is a small sliver

383
00:16:54,360 --> 00:16:56,200
 of what humans can do with their hands

384
00:16:56,200 --> 00:16:59,840
 and really not the full glory

385
00:16:59,840 --> 00:17:01,960
 that we're trying to achieve in the class.

386
00:17:01,960 --> 00:17:05,200
 I would like much more to come from our systems,

387
00:17:05,200 --> 00:17:08,200
 you know, just as a fun example,

388
00:17:08,200 --> 00:17:11,360
 you know, this is a lot more than pick and place, right?

389
00:17:11,360 --> 00:17:14,520
 And we still don't have robots that can do this, right?

390
00:17:14,520 --> 00:17:16,960
 So I'm not promising that this will be like lecture four,

391
00:17:16,960 --> 00:17:21,360
 but this is tough stuff, right?

392
00:17:21,360 --> 00:17:24,080
 And I mean, just even thinking about

393
00:17:24,080 --> 00:17:27,560
 how I would simulate the string is pretty tough.

394
00:17:27,560 --> 00:17:29,800
 The contact mechanics between those fingers

395
00:17:29,800 --> 00:17:34,800
 and the string, the topological planning

396
00:17:34,800 --> 00:17:37,200
 that we're doing here, you know,

397
00:17:37,200 --> 00:17:39,920
 this is the good stuff, okay?

398
00:17:39,920 --> 00:17:41,160
 And I would actually think,

399
00:17:41,160 --> 00:17:42,640
 even, I mean, of course, tying your shoes

400
00:17:42,640 --> 00:17:45,240
 is one thing that we do with our hands,

401
00:17:45,240 --> 00:17:49,080
 but I would argue that most of the things

402
00:17:49,080 --> 00:17:52,400
 you do with your hands have some of the characteristics

403
00:17:52,400 --> 00:17:55,640
 of this and don't look as much like the, you know,

404
00:17:55,640 --> 00:17:58,280
 grab the thing, make sure it's welded to my hand

405
00:17:58,280 --> 00:17:59,400
 and move through the world.

406
00:17:59,400 --> 00:18:01,080
 I think we're actually, as humans,

407
00:18:01,080 --> 00:18:03,200
 rarely doing the simple version.

408
00:18:03,200 --> 00:18:06,040
 (papers rustling)

409
00:18:06,040 --> 00:18:10,680
 So one of the things that's great about manipulation

410
00:18:10,680 --> 00:18:14,520
 is that it really does, if you care about AI,

411
00:18:14,520 --> 00:18:18,000
 and you care about, and maybe believe like I do,

412
00:18:18,000 --> 00:18:22,440
 that for AI to be complete,

413
00:18:22,440 --> 00:18:24,960
 we have to somehow embody it in the world.

414
00:18:24,960 --> 00:18:30,160
 Manipulation really connects a lot of the higher level

415
00:18:30,160 --> 00:18:33,600
 task reasoning, scene understanding problems

416
00:18:33,600 --> 00:18:35,280
 in artificial intelligence

417
00:18:35,280 --> 00:18:37,440
 with some of the low level dynamics and controls

418
00:18:37,440 --> 00:18:40,120
 that I love.

419
00:18:40,120 --> 00:18:42,320
 So I can tell that quickly in just one example

420
00:18:42,320 --> 00:18:44,400
 that we've spent a lot of time on,

421
00:18:44,400 --> 00:18:47,560
 which is a robot that can load the dishwasher, okay?

422
00:18:47,560 --> 00:18:51,480
 So if you just think, what would it take to program a system

423
00:18:51,480 --> 00:18:55,320
 so that Siwon can dump whatever he wants in the sink,

424
00:18:55,320 --> 00:18:58,360
 including some plates and some mugs and some spoons,

425
00:18:58,360 --> 00:19:02,480
 and the robot could go from there to a robust system

426
00:19:02,480 --> 00:19:05,000
 that can open and close the dishwasher,

427
00:19:05,000 --> 00:19:08,920
 it can pull mugs and plates out of the sink,

428
00:19:08,920 --> 00:19:10,880
 put the mugs in the top rack,

429
00:19:10,880 --> 00:19:12,760
 put the plates in the bottom rack,

430
00:19:12,760 --> 00:19:16,960
 put the silverware in the little slidey drawer thing

431
00:19:16,960 --> 00:19:18,680
 that some of our dishwashers have these days,

432
00:19:18,680 --> 00:19:21,420
 and discard anything else off to the side.

433
00:19:21,420 --> 00:19:25,080
 There's a lot going on in here.

434
00:19:25,080 --> 00:19:27,320
 I mean, first of all, you should ask,

435
00:19:27,320 --> 00:19:30,160
 why is it even setting things down on the countertop?

436
00:19:30,160 --> 00:19:31,600
 We'll talk more about that later,

437
00:19:31,600 --> 00:19:34,320
 but actually, one of the biggest reasons for that

438
00:19:34,320 --> 00:19:36,640
 is because the hand is too clunky.

439
00:19:36,640 --> 00:19:38,460
 It's not a very dexterous hand.

440
00:19:38,460 --> 00:19:42,080
 So it's very hard, you can't do in-hand reorientation

441
00:19:42,080 --> 00:19:44,040
 very well with a two-fingered gripper.

442
00:19:44,040 --> 00:19:45,560
 So we end up having to set it down

443
00:19:45,560 --> 00:19:46,600
 in order to grab it again,

444
00:19:46,600 --> 00:19:49,320
 in order to put it down in an orientation

445
00:19:49,320 --> 00:19:51,880
 that's suitable for the dishwasher.

446
00:19:51,880 --> 00:19:53,640
 Another reason for that is that the hand

447
00:19:53,640 --> 00:19:55,320
 is just big and clunky,

448
00:19:55,320 --> 00:19:59,440
 and it occludes all of our cameras

449
00:19:59,440 --> 00:20:01,560
 when we stick it down into the sink.

450
00:20:01,560 --> 00:20:04,120
 So sometimes we grab something,

451
00:20:04,120 --> 00:20:05,480
 and we just wanna make sure we grab

452
00:20:05,480 --> 00:20:07,080
 what we thought we grabbed, so we set it down,

453
00:20:07,080 --> 00:20:07,900
 and we move our hand away,

454
00:20:07,900 --> 00:20:09,320
 and make sure that the cameras can see it,

455
00:20:09,320 --> 00:20:10,800
 and then we can finish.

456
00:20:10,800 --> 00:20:14,440
 So to get a high level of robustness in that system,

457
00:20:14,440 --> 00:20:16,920
 today, we needed to drop things off on the countertop

458
00:20:16,920 --> 00:20:19,000
 in order to go all the way there.

459
00:20:19,000 --> 00:20:20,720
 We've got versions that don't have to do that,

460
00:20:20,720 --> 00:20:25,040
 but it's maybe a small window

461
00:20:25,040 --> 00:20:26,940
 into how complex the problems are.

462
00:20:26,940 --> 00:20:31,400
 There's a lot going on in that example.

463
00:20:31,400 --> 00:20:32,760
 There's a lot of different,

464
00:20:32,760 --> 00:20:36,580
 say, maybe feedback skills in terms of motion planning

465
00:20:36,580 --> 00:20:40,640
 and control of how it has to open the dishwasher,

466
00:20:40,640 --> 00:20:42,600
 how it can pick things up,

467
00:20:42,600 --> 00:20:44,480
 how it can maybe nudge things out of the corner.

468
00:20:44,480 --> 00:20:45,320
 That's another problem.

469
00:20:45,320 --> 00:20:47,780
 The hand is so big that if there's an object

470
00:20:47,780 --> 00:20:49,200
 down in the corner of the sink,

471
00:20:49,200 --> 00:20:50,960
 it can't do an enveloping grasp.

472
00:20:50,960 --> 00:20:53,120
 It has to nudge it back into the center,

473
00:20:53,120 --> 00:20:55,840
 get its hand around it in order to pick it up.

474
00:20:55,840 --> 00:20:57,000
 Okay?

475
00:20:57,000 --> 00:21:00,160
 And there's some of this multi-contact selective contact

476
00:21:00,160 --> 00:21:02,840
 that's pretty complicated, pretty subtle.

477
00:21:02,840 --> 00:21:05,580
 So like the hand in order to pick up a plate from a stack

478
00:21:05,580 --> 00:21:08,320
 has to kind of slide its fingers between the plates

479
00:21:08,320 --> 00:21:10,680
 in order to do it.

480
00:21:10,680 --> 00:21:14,240
 This is also a demonstration of how simulation and reality

481
00:21:14,240 --> 00:21:17,060
 are increasingly close.

482
00:21:17,860 --> 00:21:20,520
 (clears throat)

483
00:21:20,520 --> 00:21:25,140
 And this is actually, I forgot to autoplay this.

484
00:21:25,140 --> 00:21:30,820
 This is, so this is roughly the same kind of simulation,

485
00:21:30,820 --> 00:21:32,380
 but it's rendered nicely this time.

486
00:21:32,380 --> 00:21:34,880
 So when we're working on our feedback controllers,

487
00:21:34,880 --> 00:21:37,380
 we don't bother to send the images

488
00:21:37,380 --> 00:21:39,900
 through a blender rendering scheme.

489
00:21:39,900 --> 00:21:41,620
 But if we're training our perception systems,

490
00:21:41,620 --> 00:21:43,860
 then we do the extra step of trying to make

491
00:21:43,860 --> 00:21:48,780
 a visually realistic render of the scene.

492
00:21:48,780 --> 00:21:51,980
 And it's just incredible what you can do

493
00:21:51,980 --> 00:21:55,220
 if you put all the tools together.

494
00:21:55,220 --> 00:21:58,820
 So that's a dexterous hand picking up the plate,

495
00:21:58,820 --> 00:22:00,080
 but that's a simulation.

496
00:22:00,080 --> 00:22:03,340
 Looks pretty, to my eyes, it looks pretty darn good.

497
00:22:03,340 --> 00:22:06,020
 There's like a few artifacts that you can see

498
00:22:06,020 --> 00:22:07,220
 and realize it's a simulation,

499
00:22:07,220 --> 00:22:08,500
 but it looks pretty darn good.

500
00:22:08,500 --> 00:22:10,860
 And it's good enough to trick

501
00:22:10,860 --> 00:22:12,860
 the deep learning systems these days.

502
00:22:12,860 --> 00:22:16,320
 So that's, I guess, what matters, right?

503
00:22:16,320 --> 00:22:20,940
 So it's a great time.

504
00:22:20,940 --> 00:22:22,200
 And this is a fun, I think,

505
00:22:22,200 --> 00:22:24,580
 a fun full stack manipulation example.

506
00:22:24,580 --> 00:22:30,020
 It's also got some task level robustness

507
00:22:30,020 --> 00:22:32,340
 in the sense that if it's doing one task

508
00:22:32,340 --> 00:22:34,700
 and someone comes in and antagonizes it,

509
00:22:34,700 --> 00:22:37,260
 it's not quite the same as a Boston Dynamics hockey stick,

510
00:22:37,260 --> 00:22:38,460
 but something like that,

511
00:22:38,460 --> 00:22:41,180
 that it's smart enough to set the mug down.

512
00:22:41,820 --> 00:22:44,780
 So it's got a whole higher level reasoning system

513
00:22:44,780 --> 00:22:46,380
 that's thinking about what it's doing.

514
00:22:46,380 --> 00:22:49,620
 Is it still able to do what it was trying to do?

515
00:22:49,620 --> 00:22:51,940
 And this is just another level of complexity,

516
00:22:51,940 --> 00:22:54,680
 which is a more AI planning level of complexity

517
00:22:54,680 --> 00:22:57,620
 sitting on top of all the feedback control

518
00:22:57,620 --> 00:22:59,660
 and perceptions and everything like that.

519
00:22:59,660 --> 00:23:02,940
 So I really think it does,

520
00:23:02,940 --> 00:23:04,580
 manipulation does a beautiful job

521
00:23:04,580 --> 00:23:07,140
 of forcing you to go up and down the entire stack.

522
00:23:07,140 --> 00:23:10,900
 I made a ladder to say it, right?

523
00:23:10,900 --> 00:23:12,660
 Task level planning at the high level,

524
00:23:12,660 --> 00:23:14,940
 low level perception and control

525
00:23:14,940 --> 00:23:16,700
 to do feedback at the low level.

526
00:23:16,700 --> 00:23:20,080
 And it asks us to span that whole space.

527
00:23:20,080 --> 00:23:22,500
 Right, in general, I think even just connecting

528
00:23:22,500 --> 00:23:27,480
 learning and planning and reasoning systems to physics

529
00:23:27,480 --> 00:23:30,740
 asks you to do, to answer some other basic questions

530
00:23:30,740 --> 00:23:32,500
 that we don't often answer

531
00:23:32,500 --> 00:23:34,060
 in our machine learning pipelines these days.

532
00:23:34,060 --> 00:23:37,380
 Like, oftentimes we're collecting data,

533
00:23:37,380 --> 00:23:38,980
 labeling it offline,

534
00:23:38,980 --> 00:23:42,460
 letting the servers train on the data

535
00:23:42,460 --> 00:23:43,820
 for however long it takes,

536
00:23:43,820 --> 00:23:45,500
 and then taking the output and running it.

537
00:23:45,500 --> 00:23:48,060
 But really cognition is a dynamical system, right?

538
00:23:48,060 --> 00:23:49,660
 We're constant, we should be talking about

539
00:23:49,660 --> 00:23:51,620
 the way that the data enters,

540
00:23:51,620 --> 00:23:54,420
 how do we have a constant stream of data coming in?

541
00:23:54,420 --> 00:23:56,120
 How do we adjust our parameters?

542
00:23:56,120 --> 00:23:59,020
 And I think, you know, asking the questions

543
00:23:59,020 --> 00:24:01,820
 of how does that component actually play out

544
00:24:01,820 --> 00:24:03,380
 all the way down in the physics engine,

545
00:24:03,380 --> 00:24:04,540
 and how do those work together?

546
00:24:04,540 --> 00:24:06,460
 And what are the timing semantics?

547
00:24:06,460 --> 00:24:07,900
 You know, it really begs some of the,

548
00:24:07,900 --> 00:24:10,380
 I think, richer questions that we will be getting into

549
00:24:10,380 --> 00:24:14,620
 as AI and machine learning continues to evolve.

550
00:24:14,620 --> 00:24:18,100
 I come from a bit of a,

551
00:24:18,100 --> 00:24:19,820
 more of dynamics and controls perspective.

552
00:24:19,820 --> 00:24:21,940
 A few of you have taken underactuated with me,

553
00:24:21,940 --> 00:24:24,980
 so from that perspective, you know,

554
00:24:24,980 --> 00:24:26,860
 this class is gonna be different, you know,

555
00:24:26,860 --> 00:24:30,780
 but I wanna make sure I tell you sort of what's,

556
00:24:30,780 --> 00:24:32,740
 you know, point out some of those differences.

557
00:24:32,740 --> 00:24:35,180
 Right, so I worked on humanoid robots.

558
00:24:35,180 --> 00:24:37,740
 This is the Boston Dynamics early version

559
00:24:37,740 --> 00:24:39,340
 of the Atlas robot.

560
00:24:39,340 --> 00:24:42,060
 This is the big clunky one that the new sleek one

561
00:24:42,060 --> 00:24:45,580
 is doing all the dancing and the parkour.

562
00:24:45,580 --> 00:24:49,740
 But we trained it to, we programmed it, I would say,

563
00:24:49,740 --> 00:24:54,140
 to do this disaster response scenario

564
00:24:54,140 --> 00:24:56,900
 for the DARPA Robotics Challenge.

565
00:24:56,900 --> 00:24:57,980
 And in doing that, you know,

566
00:24:57,980 --> 00:25:00,940
 we thought a lot about planning and control,

567
00:25:00,940 --> 00:25:02,460
 and that's, you know, we talk a lot about that

568
00:25:02,460 --> 00:25:07,300
 in underactuated, my other graduate robotics class.

569
00:25:07,300 --> 00:25:09,700
 This is just an example of the feedback control

570
00:25:09,700 --> 00:25:12,220
 that the robot has to do as Andres and Lucas

571
00:25:12,220 --> 00:25:14,580
 jump on the Polaris while the robot's trying to balance

572
00:25:14,580 --> 00:25:16,460
 on one foot because that's how it had to get out

573
00:25:16,460 --> 00:25:17,740
 of the Polaris.

574
00:25:17,740 --> 00:25:19,460
 Okay, so there's a lot of work there

575
00:25:19,460 --> 00:25:22,580
 about just even, you know, stability and balance

576
00:25:22,580 --> 00:25:24,540
 and feedback control.

577
00:25:24,540 --> 00:25:26,460
 Okay, and you might ask, you know,

578
00:25:26,460 --> 00:25:29,020
 does that stuff matter for manipulation, right?

579
00:25:29,020 --> 00:25:31,660
 I'm just picking up red blocks, right?

580
00:25:31,660 --> 00:25:33,740
 And it's a fair question, actually,

581
00:25:33,740 --> 00:25:36,620
 but one of the first things that's different

582
00:25:36,620 --> 00:25:40,700
 is the way that manipulation demands more from you

583
00:25:40,700 --> 00:25:41,580
 from perception.

584
00:25:41,580 --> 00:25:46,020
 So when we were doing perception on Atlas,

585
00:25:46,020 --> 00:25:47,860
 our perception system looked like this, right?

586
00:25:47,860 --> 00:25:49,820
 It would kind of evaluate the world,

587
00:25:49,820 --> 00:25:52,460
 but only in sort of a geometric way, right?

588
00:25:52,460 --> 00:25:55,420
 So it was trying to reason about places it could step,

589
00:25:55,420 --> 00:25:56,780
 places it couldn't step.

590
00:25:56,780 --> 00:26:00,900
 But really, once it got sort of a physical understanding

591
00:26:00,900 --> 00:26:04,140
 of the static world, it could do what it needed to do

592
00:26:04,140 --> 00:26:06,900
 in order to, and it knew a lot about its own body.

593
00:26:06,900 --> 00:26:10,540
 And the control system could be tuned for its own body.

594
00:26:10,540 --> 00:26:12,980
 It can do a lot of what it needed to do.

595
00:26:12,980 --> 00:26:15,100
 If you look at some of the newest videos coming out

596
00:26:15,100 --> 00:26:18,660
 from Boss Dynamics, they're doing a way better job,

597
00:26:18,660 --> 00:26:21,500
 but they're still able to do, they're in a regime,

598
00:26:21,500 --> 00:26:23,940
 you know, this is, let's say, the Atlas doing parkour

599
00:26:23,940 --> 00:26:28,020
 or the Ninja Warrior style gymnastics, right?

600
00:26:28,020 --> 00:26:30,140
 They're still evaluating the world

601
00:26:30,140 --> 00:26:32,180
 because that's all you need to do for locomotion,

602
00:26:32,180 --> 00:26:33,620
 for a lot of locomotion,

603
00:26:33,620 --> 00:26:35,420
 as kind of like understanding the geometry,

604
00:26:35,420 --> 00:26:38,140
 finding the places you can throw your feet down, right?

605
00:26:38,140 --> 00:26:39,700
 What's gonna support my weight?

606
00:26:39,700 --> 00:26:44,340
 Think about, you know, loading the dishwasher, right?

607
00:26:44,340 --> 00:26:47,260
 It's not as cool as doing parkour,

608
00:26:47,260 --> 00:26:51,820
 but it demands a lot more from your perception system

609
00:26:51,820 --> 00:26:54,700
 and the connection between perception and control.

610
00:26:54,700 --> 00:26:56,180
 It just demands a lot more, right?

611
00:26:56,180 --> 00:26:58,860
 So we have to not just understand

612
00:26:58,860 --> 00:27:01,900
 this is the same sort of rendered simulation of the sink.

613
00:27:01,900 --> 00:27:03,540
 There's a bunch of mugs in there.

614
00:27:03,540 --> 00:27:06,140
 This is the output of the perception system

615
00:27:06,140 --> 00:27:07,940
 that's trying to identify places,

616
00:27:07,940 --> 00:27:09,820
 not only that there are mugs in there,

617
00:27:09,820 --> 00:27:12,900
 so there's sort of an object recognition component

618
00:27:12,900 --> 00:27:16,180
 that wasn't necessary for locomotion,

619
00:27:16,180 --> 00:27:18,420
 but there's also, you have to understand

620
00:27:18,420 --> 00:27:19,980
 something about the context of the mug.

621
00:27:19,980 --> 00:27:22,100
 There's a handle over here, the top's on this side,

622
00:27:22,100 --> 00:27:23,300
 the bottom's on this side, right?

623
00:27:23,300 --> 00:27:25,860
 So you could say, oh, that's only a little bit more,

624
00:27:25,860 --> 00:27:29,460
 but it gets way more complicated than that as you go on.

625
00:27:29,460 --> 00:27:33,300
 First of all, the types of mugs you might have to experience

626
00:27:33,300 --> 00:27:36,380
 are just way more diverse, right?

627
00:27:36,380 --> 00:27:38,500
 This is just whatever mugs we found on Amazon,

628
00:27:38,500 --> 00:27:40,380
 but that one's a cow, you know?

629
00:27:40,380 --> 00:27:42,100
 There's, if you go to the Disney store,

630
00:27:42,100 --> 00:27:45,860
 you find all kinds of weird ones, right?

631
00:27:45,860 --> 00:27:49,300
 So how do you have that same level of understanding

632
00:27:49,300 --> 00:27:50,180
 about what's a mug,

633
00:27:50,180 --> 00:27:53,460
 but it has to work for all possible mugs, okay?

634
00:27:53,460 --> 00:27:54,820
 And to do that sort of task

635
00:27:54,820 --> 00:27:56,340
 in order to even just set the mug down

636
00:27:56,340 --> 00:27:57,700
 in the right orientation all the time,

637
00:27:57,700 --> 00:27:59,300
 or know that you can pick it up from a handle,

638
00:27:59,300 --> 00:28:00,300
 that it will support your weight,

639
00:28:00,300 --> 00:28:03,740
 or that you could put the handle on the peg,

640
00:28:03,740 --> 00:28:07,020
 it demands a lot more understanding, if you will,

641
00:28:07,020 --> 00:28:09,100
 between the perception system

642
00:28:09,100 --> 00:28:12,020
 and the lower level control system,

643
00:28:12,020 --> 00:28:15,060
 to the point where I think, from my perspective,

644
00:28:15,060 --> 00:28:18,140
 for controls, I think it really,

645
00:28:18,140 --> 00:28:21,300
 it's the next wave of what controls has to do.

646
00:28:21,300 --> 00:28:25,820
 And I'll say it maybe in a little bit more dramatic fashion

647
00:28:25,820 --> 00:28:26,660
 in a second, but.

648
00:28:26,660 --> 00:28:32,020
 Oops, did that not, fast forward,

649
00:28:32,020 --> 00:28:34,060
 I don't want their advertisement, I want.

650
00:28:34,060 --> 00:28:37,180
 So I think there's still a question, though.

651
00:28:37,180 --> 00:28:38,780
 I showed Atlas balancing,

652
00:28:38,780 --> 00:28:42,700
 and thinking about stability and control.

653
00:28:42,700 --> 00:28:43,620
 A lot of people don't talk

654
00:28:43,620 --> 00:28:45,380
 about feedback control and manipulation.

655
00:28:45,380 --> 00:28:47,020
 And it's a fair question about,

656
00:28:47,020 --> 00:28:50,780
 is it really that important to do feedback control?

657
00:28:51,300 --> 00:28:54,900
 'Cause people do have some incredibly clever designs

658
00:28:54,900 --> 00:28:58,300
 for hands that allow you to do pick and place,

659
00:28:58,300 --> 00:29:00,980
 basically with your eyes closed, and get the job done.

660
00:29:00,980 --> 00:29:01,820
 Okay?

661
00:29:01,820 --> 00:29:05,340
 So I think that is a viable approach

662
00:29:05,340 --> 00:29:07,940
 to a huge class of useful manipulation,

663
00:29:07,940 --> 00:29:12,220
 is to not worry so much about the dynamics of your mug,

664
00:29:12,220 --> 00:29:14,620
 but build a really good end effector.

665
00:29:14,620 --> 00:29:16,500
 And I think it's important,

666
00:29:16,500 --> 00:29:19,820
 and commercially very valuable.

667
00:29:19,820 --> 00:29:23,820
 Okay, but I also think there's a lot going on.

668
00:29:23,820 --> 00:29:25,620
 If you look at human manipulation,

669
00:29:25,620 --> 00:29:29,580
 this is an example, again, from Matt's world,

670
00:29:29,580 --> 00:29:31,900
 of just a high-speed camera

671
00:29:31,900 --> 00:29:33,740
 of somebody in a convenience store, okay?

672
00:29:33,740 --> 00:29:37,340
 And if you watch all the little details

673
00:29:37,340 --> 00:29:38,860
 that we don't even pay attention to,

674
00:29:38,860 --> 00:29:40,020
 'cause it's sort of subconscious,

675
00:29:40,020 --> 00:29:42,340
 but I think when she sets down the dentine,

676
00:29:42,340 --> 00:29:43,580
 it's like, oops, she missed.

677
00:29:43,580 --> 00:29:46,620
 And there's these adjustments that are constantly happening,

678
00:29:46,620 --> 00:29:49,700
 that you see little sliding all the time.

679
00:29:49,700 --> 00:29:51,420
 It's nothing like the (whooshing)

680
00:29:51,420 --> 00:29:52,940
 and then move it around, right?

681
00:29:52,940 --> 00:29:55,620
 It's a much more dynamic process,

682
00:29:55,620 --> 00:29:59,780
 where there's constant tactile feedback, visual feedback,

683
00:29:59,780 --> 00:30:01,460
 constant corrections.

684
00:30:01,460 --> 00:30:02,860
 It makes us way more robust

685
00:30:02,860 --> 00:30:05,020
 and way more diverse in our skills.

686
00:30:05,020 --> 00:30:08,180
 You can find there's a whole bunch of examples,

687
00:30:08,180 --> 00:30:11,060
 but these kind of manipulations,

688
00:30:11,060 --> 00:30:13,420
 the way people manipulate is just so different

689
00:30:13,420 --> 00:30:16,820
 than the way robots picking up red blocks manipulate,

690
00:30:16,820 --> 00:30:18,060
 and we have to get there.

691
00:30:19,060 --> 00:30:21,740
 (mouse clicking)

692
00:30:21,740 --> 00:30:23,860
 So from a feedback control perspective,

693
00:30:23,860 --> 00:30:28,180
 it's about where Atlas, the main job,

694
00:30:28,180 --> 00:30:31,260
 was to figure out what is the state of my robot?

695
00:30:31,260 --> 00:30:34,180
 How do I regulate the state of my robot

696
00:30:34,180 --> 00:30:36,460
 to achieve some task, okay?

697
00:30:36,460 --> 00:30:38,740
 Manipulation is about, okay,

698
00:30:38,740 --> 00:30:40,100
 I do have to move the state of my robot,

699
00:30:40,100 --> 00:30:41,620
 but that's kind of easy, honestly,

700
00:30:41,620 --> 00:30:44,420
 for if I'm bolted to a table, it's not a big deal, okay?

701
00:30:44,420 --> 00:30:47,500
 But I have to somehow control everything else in the world

702
00:30:48,260 --> 00:30:50,660
 through my actuation, and I only get to touch,

703
00:30:50,660 --> 00:30:54,100
 I only get to control the state of the mug through my hands,

704
00:30:54,100 --> 00:30:55,780
 which is through contact.

705
00:30:55,780 --> 00:31:00,100
 So the challenge there is just to extend our thinking

706
00:31:00,100 --> 00:31:03,980
 about feedback control through a contact mechanics interface

707
00:31:03,980 --> 00:31:05,660
 out into the world.

708
00:31:05,660 --> 00:31:06,500
 It's awesome.

709
00:31:06,500 --> 00:31:11,620
 Especially when I don't even know how to write down

710
00:31:11,620 --> 00:31:13,300
 the state for some of these problems, right?

711
00:31:13,300 --> 00:31:15,900
 So if I think about counting the links on my robot,

712
00:31:15,900 --> 00:31:17,860
 that's easy, but if I think about

713
00:31:17,860 --> 00:31:21,700
 what is the state space of the onion as I'm chopping it,

714
00:31:21,700 --> 00:31:25,340
 and does it get bigger every time I make a cut?

715
00:31:25,340 --> 00:31:27,100
 Am I supposed to be keeping track

716
00:31:27,100 --> 00:31:30,060
 of every possible piece of onion

717
00:31:30,060 --> 00:31:31,660
 in order to accomplish the task?

718
00:31:31,660 --> 00:31:35,900
 Most of the things I know about control

719
00:31:35,900 --> 00:31:37,660
 kind of just melt down,

720
00:31:37,660 --> 00:31:40,380
 thinking about how would I do proper control

721
00:31:40,380 --> 00:31:41,300
 on a problem like that?

722
00:31:41,300 --> 00:31:42,140
 But it should be easy.

723
00:31:42,140 --> 00:31:44,660
 Like, that's not a hard problem.

724
00:31:44,660 --> 00:31:47,740
 So for me, I'm super excited about bringing

725
00:31:47,740 --> 00:31:49,700
 some of the rigorous thinking of control theory

726
00:31:49,700 --> 00:31:52,820
 up into the challenges that are just put in our face

727
00:31:52,820 --> 00:31:55,940
 by relatively simple manipulation systems.

728
00:31:55,940 --> 00:31:59,940
 I don't really wanna give robots sharp knives yet,

729
00:31:59,940 --> 00:32:02,320
 but maybe next year.

730
00:32:02,320 --> 00:32:05,940
 So we're seeing in the field,

731
00:32:05,940 --> 00:32:09,080
 more and more examples of feedback control

732
00:32:09,080 --> 00:32:13,260
 that is really using real-time camera perceptual input

733
00:32:13,260 --> 00:32:16,900
 in order to do even relatively simple tasks.

734
00:32:16,900 --> 00:32:18,380
 That wasn't part of the objective, right?

735
00:32:18,380 --> 00:32:22,840
 But where you're starting to see feedback loops

736
00:32:22,840 --> 00:32:25,780
 being controlled through non-trivial perception interfaces,

737
00:32:25,780 --> 00:32:28,900
 where it's really constantly monitoring the environment,

738
00:32:28,900 --> 00:32:33,120
 making feedback corrections, and it's very good.

739
00:32:33,120 --> 00:32:35,700
 This one in particular is using a type of,

740
00:32:35,700 --> 00:32:40,460
 it's a neural network that's looking at images

741
00:32:40,460 --> 00:32:43,900
 through the camera, trying to find corresponding images

742
00:32:43,900 --> 00:32:46,300
 in the new scene.

743
00:32:46,300 --> 00:32:48,400
 We'll talk about the particular details of that

744
00:32:48,400 --> 00:32:52,260
 when we're in the deep learning perception part of the world,

745
00:32:52,260 --> 00:32:53,440
 part of the semester.

746
00:32:53,440 --> 00:32:55,700
 But it's,

747
00:32:55,700 --> 00:33:02,060
 when you do use camera feedback well,

748
00:33:02,060 --> 00:33:04,340
 it can be incredibly robust.

749
00:33:04,340 --> 00:33:07,200
 The same way, for me, this is, I know it's not as cool,

750
00:33:07,200 --> 00:33:10,680
 but this is a little bit like, my network is lagging here.

751
00:33:10,680 --> 00:33:14,200
 For me, this is a little bit like that atlas

752
00:33:14,200 --> 00:33:17,280
 not falling down when we're jumping on the Polaris.

753
00:33:17,280 --> 00:33:18,680
 I know it's just picking up a plate,

754
00:33:18,680 --> 00:33:22,900
 but we're gonna see some, all kinds of variability,

755
00:33:22,900 --> 00:33:26,440
 and the fact that it's doing this just from cameras

756
00:33:26,440 --> 00:33:28,840
 as the primary feedback sensor,

757
00:33:28,840 --> 00:33:32,120
 and it's doing it with all sorts of perturbations,

758
00:33:32,120 --> 00:33:35,960
 and it's a multi-contact task,

759
00:33:36,880 --> 00:33:39,120
 but it's able to be, you know,

760
00:33:39,120 --> 00:33:42,840
 incredibly robust, despite Pete's best efforts

761
00:33:42,840 --> 00:33:44,560
 to mess with it.

762
00:33:44,560 --> 00:33:51,900
 So that's, I think, a humble example of something

763
00:33:51,900 --> 00:33:54,300
 that I hope we see a lot more of in the future.

764
00:33:54,300 --> 00:33:59,440
 If I were to show the less flattering videos

765
00:33:59,440 --> 00:34:01,680
 from the DARPA challenge, you would see, you know,

766
00:34:01,680 --> 00:34:05,220
 the sort of robot air balls, and so, you know,

767
00:34:05,220 --> 00:34:06,520
 the robot going out to reach something,

768
00:34:06,520 --> 00:34:08,480
 and just thinking it had it in its hand,

769
00:34:08,480 --> 00:34:11,140
 continuing the motion, falling over, those kind of,

770
00:34:11,140 --> 00:34:12,120
 you know, we don't want that anymore.

771
00:34:12,120 --> 00:34:14,880
 We wanna close the loop between perception and control.

772
00:34:14,880 --> 00:34:17,680
 And of course, reinforcement learning has come

773
00:34:17,680 --> 00:34:19,220
 into the picture in a big way,

774
00:34:19,220 --> 00:34:21,160
 in terms of how we do these things.

775
00:34:21,160 --> 00:34:22,700
 You can do these kind of tasks.

776
00:34:22,700 --> 00:34:26,000
 This is an example of banging on the simulation

777
00:34:26,000 --> 00:34:27,320
 with a reinforcement learning algorithm

778
00:34:27,320 --> 00:34:29,280
 to accomplish the same task,

779
00:34:29,280 --> 00:34:32,360
 and we're gonna talk through, you know,

780
00:34:32,360 --> 00:34:35,420
 how to understand RL approaches,

781
00:34:35,420 --> 00:34:38,680
 where do they fit into the spectrum, in my view.

782
00:34:38,680 --> 00:34:41,360
 I will admit up front that I don't think

783
00:34:41,360 --> 00:34:43,200
 it solves the whole problem.

784
00:34:43,200 --> 00:34:45,000
 I don't think it's just a matter of getting more data

785
00:34:45,000 --> 00:34:47,760
 or running more simulations, or even if it was,

786
00:34:47,760 --> 00:34:51,020
 you know, I don't think we wanna be in a place

787
00:34:51,020 --> 00:34:54,680
 where programming a robot to load the dishwasher

788
00:34:54,680 --> 00:34:58,480
 requires, you know, hundreds of thousands of dollars

789
00:34:58,480 --> 00:35:02,040
 in an Amazon, you know, AWS bill, or something like that,

790
00:35:02,040 --> 00:35:04,440
 where only the big companies can afford

791
00:35:04,440 --> 00:35:05,520
 to train a system.

792
00:35:05,520 --> 00:35:08,260
 I, we're already going that way in terms of, like,

793
00:35:08,260 --> 00:35:11,920
 our language models and our perception models,

794
00:35:11,920 --> 00:35:13,620
 but manipulation, this should be easy.

795
00:35:13,620 --> 00:35:14,520
 This should totally be easy.

796
00:35:14,520 --> 00:35:17,420
 So we should be able to have better solutions there

797
00:35:17,420 --> 00:35:19,560
 that you can run on your desktop.

798
00:35:19,560 --> 00:35:22,060
 Okay.

799
00:35:22,060 --> 00:35:25,220
 That's what I mean by manipulation.

800
00:35:25,220 --> 00:35:26,060
 Yeah, please.

801
00:35:26,060 --> 00:35:29,140
 - This might be early, probably cover this later,

802
00:35:29,140 --> 00:35:33,140
 but where does reinforcement learning fall?

803
00:35:33,140 --> 00:35:35,540
 Like, what kind of problem does that solve?

804
00:35:35,540 --> 00:35:39,800
 And then, you know, counter to the control problem?

805
00:35:39,800 --> 00:35:40,980
 - Yeah, it's a great question.

806
00:35:40,980 --> 00:35:45,980
 So I think some people, I would say it's a very natural fit

807
00:35:45,980 --> 00:35:50,040
 at the low-level control.

808
00:35:50,040 --> 00:35:54,340
 You could imagine, you know, if you want these controllers

809
00:35:54,340 --> 00:35:56,040
 that are interacting with contact forces

810
00:35:56,040 --> 00:35:59,460
 and coming up with, you know, a policy in RL parlance,

811
00:35:59,460 --> 00:36:02,380
 then I think there's an active debate

812
00:36:02,380 --> 00:36:03,560
 about whether it's better to do that

813
00:36:03,560 --> 00:36:04,980
 with a reinforcement learning technique

814
00:36:04,980 --> 00:36:06,180
 or a model-based technique.

815
00:36:06,180 --> 00:36:08,080
 We'll talk about both.

816
00:36:08,080 --> 00:36:12,420
 As you go up the hierarchy, I think the most,

817
00:36:12,420 --> 00:36:16,060
 the most fully committed people in reinforcement learning

818
00:36:16,060 --> 00:36:18,160
 would say even task-level planning,

819
00:36:18,160 --> 00:36:20,600
 you could do with reinforcement learning.

820
00:36:20,600 --> 00:36:22,220
 I don't go that high on the spectrum.

821
00:36:22,220 --> 00:36:23,800
 I think the higher you go up,

822
00:36:23,800 --> 00:36:26,540
 I think it begs for something that has some level

823
00:36:26,540 --> 00:36:29,660
 of concepts and planning that are harder to represent

824
00:36:29,660 --> 00:36:31,200
 in the reinforcement learning.

825
00:36:31,200 --> 00:36:33,940
 Leslie Kelbling here likes to say, you know,

826
00:36:33,940 --> 00:36:37,100
 if you want, I ask you to book a flight to Paris, right?

827
00:36:37,100 --> 00:36:39,380
 You don't have a policy to book a flight to Paris.

828
00:36:39,380 --> 00:36:41,880
 You're able to like put that, you've never done that before.

829
00:36:41,880 --> 00:36:45,620
 You can do, you can put together new sequences

830
00:36:45,620 --> 00:36:47,220
 that you've never experienced before.

831
00:36:47,220 --> 00:36:49,340
 So I think that doesn't fit as well

832
00:36:49,340 --> 00:36:51,260
 into the reinforcement learning paradigms

833
00:36:51,260 --> 00:36:52,700
 that we have today.

834
00:36:52,700 --> 00:36:56,740
 Now, there's no question that I think reinforcement learning

835
00:36:56,740 --> 00:36:59,020
 encourages us to think about the data that's coming in,

836
00:36:59,020 --> 00:37:00,300
 how do you make use of the data,

837
00:37:00,300 --> 00:37:02,300
 how do you use trial and error?

838
00:37:02,300 --> 00:37:05,060
 That's all good and we should be doing that at every level.

839
00:37:05,060 --> 00:37:05,900
 Right?

840
00:37:05,900 --> 00:37:09,360
 But I think the standard RL toolkit today

841
00:37:09,360 --> 00:37:11,620
 probably fits best in the lower level skills.

842
00:37:11,620 --> 00:37:15,640
 Other questions are good.

843
00:37:15,640 --> 00:37:17,220
 I love questions.

844
00:37:17,220 --> 00:37:26,720
 Cool.

845
00:37:26,720 --> 00:37:27,580
 Let me ask you.

846
00:37:27,580 --> 00:37:31,940
 So how many people have worked on manipulation before?

847
00:37:31,940 --> 00:37:32,780
 Show of hands.

848
00:37:32,780 --> 00:37:35,620
 How many in robotics before?

849
00:37:35,620 --> 00:37:41,820
 How many people have done some other area

850
00:37:41,820 --> 00:37:43,960
 of like, you know, computer vision

851
00:37:43,960 --> 00:37:45,180
 or natural language or something

852
00:37:45,180 --> 00:37:46,780
 and maybe it would be kind of fun

853
00:37:46,780 --> 00:37:49,460
 if we could put that together with robotics.

854
00:37:49,460 --> 00:37:51,060
 Okay, that's good.

855
00:37:51,060 --> 00:37:53,840
 How about from the sort of more mechanical side?

856
00:37:53,840 --> 00:37:56,540
 Few mechanical engineers.

857
00:37:56,540 --> 00:37:57,660
 All right, cool.

858
00:37:57,660 --> 00:37:59,100
 That's good.

859
00:37:59,100 --> 00:38:02,700
 Well, I actually, I see it as a bit of a challenge,

860
00:38:02,700 --> 00:38:04,820
 but I love actually that we get a diverse group

861
00:38:04,820 --> 00:38:05,760
 of people in here.

862
00:38:05,760 --> 00:38:08,100
 So, you know, every once in a while I'll say things

863
00:38:08,100 --> 00:38:10,420
 that you'll have to just nod 'cause you already know that,

864
00:38:10,420 --> 00:38:12,380
 but there's someone else in the room maybe that doesn't,

865
00:38:12,380 --> 00:38:14,180
 but I try to do my best to, I think,

866
00:38:14,180 --> 00:38:17,540
 hopefully always gives you guys something new.

867
00:38:17,540 --> 00:38:22,460
 So, let me take a minute now to try to tell you

868
00:38:22,460 --> 00:38:24,340
 about the sort of dynamical systems view

869
00:38:24,340 --> 00:38:25,500
 of all that complexity.

870
00:38:25,500 --> 00:38:27,700
 Like I just told you how complex the problem is.

871
00:38:27,700 --> 00:38:29,980
 There's task level planning, there's perception,

872
00:38:29,980 --> 00:38:33,700
 there's control, and I really have a goal for these notes

873
00:38:33,700 --> 00:38:37,860
 and for the class to sort of put a relatively coherent

874
00:38:37,860 --> 00:38:40,580
 framework for all of that together.

875
00:38:40,580 --> 00:38:41,780
 It's a big task.

876
00:38:41,780 --> 00:38:46,260
 The way I see it, systems theory,

877
00:38:46,260 --> 00:38:49,460
 dynamical systems is a framework that we can talk about

878
00:38:49,460 --> 00:38:52,160
 most of those components pretty naturally.

879
00:38:52,160 --> 00:38:55,120
 There's a few things that you kind of have to shoehorn in,

880
00:38:55,120 --> 00:38:56,940
 but we get pretty far thinking about things

881
00:38:56,940 --> 00:38:58,660
 as a dynamical system.

882
00:38:58,660 --> 00:39:00,460
 Okay, so we'll start modest,

883
00:39:00,460 --> 00:39:03,900
 and some people who know dynamics and control very well

884
00:39:03,900 --> 00:39:04,900
 will be bored for five minutes,

885
00:39:04,900 --> 00:39:08,140
 but I hope you'll see how we're gonna build a framework,

886
00:39:08,140 --> 00:39:09,980
 a toolkit of dynamical systems,

887
00:39:09,980 --> 00:39:12,100
 thinking about even perception systems

888
00:39:12,100 --> 00:39:13,540
 through the lens of dynamics,

889
00:39:13,540 --> 00:39:15,780
 and get to something pretty good,

890
00:39:15,780 --> 00:39:17,340
 I hope, by the end of the term.

891
00:39:22,880 --> 00:39:27,780
 So for me, the starting point is, I guess, 18.03,

892
00:39:27,780 --> 00:39:29,920
 if you've taken the undergrad version of it,

893
00:39:29,920 --> 00:39:32,220
 but it's basic difference equations.

894
00:39:32,220 --> 00:39:33,860
 So let's just think about, just remember,

895
00:39:33,860 --> 00:39:36,740
 dust off the cobwebs of difference equations,

896
00:39:36,740 --> 00:39:39,100
 and why do I wanna think about even a neural network

897
00:39:39,100 --> 00:39:41,980
 as a difference equation when I'm in this class, okay?

898
00:39:41,980 --> 00:39:42,820
 So.

899
00:39:42,820 --> 00:39:45,560
 (marker tapping)

900
00:39:45,560 --> 00:40:04,760
 The general form of a simple sort of state,

901
00:40:04,760 --> 00:40:09,720
 space difference equation, you might start by saying,

902
00:40:10,760 --> 00:40:15,760
 I've got some vector, a state vector, x,

903
00:40:15,760 --> 00:40:19,880
 and a state update rule,

904
00:40:19,880 --> 00:40:29,480
 equation F, and N is my time step.

905
00:40:29,480 --> 00:40:36,080
 Okay?

906
00:40:37,660 --> 00:40:41,260
 So, I mean, this is asking us to come,

907
00:40:41,260 --> 00:40:43,760
 when we start thinking about perception and the like,

908
00:40:43,760 --> 00:40:45,180
 this is asking us to say something

909
00:40:45,180 --> 00:40:48,920
 about how our perception system is evolving in time,

910
00:40:48,920 --> 00:40:51,860
 and we're gonna say that that's important

911
00:40:51,860 --> 00:40:54,660
 in order to put these things together in a beautiful way.

912
00:40:54,660 --> 00:40:57,000
 So the simplest examples of this would be,

913
00:40:57,000 --> 00:40:59,480
 for instance,

914
00:40:59,480 --> 00:41:06,060
 just a linear system, if I just had a constant,

915
00:41:06,060 --> 00:41:07,900
 but if x was a scalar,

916
00:41:07,900 --> 00:41:10,100
 and this was just a constant coefficient,

917
00:41:10,100 --> 00:41:17,420
 then the way to think about this is that I can instantly

918
00:41:17,420 --> 00:41:21,000
 do all kinds of analysis on this difference equation,

919
00:41:21,000 --> 00:41:24,020
 because I can simulate it, first of all,

920
00:41:24,020 --> 00:41:27,060
 if you give me x at time zero,

921
00:41:27,060 --> 00:41:31,580
 then I can just roll it forward.

922
00:41:31,580 --> 00:41:36,500
 I know that x1 is just a times x0,

923
00:41:36,500 --> 00:41:40,180
 and x to the N, more generally,

924
00:41:40,180 --> 00:41:44,800
 is just a to the N times x0.

925
00:41:44,800 --> 00:41:48,420
 So I can forecast far into the future very quickly,

926
00:41:48,420 --> 00:41:49,960
 because it's linear, okay?

927
00:41:49,960 --> 00:41:53,820
 And actually, just by having written that,

928
00:41:53,820 --> 00:41:57,500
 I could easily answer some pretty sophisticated questions

929
00:41:57,500 --> 00:42:01,220
 about it, like, there's really only two things

930
00:42:01,220 --> 00:42:02,140
 that this thing can do.

931
00:42:02,140 --> 00:42:04,740
 It can either converge towards zero,

932
00:42:04,740 --> 00:42:07,260
 or it can diverge towards infinity,

933
00:42:07,260 --> 00:42:09,480
 or negative infinity, or both,

934
00:42:09,480 --> 00:42:12,300
 if that's, it is negative, but.

935
00:42:12,300 --> 00:42:13,860
 So you can answer long-term questions

936
00:42:13,860 --> 00:42:15,640
 about stability, for instance.

937
00:42:15,640 --> 00:42:22,700
 In this case, you can see that, for instance,

938
00:42:22,700 --> 00:42:26,620
 if a is, let's say, strictly less than one,

939
00:42:26,620 --> 00:42:30,700
 then xn will go to zero,

940
00:42:31,700 --> 00:42:34,900
 as n goes to infinity.

941
00:42:34,900 --> 00:42:42,740
 Okay, that's just dusting off the cobwebs here,

942
00:42:42,740 --> 00:42:47,740
 but my claim is that we're gonna build,

943
00:42:47,740 --> 00:42:49,360
 we're gonna complicate this,

944
00:42:49,360 --> 00:42:51,340
 we're gonna use the full form of this,

945
00:42:51,340 --> 00:42:53,860
 and we're gonna build a whole framework in the class

946
00:42:53,860 --> 00:42:56,020
 of all the different systems, how they interact,

947
00:42:56,020 --> 00:42:57,660
 using this as our starting point.

948
00:42:57,660 --> 00:43:00,500
 (papers rustling)

949
00:43:00,500 --> 00:43:03,460
 I'll scroll over here.

950
00:43:03,460 --> 00:43:06,300
 (papers rustling)

951
00:43:06,300 --> 00:43:11,900
 Okay, so now let's just make it

952
00:43:11,900 --> 00:43:13,400
 a little bit more interesting.

953
00:43:13,400 --> 00:43:19,180
 Let's think of it as an input-output dynamical system.

954
00:43:19,180 --> 00:43:22,020
 (papers rustling)

955
00:43:22,020 --> 00:43:24,860
 (papers rustling)

956
00:43:24,860 --> 00:43:33,580
 Okay, so my robot isn't just evolving by itself, right?

957
00:43:33,580 --> 00:43:41,820
 It has some, I typically write it as u coming in,

958
00:43:41,820 --> 00:43:46,020
 y coming out.

959
00:43:46,020 --> 00:43:50,740
 The internal dynamics are still with x.

960
00:43:50,740 --> 00:43:52,500
 Okay, so now this is my inputs,

961
00:43:52,500 --> 00:43:58,960
 which in this case might be motor commands for the robot.

962
00:43:58,960 --> 00:44:06,660
 Y are my outputs.

963
00:44:06,660 --> 00:44:12,900
 For instance, my sensors,

964
00:44:12,900 --> 00:44:17,860
 could be cameras, could be joint sensors.

965
00:44:17,860 --> 00:44:20,700
 (papers rustling)

966
00:44:20,700 --> 00:44:34,500
 Pactal sensors are coming in of their own these days.

967
00:44:34,500 --> 00:44:36,840
 This is still my speed vector,

968
00:44:36,840 --> 00:44:44,340
 which in a simple case might just be,

969
00:44:44,340 --> 00:44:49,340
 let's say the robot joint positions and velocities.

970
00:44:49,340 --> 00:44:59,580
 But like I said, there'd be dragons there.

971
00:44:59,580 --> 00:45:00,840
 If you're chopping an onion,

972
00:45:00,840 --> 00:45:03,160
 I don't actually even know how to tell you what x is.

973
00:45:03,160 --> 00:45:04,000
 Okay.

974
00:45:04,000 --> 00:45:09,560
 And then the slightly more general form

975
00:45:09,560 --> 00:45:12,380
 of the difference equations would be

976
00:45:13,380 --> 00:45:16,100
 (papers rustling)

977
00:45:16,100 --> 00:45:20,060
 something that looks like this.

978
00:45:20,060 --> 00:45:22,920
 So I can tell you how the state evolves.

979
00:45:22,920 --> 00:45:24,200
 I can still simulate this.

980
00:45:24,200 --> 00:45:28,020
 If I say my current state, my current input,

981
00:45:28,020 --> 00:45:29,860
 I'll tell you what the next state is.

982
00:45:29,860 --> 00:45:33,420
 And my current output,

983
00:45:33,420 --> 00:45:37,320
 this is the standard sort of state space form.

984
00:45:41,700 --> 00:45:44,160
 I could say that given I know what the current state

985
00:45:44,160 --> 00:45:46,240
 of the world is and possibly the inputs,

986
00:45:46,240 --> 00:45:49,180
 there's not always a direct connection between you and y,

987
00:45:49,180 --> 00:45:51,580
 but then I can tell you what the sensors

988
00:45:51,580 --> 00:45:52,760
 are gonna look like.

989
00:45:52,760 --> 00:45:53,900
 This would be a model.

990
00:45:53,900 --> 00:45:59,660
 Okay, but while it's a long way from xn plus one

991
00:45:59,660 --> 00:46:04,660
 equals a of xn, the framework still kind of holds.

992
00:46:04,660 --> 00:46:07,820
 Now I might say that f is a full physics engine.

993
00:46:07,820 --> 00:46:10,660
 (papers rustling)

994
00:46:10,660 --> 00:46:16,260
 This is maybe a full game quality renderer

995
00:46:16,260 --> 00:46:20,080
 or better blender sort of ray tracing rendering.

996
00:46:20,080 --> 00:46:23,980
 It's a camera model.

997
00:46:23,980 --> 00:46:26,880
 I have to like simulate photons, right?

998
00:46:26,880 --> 00:46:31,580
 It's a lot more complicated than what we can tend

999
00:46:31,580 --> 00:46:36,440
 to do our closed form analysis on,

1000
00:46:36,440 --> 00:46:37,860
 but actually many of the tools

1001
00:46:37,860 --> 00:46:40,000
 from systems theory still apply.

1002
00:46:40,000 --> 00:46:43,860
 We tend to attack these things more numerically

1003
00:46:43,860 --> 00:46:48,860
 with simulations, okay, than we do with our pen and paper.

1004
00:46:48,860 --> 00:46:53,780
 But the same fundamental questions should be asked.

1005
00:46:53,780 --> 00:46:56,680
 You should be able to give good answers.

1006
00:46:56,680 --> 00:46:59,620
 Sometimes the function is so complicated

1007
00:46:59,620 --> 00:47:01,740
 that it's hard to say something rigorous,

1008
00:47:01,740 --> 00:47:04,100
 but we're gonna walk that line whenever we can.

1009
00:47:04,100 --> 00:47:07,440
 (papers rustling)

1010
00:47:07,440 --> 00:47:12,440
 Okay, so what is the anatomy of a manipulation system?

1011
00:47:12,440 --> 00:47:21,880
 Well, first of all, we're gonna start putting models

1012
00:47:21,880 --> 00:47:23,720
 like this together.

1013
00:47:23,720 --> 00:47:27,680
 So I kind of caricatured a robot model,

1014
00:47:27,680 --> 00:47:31,640
 okay, with a physics engine and a renderer.

1015
00:47:32,580 --> 00:47:36,860
 But we can take those types of systems

1016
00:47:36,860 --> 00:47:38,420
 and put them together, right?

1017
00:47:38,420 --> 00:47:42,580
 So I can have my robot model

1018
00:47:42,580 --> 00:47:46,900
 with Y coming out here and U coming in,

1019
00:47:46,900 --> 00:47:51,900
 and maybe I write a controller, okay?

1020
00:47:51,900 --> 00:47:54,140
 And this is another dynamical system.

1021
00:47:54,140 --> 00:47:58,500
 It could even have internal state control, okay?

1022
00:47:58,500 --> 00:48:03,500
 And I can connect these systems in a block diagram, okay?

1023
00:48:03,500 --> 00:48:16,240
 And what's important is that if this is described

1024
00:48:16,240 --> 00:48:18,020
 by a difference equation,

1025
00:48:18,020 --> 00:48:20,580
 and this is described by a difference equation,

1026
00:48:20,580 --> 00:48:22,320
 then the dynamics of the whole diagram

1027
00:48:22,320 --> 00:48:24,620
 is just another difference equation

1028
00:48:24,620 --> 00:48:28,240
 that can be derived perfectly and simulated and analyzed

1029
00:48:28,240 --> 00:48:30,880
 in the same way as we did those smaller systems.

1030
00:48:30,880 --> 00:48:34,820
 The diagram is just another difference equation system.

1031
00:48:34,820 --> 00:48:36,720
 And it gets richer and more complicated

1032
00:48:36,720 --> 00:48:38,180
 when you have these things operating

1033
00:48:38,180 --> 00:48:40,060
 at different rates or whatever,

1034
00:48:40,060 --> 00:48:42,500
 but it all still kind of works.

1035
00:48:42,500 --> 00:48:44,420
 We have a theory to build up

1036
00:48:44,420 --> 00:48:46,020
 a lot of those different things.

1037
00:48:46,020 --> 00:48:50,600
 Okay, and I would say, for those of you

1038
00:48:50,600 --> 00:48:53,240
 that have taken underactuated or will take underactuated,

1039
00:48:53,240 --> 00:48:55,380
 this is sort of the view of the world

1040
00:48:55,380 --> 00:48:57,040
 for most of my controls class,

1041
00:48:57,040 --> 00:48:58,820
 and most controls classes you'll take,

1042
00:48:58,820 --> 00:49:00,380
 this is kind of the view of the world.

1043
00:49:00,380 --> 00:49:02,840
 You're given a plant or a robot,

1044
00:49:02,840 --> 00:49:06,380
 and you have to design a controller, okay?

1045
00:49:06,380 --> 00:49:07,300
 But that's not gonna get us

1046
00:49:07,300 --> 00:49:08,980
 where we need to go for manipulation.

1047
00:49:08,980 --> 00:49:12,860
 There's a whole bunch more going on here for manipulation.

1048
00:49:12,860 --> 00:49:16,160
 So we have perception models.

1049
00:49:16,160 --> 00:49:26,440
 Okay, so, and there's all kinds that we'll talk about.

1050
00:49:26,440 --> 00:49:27,280
 Yeah, please.

1051
00:49:27,280 --> 00:49:33,140
 So, there's a bunch of different ways to answer that.

1052
00:49:33,140 --> 00:49:35,940
 I wrote it as Y, and that would imply

1053
00:49:35,940 --> 00:49:37,560
 that you probably have a filter in here.

1054
00:49:37,560 --> 00:49:38,820
 So you have a dynamic controller

1055
00:49:38,820 --> 00:49:40,500
 that's estimating X inside here.

1056
00:49:40,500 --> 00:49:43,420
 In our full state feedback world,

1057
00:49:43,420 --> 00:49:44,700
 I might separate that out and say,

1058
00:49:44,700 --> 00:49:46,700
 like put a Kalman filter here to estimate X,

1059
00:49:46,700 --> 00:49:51,180
 or I might just cheat and give direct access to X, right?

1060
00:49:51,180 --> 00:49:55,500
 But it does, I think the view I like best of control

1061
00:49:55,500 --> 00:49:58,620
 is that this is really reading the raw sensors.

1062
00:49:58,620 --> 00:50:01,740
 It's doing any internal dynamics it needs

1063
00:50:01,740 --> 00:50:03,640
 to keep track and estimate,

1064
00:50:03,640 --> 00:50:06,600
 and it need not always estimate the full state.

1065
00:50:06,600 --> 00:50:08,460
 And then that becomes important to manipulation

1066
00:50:08,460 --> 00:50:11,540
 because what's the state of my shirt?

1067
00:50:11,540 --> 00:50:13,820
 Like if I need to estimate the full state of my shirt

1068
00:50:13,820 --> 00:50:16,140
 in order to button my shirt, I'm kind of,

1069
00:50:16,140 --> 00:50:17,480
 it's a bad way to go.

1070
00:50:17,480 --> 00:50:21,100
 So that's a great question, and we'll talk about it.

1071
00:50:23,960 --> 00:50:25,720
 So perception modules, there's all,

1072
00:50:25,720 --> 00:50:30,520
 we're gonna talk about two different flavors of perception.

1073
00:50:30,520 --> 00:50:33,880
 Right, we're gonna talk about some more geometric perception.

1074
00:50:33,880 --> 00:50:35,840
 That was dramatic.

1075
00:50:35,840 --> 00:50:37,300
 Oh, is that, yeah, no worries.

1076
00:50:37,300 --> 00:50:44,200
 And lighting changes are hell on a perception system.

1077
00:50:44,200 --> 00:50:47,420
 That's what always happens is you get your robot

1078
00:50:47,420 --> 00:50:50,260
 working perfectly, and then someone says,

1079
00:50:50,260 --> 00:50:51,640
 oh, I'm gonna bring a camera,

1080
00:50:51,640 --> 00:50:52,960
 and we're gonna take some beautiful footage

1081
00:50:52,960 --> 00:50:53,920
 of your robot doing it, right,

1082
00:50:53,920 --> 00:50:55,160
 and then they put a spotlight on it,

1083
00:50:55,160 --> 00:50:57,060
 and your perception system doesn't work.

1084
00:50:57,060 --> 00:51:01,920
 Yeah, it happens more than you'd think.

1085
00:51:01,920 --> 00:51:05,880
 Okay, so we're gonna talk about some geometric perception.

1086
00:51:05,880 --> 00:51:09,020
 So there's different kind of sensor models.

1087
00:51:09,020 --> 00:51:15,960
 So we could have just our RGB sensor,

1088
00:51:15,960 --> 00:51:19,320
 which might take somehow the state of the world,

1089
00:51:19,320 --> 00:51:23,600
 which we'll, I'll talk about more in a minute,

1090
00:51:23,600 --> 00:51:25,680
 but talk about our state of the world,

1091
00:51:25,680 --> 00:51:28,860
 and output, for instance, an RGB image.

1092
00:51:28,860 --> 00:51:33,560
 Right, green and blue being a standard color space,

1093
00:51:33,560 --> 00:51:38,560
 but just some, you know, some standard photograph image.

1094
00:51:38,560 --> 00:51:41,640
 Maybe that's the sensor that's coming out.

1095
00:51:41,640 --> 00:51:45,300
 And I might wanna build a perception system

1096
00:51:45,300 --> 00:51:47,200
 that, for instance, I don't know,

1097
00:51:47,200 --> 00:51:50,240
 estimates the position of the mug in the scene, right?

1098
00:51:50,240 --> 00:51:55,240
 So I might go from an RGB image to the pose of the mug,

1099
00:51:55,240 --> 00:52:00,400
 which implies that I already knew

1100
00:52:00,400 --> 00:52:03,260
 there was a mug in the scene, which is a fragility,

1101
00:52:03,260 --> 00:52:06,760
 but, you know, I could do a pose estimator here.

1102
00:52:06,760 --> 00:52:14,360
 And we'll talk about ways to do that.

1103
00:52:14,360 --> 00:52:16,480
 One way to do that would be to do,

1104
00:52:16,480 --> 00:52:18,440
 use a big convolutional neural network.

1105
00:52:18,440 --> 00:52:38,300
 And if you're doing a standard feed-forward neural network,

1106
00:52:38,300 --> 00:52:41,780
 then this is sort of the simplest form

1107
00:52:41,780 --> 00:52:44,680
 of a dynamical system where I really just have

1108
00:52:44,680 --> 00:52:50,680
 Y of N is some function G of U of N.

1109
00:52:50,680 --> 00:52:55,440
 I don't even have any state.

1110
00:52:55,440 --> 00:53:04,120
 But often in manipulation, you need to do better than that.

1111
00:53:04,120 --> 00:53:09,120
 That can maybe work for, you know, finding cats on Flickr,

1112
00:53:09,160 --> 00:53:12,340
 but, you know, in manipulation,

1113
00:53:12,340 --> 00:53:15,540
 you often need to like gather new information

1114
00:53:15,540 --> 00:53:17,740
 or take multiple camera images

1115
00:53:17,740 --> 00:53:20,040
 in order to build up your understanding of the scene.

1116
00:53:20,040 --> 00:53:22,460
 If I have to look around my computer

1117
00:53:22,460 --> 00:53:24,260
 to see what's behind it, right,

1118
00:53:24,260 --> 00:53:26,700
 it might be that I need a richer,

1119
00:53:26,700 --> 00:53:28,420
 I can't just make all my decisions

1120
00:53:28,420 --> 00:53:30,700
 based on the current input,

1121
00:53:30,700 --> 00:53:33,300
 the current image coming out of my camera.

1122
00:53:33,300 --> 00:53:36,940
 So that's where we get into people using, for instance,

1123
00:53:36,940 --> 00:53:38,260
 recurrent neural networks.

1124
00:53:38,260 --> 00:53:40,840
 (feet tapping)

1125
00:53:40,840 --> 00:53:46,600
 Which really do snap right into the

1126
00:53:46,600 --> 00:53:50,060
 dynamical systems view of the world.

1127
00:53:50,060 --> 00:53:58,920
 Where they are perfectly described by difference equations.

1128
00:53:58,920 --> 00:54:01,660
 (feet tapping)

1129
00:54:01,660 --> 00:54:04,240
 (feet tapping)

1130
00:54:04,240 --> 00:54:17,820
 But we're also gonna talk about

1131
00:54:17,820 --> 00:54:25,720
 less deep, more geometric approaches to perception.

1132
00:54:28,900 --> 00:54:33,300
 One of the great advances in robotics in the last,

1133
00:54:33,300 --> 00:54:35,860
 I don't know, 12 years or something,

1134
00:54:35,860 --> 00:54:38,480
 was the depth camera, right?

1135
00:54:38,480 --> 00:54:41,220
 The fact that we can have something

1136
00:54:41,220 --> 00:54:43,300
 that looks roughly in the form factor of a camera,

1137
00:54:43,300 --> 00:54:46,260
 but give not only RGB values at every pixel,

1138
00:54:46,260 --> 00:54:48,420
 but also a depth estimate at every pixel.

1139
00:54:48,420 --> 00:54:50,740
 They do it from various technologies,

1140
00:54:50,740 --> 00:54:53,780
 whether it's shining a dot pattern

1141
00:54:53,780 --> 00:54:54,900
 or having multiple cameras,

1142
00:54:54,900 --> 00:54:57,500
 or there's various different ways that we'll talk about

1143
00:54:57,500 --> 00:54:58,940
 when we get to perception.

1144
00:54:58,940 --> 00:55:03,080
 But a lot of times, our robots will have depth cameras.

1145
00:55:03,080 --> 00:55:05,660
 (feet tapping)

1146
00:55:05,660 --> 00:55:13,580
 Which takes the state of the world in

1147
00:55:13,580 --> 00:55:15,140
 and outputs an RGB

1148
00:55:15,140 --> 00:55:21,220
 D image, where you have an extra channel for depth.

1149
00:55:21,220 --> 00:55:25,700
 And you might have a system,

1150
00:55:25,700 --> 00:55:30,460
 we will build up systems that take RGBD plus camera pose.

1151
00:55:30,460 --> 00:55:34,980
 You have an estimate of where your camera is in the world,

1152
00:55:34,980 --> 00:55:38,740
 and you have potentially many RGBD cameras.

1153
00:55:38,740 --> 00:55:43,740
 You can make a point cloud reconstruction of the world.

1154
00:55:43,740 --> 00:55:47,060
 It might have history,

1155
00:55:47,060 --> 00:55:48,020
 you might take a history of those,

1156
00:55:48,020 --> 00:55:49,660
 and so it'd have internal state,

1157
00:55:49,660 --> 00:55:51,860
 where it might be a one-shot system,

1158
00:55:51,860 --> 00:55:54,860
 depending how many cameras you have.

1159
00:55:54,860 --> 00:55:57,700
 And then it can come out with a 3D point cloud,

1160
00:55:57,700 --> 00:55:58,540
 for instance.

1161
00:55:58,540 --> 00:56:12,020
 And once you have a 3D point cloud,

1162
00:56:12,020 --> 00:56:13,700
 you can put that into a neural network,

1163
00:56:13,700 --> 00:56:15,620
 and we're learning more and more about

1164
00:56:15,620 --> 00:56:20,580
 deep geometric 3D perception,

1165
00:56:20,580 --> 00:56:23,420
 and how do you use those properly in the neural network.

1166
00:56:24,820 --> 00:56:29,580
 But there's also a lot of more geometric direct reasoning,

1167
00:56:29,580 --> 00:56:30,660
 algorithms that you can do.

1168
00:56:30,660 --> 00:56:32,980
 We can do point cloud registration.

1169
00:56:32,980 --> 00:56:43,300
 You can do plane segmentation,

1170
00:56:43,300 --> 00:56:44,140
 you can do,

1171
00:56:44,140 --> 00:56:47,900
 there's a whole bunch of geometric algorithms

1172
00:56:47,900 --> 00:56:51,100
 that have relatively more maturity

1173
00:56:51,100 --> 00:56:54,660
 in terms of giving guarantees about performance

1174
00:56:54,660 --> 00:56:56,860
 against outliers and noise rejection,

1175
00:56:56,860 --> 00:56:58,660
 and these kind of things.

1176
00:56:58,660 --> 00:56:59,620
 So I find it,

1177
00:56:59,620 --> 00:57:02,540
 I think it's very important to talk about both the geometric,

1178
00:57:02,540 --> 00:57:04,980
 we'll do a section on the geometric perception,

1179
00:57:04,980 --> 00:57:06,540
 and we'll do a section on the deep perception,

1180
00:57:06,540 --> 00:57:07,820
 and we'll put them next to each other,

1181
00:57:07,820 --> 00:57:09,620
 and understand what's good and what.

1182
00:57:09,620 --> 00:57:16,540
 Running inside this,

1183
00:57:16,540 --> 00:57:20,300
 possibly answering your question about from Y to X,

1184
00:57:20,300 --> 00:57:23,780
 you can have state estimation,

1185
00:57:23,780 --> 00:57:25,420
 if you know about Kalman filters,

1186
00:57:25,420 --> 00:57:30,300
 we'll have some state estimation kind of algorithms

1187
00:57:30,300 --> 00:57:31,140
 happening in here.

1188
00:57:31,140 --> 00:57:35,260
 Typically, they're nonlinear observers,

1189
00:57:35,260 --> 00:57:38,180
 but just to give examples,

1190
00:57:38,180 --> 00:57:39,980
 we'll build up our tools

1191
00:57:39,980 --> 00:57:43,100
 for trying to do state estimation in this class.

1192
00:57:43,100 --> 00:57:47,220
 Something that I sweep under the rug in my controls class,

1193
00:57:47,220 --> 00:57:52,220
 but is essential, I think, for doing manipulation.

1194
00:57:53,220 --> 00:57:55,460
 And this may be,

1195
00:57:55,460 --> 00:57:58,460
 you can think of it as outputting an estimate of the state.

1196
00:57:58,460 --> 00:58:13,980
 So as we go,

1197
00:58:13,980 --> 00:58:16,860
 you can have a perfectly algebraic discussion

1198
00:58:16,860 --> 00:58:17,780
 of Kalman filters,

1199
00:58:17,780 --> 00:58:19,260
 and of point cloud algorithms,

1200
00:58:19,260 --> 00:58:20,300
 and stuff like this.

1201
00:58:20,300 --> 00:58:23,020
 We're gonna do the extra step of just saying,

1202
00:58:23,020 --> 00:58:27,500
 how does it fit into my systems framework toolkit?

1203
00:58:27,500 --> 00:58:31,420
 And we'll build up an arsenal of dynamical systems

1204
00:58:31,420 --> 00:58:35,140
 that we can then assemble into a big complicated diagram,

1205
00:58:35,140 --> 00:58:37,020
 and build that's how we're gonna,

1206
00:58:37,020 --> 00:58:38,620
 connect all the pieces together.

1207
00:58:38,620 --> 00:58:44,260
 I think it's essential for addressing the complexity

1208
00:58:44,260 --> 00:58:45,780
 of all the different pieces

1209
00:58:45,780 --> 00:58:48,500
 that we have flying around in a manipulation system,

1210
00:58:48,500 --> 00:58:49,340
 for me.

1211
00:58:50,340 --> 00:58:53,540
 Okay, and we're gonna be talking about

1212
00:58:53,540 --> 00:58:55,140
 planning and control algorithms.

1213
00:58:55,140 --> 00:59:00,340
 Control definitely fits directly into this.

1214
00:59:00,340 --> 00:59:02,540
 It's interesting to think about

1215
00:59:02,540 --> 00:59:04,340
 how a planning algorithm fits in.

1216
00:59:04,340 --> 00:59:07,860
 It gets more subtle, more complicated.

1217
00:59:07,860 --> 00:59:11,140
 But I still think it's essential

1218
00:59:11,140 --> 00:59:13,220
 to think about the semantics

1219
00:59:13,220 --> 00:59:16,460
 of how your planner is gonna interact

1220
00:59:16,460 --> 00:59:18,260
 with the real world clock.

1221
00:59:19,220 --> 00:59:22,220
 So maybe I have some sensors coming in,

1222
00:59:22,220 --> 00:59:25,540
 or my state estimate coming in,

1223
00:59:25,540 --> 00:59:30,100
 and I have some motion planner algorithm.

1224
00:59:30,100 --> 00:59:31,700
 Maybe it takes a long time

1225
00:59:31,700 --> 00:59:36,700
 for me to decide exactly how I'm gonna move my robot.

1226
00:59:36,700 --> 00:59:40,980
 And I only very slowly put out an entire motion plan,

1227
00:59:40,980 --> 00:59:42,940
 like a desired trajectory.

1228
00:59:43,460 --> 00:59:46,220
 (marker tapping)

1229
00:59:46,220 --> 00:59:54,180
 Okay, but then you need additional semantics,

1230
00:59:54,180 --> 00:59:57,380
 and additional tools to understand

1231
00:59:57,380 --> 01:00:02,020
 how I'm gonna execute that trajectory

1232
01:00:02,020 --> 01:00:05,020
 in a feedback controller that takes in

1233
01:00:05,020 --> 01:00:09,180
 my current sensors, X hat, right?

1234
01:00:09,180 --> 01:00:12,380
 It outputs my commands to my robot.

1235
01:00:12,860 --> 01:00:14,980
 (marker tapping)

1236
01:00:14,980 --> 01:00:16,340
 Okay, and onward and upward.

1237
01:00:16,340 --> 01:00:17,540
 So you get the idea, right?

1238
01:00:17,540 --> 01:00:22,420
 I think this idea of starting with difference equations,

1239
01:00:22,420 --> 01:00:25,380
 and understanding, using that as the glue

1240
01:00:25,380 --> 01:00:27,700
 to put all of our pieces together

1241
01:00:27,700 --> 01:00:30,420
 is kind of the way I wanna organize

1242
01:00:30,420 --> 01:00:34,100
 the diversity of topics we have in the class,

1243
01:00:34,100 --> 01:00:35,500
 and make you feel like, I hope,

1244
01:00:35,500 --> 01:00:37,980
 feel like you've got a pretty strong toolbox

1245
01:00:37,980 --> 01:00:41,300
 that you can compose lots of different systems

1246
01:00:41,300 --> 01:00:42,700
 and make them work together.

1247
01:00:42,700 --> 01:00:44,980
 Even at the control level,

1248
01:00:44,980 --> 01:00:47,180
 there's so many choices and so many details.

1249
01:00:47,180 --> 01:00:51,220
 We'll do differential inverse kinematics controllers.

1250
01:00:51,220 --> 01:00:52,700
 We'll do force control.

1251
01:00:52,700 --> 01:00:54,900
 We'll do impedance control, those kind of ideas.

1252
01:00:54,900 --> 01:00:57,100
 And they all fit into this sort of framework.

1253
01:00:57,100 --> 01:01:07,860
 Now, as we get deeper into the rabbit hole,

1254
01:01:10,340 --> 01:01:14,700
 even my X, N plus one is F of X, U,

1255
01:01:14,700 --> 01:01:17,220
 starts feeling inadequate.

1256
01:01:17,220 --> 01:01:19,420
 So we will generalize it a little bit more.

1257
01:01:19,420 --> 01:01:36,020
 But not a lot more, actually.

1258
01:01:36,020 --> 01:01:38,900
 And you get pretty far if you think about it

1259
01:01:40,060 --> 01:01:43,420
 as having X, having U.

1260
01:01:43,420 --> 01:01:49,260
 It's often very useful and meaningful

1261
01:01:49,260 --> 01:01:54,260
 to separate U that is sort of commanded by the controller

1262
01:01:54,260 --> 01:01:57,740
 versus random disturbances W.

1263
01:01:57,740 --> 01:02:00,340
 This would be disturbance inputs, or random.

1264
01:02:09,900 --> 01:02:14,500
 And then you can have some parameters P,

1265
01:02:14,500 --> 01:02:22,900
 which could be the size of the red cube, for instance.

1266
01:02:22,900 --> 01:02:32,100
 Or it could be the weights of my neural network.

1267
01:02:32,100 --> 01:02:34,940
 (markers tapping)

1268
01:02:34,940 --> 01:02:44,060
 Okay, maybe they have dynamics, but the way I wrote it,

1269
01:02:44,060 --> 01:02:47,600
 maybe they are fixed over the course of a simulation.

1270
01:02:47,600 --> 01:02:55,900
 Okay, and sometimes this might be a vector,

1271
01:02:55,900 --> 01:03:00,620
 just a vector of real numbers.

1272
01:03:00,620 --> 01:03:03,980
 (markers tapping)

1273
01:03:03,980 --> 01:03:08,980
 Say a vector in Rn, or could be a structured data,

1274
01:03:08,980 --> 01:03:16,780
 like an RGB image, which you could, of course, vectorize,

1275
01:03:16,780 --> 01:03:20,580
 but at some point you wanna start keeping around

1276
01:03:20,580 --> 01:03:21,940
 the structure of the data.

1277
01:03:21,940 --> 01:03:26,340
 Or a motion plan is another good example.

1278
01:03:26,340 --> 01:03:29,180
 (markers tapping)

1279
01:03:29,180 --> 01:03:36,060
 Okay, so the same language holds,

1280
01:03:36,060 --> 01:03:39,180
 but we're gonna take it in its full generality.

1281
01:03:39,180 --> 01:03:46,060
 There's some software that we'll use with the course

1282
01:03:46,060 --> 01:03:50,500
 that wraps all this up into code, okay?

1283
01:03:50,500 --> 01:03:54,100
 I wanna make this point because,

1284
01:03:54,100 --> 01:03:57,500
 so Drake is the name of the software.

1285
01:03:57,500 --> 01:04:09,400
 And one of the things it has is a way to compose

1286
01:04:09,400 --> 01:04:11,020
 and write these block diagrams.

1287
01:04:11,020 --> 01:04:15,940
 But because of the, it uses this sort of

1288
01:04:15,940 --> 01:04:18,340
 difference equation back end,

1289
01:04:18,340 --> 01:04:20,260
 but it wants to be able to support

1290
01:04:20,260 --> 01:04:23,460
 all the different possible permutations or variations

1291
01:04:23,460 --> 01:04:25,560
 or structured data that you want in here.

1292
01:04:25,560 --> 01:04:31,620
 We tend to wrap this up in code with something,

1293
01:04:31,620 --> 01:04:38,060
 we'll call that the context,

1294
01:04:38,060 --> 01:04:42,940
 which you can think of as just having some,

1295
01:04:42,940 --> 01:04:45,820
 let's say a vector X or a state X,

1296
01:04:45,820 --> 01:04:50,820
 and some vector U, maybe W, maybe P,

1297
01:04:51,820 --> 01:04:56,820
 okay, sorry for my silly pseudocode, okay?

1298
01:04:56,820 --> 01:05:01,060
 But you'll see me writing in code,

1299
01:05:01,060 --> 01:05:05,140
 you will write and I will write sometimes

1300
01:05:05,140 --> 01:05:06,740
 something that looks more like,

1301
01:05:06,740 --> 01:05:14,560
 I'm just gonna pass in a context,

1302
01:05:14,560 --> 01:05:16,620
 which is just the list of all the possible,

1303
01:05:16,620 --> 01:05:19,060
 even the time N might be in here,

1304
01:05:20,100 --> 01:05:21,460
 it could be time dependent.

1305
01:05:21,460 --> 01:05:24,140
 Okay, but if you see that, don't be alarmed,

1306
01:05:24,140 --> 01:05:25,460
 I'm still just talking about difference

1307
01:05:25,460 --> 01:05:27,100
 and differential equations,

1308
01:05:27,100 --> 01:05:29,940
 and we just lumped all of those into a structure.

1309
01:05:29,940 --> 01:05:47,440
 Okay, so the cool thing about having that language

1310
01:05:47,440 --> 01:05:49,940
 is that all of the fundamental questions

1311
01:05:49,940 --> 01:05:52,920
 of systems theory, and I would say maybe AI,

1312
01:05:52,920 --> 01:05:58,700
 can sort of be asked in a specific and clear way,

1313
01:05:58,700 --> 01:06:01,220
 given that basic language, right?

1314
01:06:01,220 --> 01:06:03,720
 So, simulation is what we did

1315
01:06:03,720 --> 01:06:14,180
 for the linear difference equation.

1316
01:06:14,180 --> 01:06:19,180
 You know, if you give me X zero and a point,

1317
01:06:19,780 --> 01:06:22,940
 and a bunch of, and my control inputs U,

1318
01:06:22,940 --> 01:06:26,060
 I use the dot for sort of a trajectory of U's,

1319
01:06:26,060 --> 01:06:31,940
 then I need to compute X at some future step.

1320
01:06:31,940 --> 01:06:39,780
 That's just evolving my difference equations in time,

1321
01:06:39,780 --> 01:06:41,780
 which was sort of natural to do for the linear systems,

1322
01:06:41,780 --> 01:06:43,620
 but you can do it even if it's a physics engine

1323
01:06:43,620 --> 01:06:45,700
 and a renderer, okay?

1324
01:06:47,500 --> 01:06:48,980
 Planning, right, is given,

1325
01:06:48,980 --> 01:07:00,660
 one form of planning is given X zero

1326
01:07:00,660 --> 01:07:05,660
 and some objective or goal cost function, say.

1327
01:07:05,660 --> 01:07:15,780
 You need to compute some series of U

1328
01:07:16,780 --> 01:07:21,780
 and maybe X also that minimizes my objective

1329
01:07:21,780 --> 01:07:28,580
 or obtains my goal, okay?

1330
01:07:28,580 --> 01:07:32,100
 You know, state estimation, it all fits.

1331
01:07:32,100 --> 01:07:33,940
 It's all just different questions to ask

1332
01:07:33,940 --> 01:07:36,740
 about the same set of difference equations, right?

1333
01:07:36,740 --> 01:07:40,340
 State estimation says, if you give me X zero

1334
01:07:45,720 --> 01:07:50,720
 or let's even Y zero to Yn, U zero to Un,

1335
01:07:50,720 --> 01:08:00,820
 you know, estimate X hat n or n plus one.

1336
01:08:00,820 --> 01:08:05,820
 The off by one can be (indistinct) sometimes.

1337
01:08:05,820 --> 01:08:12,940
 Stability analysis, verification, learning,

1338
01:08:12,940 --> 01:08:16,280
 system identification, they're all just variations

1339
01:08:16,280 --> 01:08:18,180
 of the same question.

1340
01:08:18,180 --> 01:08:21,780
 So system identification or model learning, if you will,

1341
01:08:21,780 --> 01:08:32,740
 is just given data of U, X, estimate P.

1342
01:08:33,440 --> 01:08:38,440
 Of U, X, estimate P, right?

1343
01:08:38,440 --> 01:08:44,480
 Even if it's a neural network

1344
01:08:44,480 --> 01:08:46,680
 and you wanna find the weights of P.

1345
01:08:46,680 --> 01:08:50,580
 All of these questions can be asked

1346
01:08:50,580 --> 01:08:54,180
 in a very rigorous or clear headed way

1347
01:08:54,180 --> 01:08:57,140
 about equations that look like that.

1348
01:08:57,140 --> 01:08:59,160
 And it really shouldn't matter that much.

1349
01:08:59,160 --> 01:09:00,780
 Part of my system is a neural network

1350
01:09:00,780 --> 01:09:02,600
 and part of it is a physics simulator

1351
01:09:02,600 --> 01:09:04,340
 or the whole thing is a neural network

1352
01:09:04,340 --> 01:09:07,120
 or any combination of the two, okay?

1353
01:09:07,120 --> 01:09:10,280
 So this for me is maybe the biggest reason

1354
01:09:10,280 --> 01:09:12,880
 to try to conceptualize clearly in the language

1355
01:09:12,880 --> 01:09:17,420
 of dynamical systems, the basic framework

1356
01:09:17,420 --> 01:09:20,500
 and to build up our library, our arsenal of tools,

1357
01:09:20,500 --> 01:09:22,060
 always connecting back to that framework

1358
01:09:22,060 --> 01:09:26,240
 because then you have a point cloud estimation algorithm.

1359
01:09:26,240 --> 01:09:27,200
 If you throw it in this language,

1360
01:09:27,200 --> 01:09:29,080
 I can still do system identification through it

1361
01:09:29,080 --> 01:09:30,240
 if that's what I wanted to do.

1362
01:09:30,240 --> 01:09:33,480
 That's a particularly weird one, but we could do it, okay?

1363
01:09:33,480 --> 01:09:38,680
 Questions about that?

1364
01:09:38,680 --> 01:09:41,060
 About that general philosophy?

1365
01:09:41,060 --> 01:09:43,840
 Yeah.

1366
01:09:43,840 --> 01:09:45,080
 - All right, could you explain again

1367
01:09:45,080 --> 01:09:46,960
 one more time what is W?

1368
01:09:46,960 --> 01:09:50,200
 - W is like a random disturbance input

1369
01:09:50,200 --> 01:09:54,160
 or any other random input.

1370
01:09:54,160 --> 01:09:57,440
 So people in reinforcement learning

1371
01:09:57,440 --> 01:09:59,400
 will do domain randomization.

1372
01:09:59,400 --> 01:10:01,600
 They'll try to change the lighting conditions

1373
01:10:01,600 --> 01:10:02,640
 on the robot or something like that.

1374
01:10:02,640 --> 01:10:06,440
 I would bring that in through W just to have clearly,

1375
01:10:06,440 --> 01:10:08,600
 because robustness analysis, for instance,

1376
01:10:08,600 --> 01:10:11,080
 would be to try to find a U and an X

1377
01:10:11,080 --> 01:10:13,280
 that works well for all W

1378
01:10:13,280 --> 01:10:16,000
 or over some expected value of W.

1379
01:10:16,000 --> 01:10:17,520
 So to be able to separate those out

1380
01:10:17,520 --> 01:10:18,920
 and ask the question clearly

1381
01:10:18,920 --> 01:10:20,800
 about what I'm trying to be robust to

1382
01:10:20,800 --> 01:10:23,720
 versus what I'm trying to allow to optimize.

1383
01:10:23,720 --> 01:10:25,700
 But in the diagram, you could actually pull them in

1384
01:10:25,700 --> 01:10:26,840
 through the same input.

1385
01:10:28,320 --> 01:10:30,720
 That's sort of the notation from robust control,

1386
01:10:30,720 --> 01:10:33,120
 but it works for our own.

1387
01:10:33,120 --> 01:10:37,120
 - Also, as a general note,

1388
01:10:37,120 --> 01:10:38,360
 when people are asking questions,

1389
01:10:38,360 --> 01:10:41,080
 try to speak up so we can pick you up on the streaming.

1390
01:10:41,080 --> 01:10:43,080
 - I should, it should be my burden.

1391
01:10:43,080 --> 01:10:44,560
 I should repeat the question.

1392
01:10:44,560 --> 01:10:46,160
 But that's an awesome, thank you.

1393
01:10:46,160 --> 01:10:48,200
 Yeah, I will repeat the question.

1394
01:10:48,200 --> 01:10:51,360
 So the question was, in that case, was what is W?

1395
01:10:51,360 --> 01:10:52,200
 Yes?

1396
01:10:52,200 --> 01:10:56,040
 - So I understand there is feedback in each nitro.

1397
01:10:56,040 --> 01:10:56,880
 - Potentially, yeah.

1398
01:10:56,880 --> 01:11:01,440
 - Is there like a channel system feedback

1399
01:11:01,440 --> 01:11:02,760
 that's going on between different--

1400
01:11:02,760 --> 01:11:03,800
 - I missed the middle word there.

1401
01:11:03,800 --> 01:11:04,720
 Is there what feedback?

1402
01:11:04,720 --> 01:11:07,800
 - Is there like a channel system feedback?

1403
01:11:07,800 --> 01:11:08,640
 - Yes.

1404
01:11:08,640 --> 01:11:13,640
 - Can there be feedback from motion planning to perception?

1405
01:11:13,640 --> 01:11:15,920
 - So each of those block,

1406
01:11:15,920 --> 01:11:17,480
 that's what you're gonna be revealing

1407
01:11:17,480 --> 01:11:19,160
 at the block diagram level.

1408
01:11:19,160 --> 01:11:20,920
 It forces you to be explicit about

1409
01:11:20,920 --> 01:11:23,640
 what data is flowing in what directions.

1410
01:11:23,640 --> 01:11:25,880
 Does my motion planning system have to have

1411
01:11:25,880 --> 01:11:28,600
 a streaming update of the camera or not?

1412
01:11:28,600 --> 01:11:29,960
 The block diagram sort of forces you

1413
01:11:29,960 --> 01:11:31,480
 to be explicit about that.

1414
01:11:31,480 --> 01:11:33,960
 And a little bit sparing, I think,

1415
01:11:33,960 --> 01:11:35,600
 in your use of the different,

1416
01:11:35,600 --> 01:11:39,360
 I think it's cleaner if you don't depend on everything.

1417
01:11:39,360 --> 01:11:42,560
 But absolutely, that information should flow.

1418
01:11:42,560 --> 01:11:52,760
 Okay, so the simulation framework in Drake

1419
01:11:52,760 --> 01:11:55,120
 encourages this behavior.

1420
01:11:55,120 --> 01:11:58,720
 It's not the standard in robotics, I would say.

1421
01:11:58,720 --> 01:12:01,040
 Well, certainly Drake is not the standard yet,

1422
01:12:01,040 --> 01:12:06,040
 but I would say the emphasis on writing out

1423
01:12:06,040 --> 01:12:09,680
 and declaring your state and declaring yourself

1424
01:12:09,680 --> 01:12:14,000
 in this sort of extra specific way

1425
01:12:14,000 --> 01:12:17,880
 is I'm asking more of you than what Ross,

1426
01:12:17,880 --> 01:12:20,440
 if you used Ross or something, would ask of you.

1427
01:12:20,440 --> 01:12:24,240
 But I think we get to do more pedagogical,

1428
01:12:24,240 --> 01:12:25,440
 and it's better for teaching,

1429
01:12:25,440 --> 01:12:28,320
 but it's also better for debugging and analysis

1430
01:12:28,320 --> 01:12:29,160
 and all these things.

1431
01:12:29,160 --> 01:12:32,720
 It will be able to ask more clear questions.

1432
01:12:32,720 --> 01:12:35,880
 In my mind, in fact, message passing systems,

1433
01:12:35,880 --> 01:12:40,040
 so for those of you that are doing robotics yet,

1434
01:12:40,040 --> 01:12:42,280
 oftentimes we actually run our controller

1435
01:12:42,280 --> 01:12:44,800
 and our perception system and our robot driver

1436
01:12:44,800 --> 01:12:46,880
 all on separate threads, at least,

1437
01:12:46,880 --> 01:12:48,760
 maybe separate computers, and we're just talking

1438
01:12:48,760 --> 01:12:51,280
 over some network message passing interface.

1439
01:12:51,280 --> 01:12:54,280
 Okay, that's yet another, I would model

1440
01:12:54,280 --> 01:12:56,940
 that message passing as another system,

1441
01:12:56,940 --> 01:12:59,620
 which has random delay and dropouts,

1442
01:12:59,620 --> 01:13:01,240
 and it's a whole bunch of complexity

1443
01:13:01,240 --> 01:13:03,880
 that if you wanna actually analyze this thing,

1444
01:13:03,880 --> 01:13:05,200
 you should embrace, right?

1445
01:13:05,200 --> 01:13:07,440
 And we tend to sweep it under the rug

1446
01:13:07,440 --> 01:13:08,880
 and get by a lot of the times

1447
01:13:08,880 --> 01:13:11,640
 until you have to really make something work

1448
01:13:11,640 --> 01:13:14,520
 100% of the time, and then it starts really getting you.

1449
01:13:14,520 --> 01:13:16,600
 It turns out a lot of people don't,

1450
01:13:16,600 --> 01:13:19,400
 so there's a simple property you would think you'd want,

1451
01:13:19,400 --> 01:13:22,080
 which is to be able to deterministically repeat

1452
01:13:22,080 --> 01:13:23,520
 your simulation, right?

1453
01:13:23,520 --> 01:13:26,440
 It's hard, a lot of things, a lot of our robotics tools

1454
01:13:26,440 --> 01:13:29,280
 don't permit that, to actually get the same answer twice.

1455
01:13:29,280 --> 01:13:32,720
 But for teaching, I want you to get the same answer twice.

1456
01:13:32,720 --> 01:13:34,160
 Right, if I wanna write a grade,

1457
01:13:34,160 --> 01:13:36,280
 I want it to come out with the same answer twice.

1458
01:13:36,280 --> 01:13:40,600
 Okay, let me take it home with, so that is,

1459
01:13:40,600 --> 01:13:42,320
 so Drake, the software you'll use,

1460
01:13:42,320 --> 01:13:45,240
 in the past, I have been a little bit shy

1461
01:13:45,240 --> 01:13:47,200
 about pushing Drake on people,

1462
01:13:47,200 --> 01:13:49,320
 and I feel the feedback I've gotten

1463
01:13:49,320 --> 01:13:51,120
 has been, at the end of the class,

1464
01:13:51,120 --> 01:13:53,120
 I wish you had just told me a little bit more about Drake

1465
01:13:53,120 --> 01:13:54,440
 so that I was more of an expert

1466
01:13:54,440 --> 01:13:55,880
 when it came time for my project.

1467
01:13:55,880 --> 01:13:57,600
 So we're gonna do a little bit more

1468
01:13:57,600 --> 01:14:00,160
 of sort of like explaining what's going on there.

1469
01:14:00,160 --> 01:14:04,720
 This idea of the context is one idea behind it,

1470
01:14:04,720 --> 01:14:09,720
 but Drake roughly is three big parts.

1471
01:14:09,720 --> 01:14:13,960
 One of them is this notion of assembling your systems

1472
01:14:13,960 --> 01:14:16,520
 in block diagrams and writing each of the systems out

1473
01:14:16,520 --> 01:14:17,920
 with their state and their control

1474
01:14:17,920 --> 01:14:20,160
 and their disturbance inputs and the like.

1475
01:14:20,160 --> 01:14:22,560
 There's tutorials, okay.

1476
01:14:22,560 --> 01:14:27,800
 There's a physics engine, which is, I think,

1477
01:14:27,800 --> 01:14:31,040
 world-class for simulating contact and the like,

1478
01:14:31,040 --> 01:14:33,200
 so you'll be able to do the very rich

1479
01:14:33,200 --> 01:14:35,560
 contact simulations like you saw.

1480
01:14:35,560 --> 01:14:37,560
 And then when we get to motion planning

1481
01:14:37,560 --> 01:14:40,360
 and optimization and system identification and learning,

1482
01:14:40,360 --> 01:14:43,600
 we'll be putting to use some of the optimization tools

1483
01:14:43,600 --> 01:14:47,000
 that are just like the third big component inside Drake.

1484
01:14:48,000 --> 01:14:53,000
 So, you know, the type of notation that you will see

1485
01:14:53,000 --> 01:14:58,400
 in there is it really just says,

1486
01:14:58,400 --> 01:15:00,680
 I'm gonna make a new system.

1487
01:15:00,680 --> 01:15:03,880
 I'm gonna declare my state to be some variable.

1488
01:15:03,880 --> 01:15:07,200
 I'm gonna declare my dynamics to have some dynamics.

1489
01:15:07,200 --> 01:15:09,280
 I'm gonna declare my output.

1490
01:15:09,280 --> 01:15:13,080
 This is like, we just codify the equations

1491
01:15:13,080 --> 01:15:14,920
 that I put on the board, okay.

1492
01:15:14,920 --> 01:15:17,720
 And it really does sort of follow the standard

1493
01:15:17,720 --> 01:15:21,760
 discrete difference equation or continuous

1494
01:15:21,760 --> 01:15:25,240
 or many mixture of the two sort of notation.

1495
01:15:25,240 --> 01:15:31,960
 And you can assemble big, complicated diagrams.

1496
01:15:31,960 --> 01:15:34,920
 This is actually, you know, an expandable diagram

1497
01:15:34,920 --> 01:15:39,680
 that I put in the notes, but this is what it took

1498
01:15:39,680 --> 01:15:41,400
 to run the little teleop interface,

1499
01:15:41,400 --> 01:15:43,240
 my little silly thing where I dram the robot

1500
01:15:43,240 --> 01:15:45,720
 into the table and it shot the brick to the left

1501
01:15:45,720 --> 01:15:46,920
 off the screen, right.

1502
01:15:46,920 --> 01:15:50,080
 That actually involved an inverse dynamics controller,

1503
01:15:50,080 --> 01:15:52,760
 a physics engine, a geometry engine for the perception

1504
01:15:52,760 --> 01:15:54,600
 for, you know, like a lot of pieces

1505
01:15:54,600 --> 01:15:57,120
 were assembled together to make that simple demo.

1506
01:15:57,120 --> 01:15:58,240
 And you're gonna be able to build on that

1507
01:15:58,240 --> 01:16:00,680
 and understand it.

1508
01:16:00,680 --> 01:16:03,200
 There's nothing, it's open source, right.

1509
01:16:03,200 --> 01:16:06,520
 So there's nothing that's hidden from you.

1510
01:16:06,520 --> 01:16:08,120
 You can choose to dig in or not.

1511
01:16:08,120 --> 01:16:11,280
 And there's sort of a commitment for me

1512
01:16:11,280 --> 01:16:12,520
 to be open source, right.

1513
01:16:12,520 --> 01:16:15,720
 So I think you'll see that throughout the class.

1514
01:16:15,720 --> 01:16:19,320
 Like actually, if you were to look really carefully

1515
01:16:19,320 --> 01:16:21,360
 right now at the visualization of that sliders

1516
01:16:21,360 --> 01:16:24,720
 that came down, the word open close gripper

1517
01:16:24,720 --> 01:16:29,440
 is truncated at grip because there was a bug in the,

1518
01:16:29,440 --> 01:16:32,520
 you know, in some, I decided to basically push open source.

1519
01:16:32,520 --> 01:16:34,640
 You know, I tried to push a fix upstream

1520
01:16:34,640 --> 01:16:37,040
 to like the GUI, the JavaScript GUI tool

1521
01:16:37,040 --> 01:16:37,960
 that I was using or whatever.

1522
01:16:37,960 --> 01:16:39,800
 And it's gonna take a few days for that to trickle through

1523
01:16:39,800 --> 01:16:41,880
 and for me to update my dependencies and whatever.

1524
01:16:41,880 --> 01:16:44,440
 But there's kind of like a commitment that you make

1525
01:16:44,440 --> 01:16:45,960
 when you live in the open source world

1526
01:16:45,960 --> 01:16:47,680
 to like try to make everything better

1527
01:16:47,680 --> 01:16:48,920
 every time you touch it, you know.

1528
01:16:48,920 --> 01:16:51,200
 And you'll see that commitment.

1529
01:16:51,200 --> 01:16:52,960
 Sometimes you'll be mad at me for that commitment, maybe.

1530
01:16:52,960 --> 01:16:55,240
 But I do my best to try to keep this, you know,

1531
01:16:55,240 --> 01:16:58,760
 very open Toyota Research Institute

1532
01:16:58,760 --> 01:17:01,480
 is putting a ton of effort into it and keeping it open,

1533
01:17:01,480 --> 01:17:04,240
 which was a great thing to have accomplished.

1534
01:17:04,240 --> 01:17:08,680
 And it's all connected into the notebook.

1535
01:17:08,680 --> 01:17:11,440
 So we'll see that here.

1536
01:17:11,440 --> 01:17:16,360
 So you'll see that, you know, I can,

1537
01:17:16,360 --> 01:17:19,320
 in the system's way of thinking,

1538
01:17:19,320 --> 01:17:21,520
 I can encapsulate an entire diagram

1539
01:17:21,520 --> 01:17:23,560
 and make some abstract powerful abstractions.

1540
01:17:23,560 --> 01:17:26,280
 So that my entire robot, which is a physics engine

1541
01:17:26,280 --> 01:17:28,640
 and a sensor simulation for a camera

1542
01:17:28,640 --> 01:17:31,600
 and a low level controller and everything like that.

1543
01:17:31,600 --> 01:17:34,920
 You know, we bottle that up into a, you know,

1544
01:17:34,920 --> 01:17:38,600
 a bigger system called the manipulation station.

1545
01:17:38,600 --> 01:17:41,640
 But, you know, it takes in just position commands,

1546
01:17:41,640 --> 01:17:44,280
 possibly feed forward torques, gripper commands.

1547
01:17:44,280 --> 01:17:46,840
 Inside it is a whole bunch of different components

1548
01:17:46,840 --> 01:17:49,920
 that make that thing tick.

1549
01:17:49,920 --> 01:17:53,160
 And it outputs a lot of different outputs,

1550
01:17:53,160 --> 01:17:57,520
 which were chosen because they are the same outputs

1551
01:17:57,520 --> 01:18:01,480
 that the real hardware outputs.

1552
01:18:01,480 --> 01:18:04,400
 And so there's an almost identical system

1553
01:18:04,400 --> 01:18:07,000
 called the manipulation station hardware interface,

1554
01:18:07,000 --> 01:18:10,440
 which presents the same inputs and outputs,

1555
01:18:10,440 --> 01:18:11,560
 except for a few cheap ports

1556
01:18:11,560 --> 01:18:14,600
 you're allowed to have in simulation, okay?

1557
01:18:14,600 --> 01:18:16,480
 But inside this system,

1558
01:18:16,480 --> 01:18:18,520
 there's just a bunch of driver code

1559
01:18:18,520 --> 01:18:21,360
 or message passing to the drivers or something like this.

1560
01:18:21,360 --> 01:18:23,600
 So you can take your big complicated perception control

1561
01:18:23,600 --> 01:18:26,400
 or whatever, train it up in simulation,

1562
01:18:26,400 --> 01:18:28,360
 pull that system out, put the robot,

1563
01:18:28,360 --> 01:18:32,000
 physical robot in effectively and be running immediately.

1564
01:18:32,000 --> 01:18:33,680
 So if we get you guys to the hardware,

1565
01:18:33,680 --> 01:18:35,280
 that's the way it makes it work.

1566
01:18:35,280 --> 01:18:37,680
 (whispering)

1567
01:18:37,680 --> 01:18:43,200
 Okay, so I mentioned it already,

1568
01:18:43,200 --> 01:18:44,880
 you know, the schedule's online,

1569
01:18:44,880 --> 01:18:46,600
 but we're gonna go through,

1570
01:18:46,600 --> 01:18:48,120
 not only are we gonna try to build up

1571
01:18:48,120 --> 01:18:51,560
 an arsenal of components that you can put together,

1572
01:18:51,560 --> 01:18:52,720
 but I wanna order it in a way

1573
01:18:52,720 --> 01:18:55,240
 that you're solving more and more complex tasks.

1574
01:18:55,240 --> 01:18:58,240
 And I don't wanna introduce a new technique

1575
01:18:58,240 --> 01:19:00,400
 unless it actually helps you do something cool

1576
01:19:00,400 --> 01:19:02,560
 that you couldn't do before.

1577
01:19:02,560 --> 01:19:04,080
 So we'll start off by just telling you

1578
01:19:04,080 --> 01:19:06,560
 about the hardware that we have in robotics

1579
01:19:06,560 --> 01:19:08,800
 and how we might model that a little bit,

1580
01:19:08,800 --> 01:19:11,880
 do some basic pick and place, even with that red cube,

1581
01:19:11,880 --> 01:19:13,760
 but that'll force us to think about kinematics,

1582
01:19:13,760 --> 01:19:16,360
 differential kinematics, some basic motion planning.

1583
01:19:16,360 --> 01:19:20,600
 Then we'll start doing the 3D geometric perception.

1584
01:19:20,600 --> 01:19:25,440
 Then we'll start making the scenes more cluttered

1585
01:19:25,440 --> 01:19:29,040
 and have to think about more complicated plans for grasping.

1586
01:19:29,040 --> 01:19:31,080
 How do you choose a collision-free grasp

1587
01:19:31,080 --> 01:19:34,960
 that's gonna get a good contact with my environment?

1588
01:19:34,960 --> 01:19:37,160
 We'll make a more and more complicated system

1589
01:19:37,160 --> 01:19:38,480
 in that respect.

1590
01:19:38,480 --> 01:19:40,600
 We'll start programming some higher level behaviors

1591
01:19:40,600 --> 01:19:42,000
 in that world.

1592
01:19:42,000 --> 01:19:45,520
 Then we'll get to deep perception.

1593
01:19:45,520 --> 01:19:47,760
 So we'll stop assuming that we know

1594
01:19:47,760 --> 01:19:48,800
 what objects are in the world

1595
01:19:48,800 --> 01:19:51,200
 and we'll have to detect objects when they happen.

1596
01:19:51,200 --> 01:19:52,320
 We'll have to segment the world

1597
01:19:52,320 --> 01:19:55,280
 into reasonable things for manipulation

1598
01:19:55,280 --> 01:19:59,640
 and build more interesting state representations of the world.

1599
01:19:59,640 --> 01:20:01,160
 We'll do some work on force control

1600
01:20:01,160 --> 01:20:02,920
 and trajectory tracking and motion planning

1601
01:20:02,920 --> 01:20:06,000
 that will allow our robots to do more dexterous things

1602
01:20:06,000 --> 01:20:08,120
 in those same kind of environments.

1603
01:20:08,120 --> 01:20:13,280
 We'll then take some of the things that we've already done

1604
01:20:13,280 --> 01:20:15,360
 and we can do a little better with reinforcement learning.

1605
01:20:15,360 --> 01:20:17,800
 I wanna compare and contrast those

1606
01:20:17,800 --> 01:20:19,560
 with the model-based approaches.

1607
01:20:19,560 --> 01:20:21,920
 And then we'll end the term,

1608
01:20:21,920 --> 01:20:23,960
 as you guys are deep in your projects,

1609
01:20:23,960 --> 01:20:28,040
 we will end the term with a few kind of boutique lectures,

1610
01:20:28,040 --> 01:20:29,000
 if you will, of some of the,

1611
01:20:29,000 --> 01:20:31,360
 what's hot in robotics right now.

1612
01:20:31,360 --> 01:20:34,800
 I'll give a lecture each on some of the hot topics.

1613
01:20:34,800 --> 01:20:38,240
 I'll take feedback even if you guys,

1614
01:20:38,240 --> 01:20:40,520
 if you think, oh, I'd really love to hear about this,

1615
01:20:40,520 --> 01:20:42,000
 it's not on your list.

1616
01:20:42,000 --> 01:20:45,160
 I'd say those last ones will do runtime decision.

1617
01:20:45,160 --> 01:20:52,280
 All right, so just to put that same slide up again,

1618
01:20:52,280 --> 01:20:54,800
 make sure you're on Piazza,

1619
01:20:54,800 --> 01:20:56,680
 take a look at the course guidelines,

1620
01:20:57,600 --> 01:20:59,480
 take a look at the lecture notes,

1621
01:20:59,480 --> 01:21:01,520
 run my little GUI slider 'cause I've heard,

1622
01:21:01,520 --> 01:21:02,960
 really heard of that.

1623
01:21:02,960 --> 01:21:05,640
 (audience laughing)

1624
01:21:05,640 --> 01:21:07,000
 I'm afraid no one's gonna hear.

1625
01:21:07,000 --> 01:21:08,840
 And if DeepNote doesn't work for you, tell me.

1626
01:21:08,840 --> 01:21:10,800
 That's like, that's the biggest uncertainty in my mind

1627
01:21:10,800 --> 01:21:14,080
 is like, I just changed the whole back end of that.

1628
01:21:14,080 --> 01:21:15,640
 The P-set's gonna be released tomorrow.

1629
01:21:15,640 --> 01:21:17,440
 There's a white P-set for this week

1630
01:21:17,440 --> 01:21:21,800
 that we're gonna start our Wednesday cadence of problem sets

1631
01:21:21,800 --> 01:21:24,080
 and start talking about final project.

1632
01:21:24,080 --> 01:21:24,920
 I promise.

1633
01:21:24,920 --> 01:21:28,080
 (audience chattering)

1634
01:21:28,600 --> 01:21:31,760
 (audience chattering)

1635
01:21:31,760 --> 01:21:42,040
 [BLANK_AUDIO]

