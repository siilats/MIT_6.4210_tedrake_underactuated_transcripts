1
00:00:00,000 --> 00:00:05,280
 That wasn't weird at all.

2
00:00:05,280 --> 00:00:09,040
 All right.

3
00:00:09,040 --> 00:00:15,800
 So today is the second of our boutique lectures and actually the third to last lecture.

4
00:00:15,800 --> 00:00:21,780
 So we've spent the last four or five lectures, I think, on RL and learning.

5
00:00:21,780 --> 00:00:25,640
 And today we're going to take a slightly different perspective.

6
00:00:25,640 --> 00:00:31,040
 We've been working on how to generate more short-term behavior from scratch.

7
00:00:31,040 --> 00:00:39,120
 And today we're going to think more about multi-step manipulation and long horizon planning

8
00:00:39,120 --> 00:00:41,740
 and work that is general.

9
00:00:41,740 --> 00:00:44,800
 And so to set the stage, I want to give a couple of videos of examples, kind of giving

10
00:00:44,800 --> 00:00:54,040
 the motivation of the type of behavior that we're interested in producing.

11
00:00:54,040 --> 00:00:58,360
 So the kinds of things that I would like my robots to do-- this is a very simplified kitchen

12
00:00:58,360 --> 00:00:59,360
 example.

13
00:00:59,360 --> 00:01:01,440
 Here, a green block is supposed to be food.

14
00:01:01,440 --> 00:01:04,320
 Just believe with me.

15
00:01:04,320 --> 00:01:10,000
 And what we want our robots to do is it's doing what I'll argue is a complex series

16
00:01:10,000 --> 00:01:13,040
 of manipulation tasks.

17
00:01:13,040 --> 00:01:14,040
 It's placing things.

18
00:01:14,040 --> 00:01:15,040
 It's picking things.

19
00:01:15,040 --> 00:01:18,280
 It's sequencing the series of actions.

20
00:01:18,280 --> 00:01:23,560
 It's making a lot of different choices based off geometry.

21
00:01:23,560 --> 00:01:29,280
 It's doing all of that important motion planning stuff.

22
00:01:29,280 --> 00:01:30,840
 And this is a video you all have seen before.

23
00:01:30,840 --> 00:01:33,920
 Here again, we're doing multi-step manipulation.

24
00:01:33,920 --> 00:01:38,600
 And in addition to reasoning over all of the motion constraints here-- and we'll return

25
00:01:38,600 --> 00:01:42,600
 back to this example-- we're reasoning over force constraints as well.

26
00:01:42,600 --> 00:01:46,080
 And this is to open the bottle.

27
00:01:46,080 --> 00:01:50,600
 And the last example I'll give-- I believe so far every robot we've seen has been bolted

28
00:01:50,600 --> 00:01:51,600
 to a table.

29
00:01:51,600 --> 00:01:54,320
 I don't think we've seen a robot move.

30
00:01:54,320 --> 00:01:58,480
 But in the general sense, we have robots that move around.

31
00:01:58,480 --> 00:02:03,160
 And so you might imagine I have this robot that can move around and perceive the world.

32
00:02:03,160 --> 00:02:05,880
 And in this case, the goal of the robot is to escape the lab.

33
00:02:05,880 --> 00:02:08,120
 This is when we used to be on the fourth floor.

34
00:02:08,120 --> 00:02:12,720
 And so it's doing this kind of complex series of manipulations that it's planning.

35
00:02:12,720 --> 00:02:13,720
 How do I escape the lab?

36
00:02:13,720 --> 00:02:14,720
 Oh, there's chairs in the way.

37
00:02:14,720 --> 00:02:18,960
 Oh, I need to pick up and move the chairs out of the way.

38
00:02:18,960 --> 00:02:23,360
 I feel like often professors are showing off their students' videos.

39
00:02:23,360 --> 00:02:24,760
 And I have the joy of I am a student.

40
00:02:24,760 --> 00:02:26,360
 And this is showing off the professor's video.

41
00:02:26,360 --> 00:02:28,320
 This is by Leslie and Tomas.

42
00:02:28,320 --> 00:02:31,600
 They're actually coding in the background.

43
00:02:31,600 --> 00:02:35,440
 And at one point, you can see students come in and watch their advisors do work, which

44
00:02:35,440 --> 00:02:36,440
 is fun.

45
00:02:36,440 --> 00:02:39,160
 So I want my robot to do these kinds of things.

46
00:02:39,160 --> 00:02:40,160
 I want my robot to cook.

47
00:02:40,160 --> 00:02:41,160
 I want it to open bottles.

48
00:02:41,160 --> 00:02:43,640
 I want it to escape the lab.

49
00:02:43,640 --> 00:02:47,920
 And you might imagine we've talked about composing high-level behavior before.

50
00:02:47,920 --> 00:02:52,640
 If we go way back to lecture 10, we talked about you could script things.

51
00:02:52,640 --> 00:02:57,660
 You could do behavior trees, decision trees, finite state machines.

52
00:02:57,660 --> 00:03:02,320
 But I think you all got a taste for how complex finite state machines can blow up.

53
00:03:02,320 --> 00:03:06,640
 And if we think about accomplishing any one of these tasks, like having to write out the

54
00:03:06,640 --> 00:03:14,780
 finite state machine for what these robots do, it gets kind of intractable pretty fast.

55
00:03:14,780 --> 00:03:15,780
 So we want to do better.

56
00:03:15,780 --> 00:03:19,920
 And that's kind of what motivates what we're talking about today, which is task and motion

57
00:03:19,920 --> 00:03:22,800
 planning, which pretty much everyone abbreviates to the word TAMP.

58
00:03:22,800 --> 00:03:26,300
 So you're just going to hear the word TAMP over and over again today.

59
00:03:26,300 --> 00:03:33,720
 And the highest order bit is that TAMP is a computational mechanism for composing pieces.

60
00:03:33,720 --> 00:03:35,640
 Most of what we're going to talk about is planning.

61
00:03:35,640 --> 00:03:39,160
 But towards the end, we'll show how you can kind of bring in all of the pieces and that

62
00:03:39,160 --> 00:03:42,760
 TAMP overall is a framework.

63
00:03:42,760 --> 00:03:47,040
 So we're going to start off with a couple of building blocks of what is background knowledge

64
00:03:47,040 --> 00:03:48,040
 necessary.

65
00:03:48,040 --> 00:03:49,600
 Oh, I told Danny I wouldn't use this part of the board.

66
00:03:49,600 --> 00:03:51,940
 I'm so sorry.

67
00:03:51,940 --> 00:03:54,280
 We're going to go over some building blocks.

68
00:03:54,280 --> 00:03:55,280
 Then we're going to formalize.

69
00:03:55,280 --> 00:04:00,720
 I'm going to actually kind of go on a mini rant about how I like to define TAMP, talk

70
00:04:00,720 --> 00:04:02,400
 about the algorithmic components.

71
00:04:02,400 --> 00:04:06,020
 And then once we've had that established, I think to make things a little bit more concrete,

72
00:04:06,020 --> 00:04:07,680
 we're going to go through a case study example.

73
00:04:07,680 --> 00:04:11,680
 We're going to return to that bottle and think about if I wanted to actually code things

74
00:04:11,680 --> 00:04:13,880
 up, how would I do it?

75
00:04:13,880 --> 00:04:17,720
 And then we're going to end by returning to this idea of TAMP as a computational framework

76
00:04:17,720 --> 00:04:20,960
 and show kind of a bunch of different examples of how you can put different pieces in.

77
00:04:20,960 --> 00:04:25,200
 This is also a fun way for me to end by just showing you lots of videos of robots doing

78
00:04:25,200 --> 00:04:27,160
 cool stuff.

79
00:04:27,160 --> 00:04:32,760
 Any questions about where we're going today?

80
00:04:32,760 --> 00:04:38,480
 I will front that a lot of what we're going to be talking about today has basis in the

81
00:04:38,480 --> 00:04:41,680
 survey paper that our lab wrote last year.

82
00:04:41,680 --> 00:04:48,080
 So if you want to look into things further or get deep insight into how this lecture

83
00:04:48,080 --> 00:04:51,920
 was structured, I would very highly encourage you to look at our survey paper, which is

84
00:04:51,920 --> 00:04:52,920
 only slightly self-promotional.

85
00:04:52,920 --> 00:04:57,120
 But it's good work.

86
00:04:57,120 --> 00:05:00,560
 So let's dive into the building blocks.

87
00:05:00,560 --> 00:05:04,920
 I would argue task and motion planning builds off of kind of three key areas in terms of

88
00:05:04,920 --> 00:05:06,880
 where it pulls from.

89
00:05:06,880 --> 00:05:10,280
 It is perhaps not surprising that task and motion planning pulls from motion planning

90
00:05:10,280 --> 00:05:11,960
 and task planning.

91
00:05:11,960 --> 00:05:14,920
 And we're actually going to go through those very quickly because you all are super experienced

92
00:05:14,920 --> 00:05:17,720
 in motion planning and you've seen task planning in lecture 10.

93
00:05:17,720 --> 00:05:21,440
 And we're going to spend a little bit more time on multimodal motion planning.

94
00:05:21,440 --> 00:05:25,920
 Because this is a review in some parts, we can go through it a little bit quicker.

95
00:05:25,920 --> 00:05:31,840
 I'm going to actually ask you all to do half the work in terms of answering things.

96
00:05:31,840 --> 00:05:35,240
 So to walk through all of these, I'm going to set up a concrete example.

97
00:05:35,240 --> 00:05:39,640
 And this is a very, very simple TAMP problem.

98
00:05:39,640 --> 00:05:42,040
 Let's say that we have our little yellow robot.

99
00:05:42,040 --> 00:05:46,480
 And the red disk is a pizza.

100
00:05:46,480 --> 00:05:47,760
 Bear with me.

101
00:05:47,760 --> 00:05:48,860
 It's on a green plate.

102
00:05:48,860 --> 00:05:50,720
 And we have an oven, which is an orange box.

103
00:05:50,720 --> 00:05:52,800
 You could think of it as a hot plate.

104
00:05:52,800 --> 00:05:56,840
 And our goal is that we want our robot to cook pizza.

105
00:05:56,840 --> 00:05:57,960
 That is the task.

106
00:05:57,960 --> 00:06:04,180
 And for right now, we'll say the robot cooks pizza if it moves the pizza onto the hot plate.

107
00:06:04,180 --> 00:06:08,680
 That is about as simple as we can get tasks.

108
00:06:08,680 --> 00:06:11,880
 Check out.

109
00:06:11,880 --> 00:06:15,760
 So let's work through each of our three kind of building blocks.

110
00:06:15,760 --> 00:06:16,960
 So you all know motion planning.

111
00:06:16,960 --> 00:06:17,960
 It's lectures 15 and 16.

112
00:06:17,960 --> 00:06:22,480
 And I'm going to say in the most vanilla form that motion planning is if we have a start

113
00:06:22,480 --> 00:06:27,200
 configuration and a set of goal configurations, even our most basic motion planners that give

114
00:06:27,200 --> 00:06:33,480
 you the RRT from homework 9, that you're going to find a path from your start to your goal

115
00:06:33,480 --> 00:06:35,380
 such that you're collision free.

116
00:06:35,380 --> 00:06:39,800
 I'm reintroducing a little bit of notation because it'll help us later.

117
00:06:39,800 --> 00:06:45,260
 And so if I give you this RRT, the question I will pose to you all is, have we already

118
00:06:45,260 --> 00:06:47,880
 solved the problem?

119
00:06:47,880 --> 00:06:53,040
 Can the robot cook pizza if all I give you is an RRT?

120
00:06:53,040 --> 00:06:55,520
 Some people are shaking their heads no.

121
00:06:55,520 --> 00:06:58,160
 Why not?

122
00:06:58,160 --> 00:06:59,160
 You can just shout out.

123
00:06:59,160 --> 00:07:00,160
 You do not have to raise your hand.

124
00:07:00,160 --> 00:07:01,160
 [INAUDIBLE]

125
00:07:01,160 --> 00:07:02,160
 Yeah.

126
00:07:02,160 --> 00:07:12,720
 So Yang is arguing that you have two different-- that the problem changes if you enact with

127
00:07:12,720 --> 00:07:13,720
 the state.

128
00:07:13,720 --> 00:07:16,440
 So it's an excellent point.

129
00:07:16,440 --> 00:07:21,680
 What you cannot do with motion planning in its most basic sense is that you cannot capture

130
00:07:21,680 --> 00:07:23,320
 changes in the world.

131
00:07:23,320 --> 00:07:29,420
 And so right to Yang's point, you cannot capture the fact that now you are grasping that plate.

132
00:07:29,420 --> 00:07:33,480
 So that is going to motivate that in order to capture that kind of structure in the world,

133
00:07:33,480 --> 00:07:37,240
 what we want to-- what we use is multimodal motion planning.

134
00:07:37,240 --> 00:07:41,040
 By the end of this, you will understand and deeply appreciate the beauty of this figure.

135
00:07:41,040 --> 00:07:43,720
 We will get there.

136
00:07:43,720 --> 00:07:47,760
 So what we want to do is that we need to introduce modal structure into the problem.

137
00:07:47,760 --> 00:07:50,420
 This is where multimodal motion planning gets its name.

138
00:07:50,420 --> 00:07:53,520
 What does modal structure mean?

139
00:07:53,520 --> 00:07:55,620
 So let's say we have our scene from before.

140
00:07:55,620 --> 00:07:59,880
 And we're going to describe this scene with something called a kinematic graph.

141
00:07:59,880 --> 00:08:02,720
 And so a kinematic graph is going to represent the state of our world.

142
00:08:02,720 --> 00:08:05,460
 It's going to encode the dependencies.

143
00:08:05,460 --> 00:08:11,120
 So the-- oh, I'm not tall enough.

144
00:08:11,120 --> 00:08:13,120
 Each of our nodes corresponds to an object.

145
00:08:13,120 --> 00:08:18,360
 So we have nodes for our world and then attached to our world is our table, attached on top

146
00:08:18,360 --> 00:08:21,440
 of our table is our plate, on top of our plate is our pizza.

147
00:08:21,440 --> 00:08:25,560
 And the edges represent some level of dependencies, whether it's being supported by or rigidly

148
00:08:25,560 --> 00:08:26,560
 attached.

149
00:08:26,560 --> 00:08:36,560
 And we're going to call what's represented by this that this is mode sigma, that what

150
00:08:36,560 --> 00:08:40,680
 the state of the world as represented by this kinematic graph is mode sigma.

151
00:08:40,680 --> 00:08:47,640
 And I would argue that within mode sigma, we can do motion planning, that we can control

152
00:08:47,640 --> 00:08:49,480
 the state of our robot joints.

153
00:08:49,480 --> 00:08:54,560
 Now if we were to do motion planning and kind of plan for a new configuration queue, would

154
00:08:54,560 --> 00:09:00,960
 our kinematic graph change?

155
00:09:00,960 --> 00:09:06,080
 If we just do motion planning and we move, basically change our configuration queue,

156
00:09:06,080 --> 00:09:07,080
 we move our robot.

157
00:09:07,080 --> 00:09:08,080
 Why?

158
00:09:08,080 --> 00:09:09,080
 Because I guess the relationship is all the objects want to interact with them, so the

159
00:09:09,080 --> 00:09:10,080
 objects [INAUDIBLE]

160
00:09:10,080 --> 00:09:11,080
 Yep.

161
00:09:11,080 --> 00:09:22,720
 There are no relationships between the objects changed.

162
00:09:22,720 --> 00:09:24,540
 That's exactly correct.

163
00:09:24,540 --> 00:09:28,440
 So let's say something happens in the world, something mysterious, we'll get back to what

164
00:09:28,440 --> 00:09:29,440
 it is.

165
00:09:29,440 --> 00:09:33,280
 Something happens in the world and now the robot is holding the plate.

166
00:09:33,280 --> 00:09:34,400
 Same question.

167
00:09:34,400 --> 00:09:38,600
 Does the kinematic graph change in this case?

168
00:09:38,600 --> 00:09:39,600
 Why?

169
00:09:39,600 --> 00:09:40,600
 Anyone?

170
00:09:40,600 --> 00:09:41,600
 [INAUDIBLE]

171
00:09:41,600 --> 00:09:42,600
 Right.

172
00:09:42,600 --> 00:09:49,600
 So our kinematic graph changes such that our pizza is still supported by our plate, but

173
00:09:49,600 --> 00:09:54,680
 our plate, instead of being supported by a table, is now supported by our robot hand.

174
00:09:54,680 --> 00:09:59,600
 Now Yang actually alluded to this earlier, is that we can do motion planning within this

175
00:09:59,600 --> 00:10:04,160
 new mode, this mode sigma prime, but it is a different motion planning problem.

176
00:10:04,160 --> 00:10:07,520
 In this case, it's a constrained motion planning problem where you maybe have the constraint

177
00:10:07,520 --> 00:10:11,160
 that I want to keep my-- you have an orientation constraint and you want to keep your plate

178
00:10:11,160 --> 00:10:14,120
 upright, which we know how to do.

179
00:10:14,120 --> 00:10:18,320
 But you can do motion planning in both, but they are perhaps two different motion planning

180
00:10:18,320 --> 00:10:20,440
 problems.

181
00:10:20,440 --> 00:10:24,360
 Now if we have mode sigma and we go to mode sigma prime, how do we go from one to the

182
00:10:24,360 --> 00:10:25,360
 other?

183
00:10:25,360 --> 00:10:28,280
 So transforming to one to the other is what's called a mode switch.

184
00:10:28,280 --> 00:10:32,160
 It's also called a kinematic switch, and that's the instantaneous change in our kinematic

185
00:10:32,160 --> 00:10:34,000
 graph.

186
00:10:34,000 --> 00:10:39,480
 In this case, what action is represented-- what happened during our mode switch in this

187
00:10:39,480 --> 00:10:40,480
 case?

188
00:10:40,480 --> 00:10:41,480
 [INAUDIBLE]

189
00:10:41,480 --> 00:10:42,480
 Yes.

190
00:10:42,480 --> 00:10:48,120
 None of these are trick questions.

191
00:10:48,120 --> 00:10:51,440
 So what our robot had to do in order to switch from not holding the plate to holding the

192
00:10:51,440 --> 00:10:53,320
 plate is it had to hold the plate.

193
00:10:53,320 --> 00:10:56,160
 It had to grasp the plate, and it switched modes.

194
00:10:56,160 --> 00:10:59,720
 And there's a neat point in that in order to be able to switch from one mode to the

195
00:10:59,720 --> 00:11:04,440
 other, it had to be in a particular configuration where it can grasp, because that is a configuration

196
00:11:04,440 --> 00:11:09,560
 where it can switch to being in that next mode.

197
00:11:09,560 --> 00:11:13,480
 So if we take away our kinematic graphs, we can now understand one of my favorite figures

198
00:11:13,480 --> 00:11:19,240
 of all time, which is that this is the heart of multimodal motion planning, is that you're

199
00:11:19,240 --> 00:11:25,200
 basically sequencing planning within modes, switching to a new mode at an intersection

200
00:11:25,200 --> 00:11:27,440
 point, and planning within different modes.

201
00:11:27,440 --> 00:11:33,520
 And so if we connect that back to our example, we can do single mode motion planning where

202
00:11:33,520 --> 00:11:36,000
 we do not change mode, but we change our configuration.

203
00:11:36,000 --> 00:11:40,880
 You can imagine that as moving along that green manifold from one configuration to another

204
00:11:40,880 --> 00:11:44,400
 until you plan for a point where you can switch.

205
00:11:44,400 --> 00:11:47,080
 You have to find a point that's at the intersection of your two manifolds.

206
00:11:47,080 --> 00:11:49,360
 That's your mode switch.

207
00:11:49,360 --> 00:11:53,920
 Instantaneously-- we're dealing with discrete time-- you're going to not change configuration,

208
00:11:53,920 --> 00:11:56,800
 but you're going to instantaneously change mode.

209
00:11:56,800 --> 00:12:01,360
 And then you can go along your happy way in your new mode doing more single mode motion

210
00:12:01,360 --> 00:12:02,360
 planning.

211
00:12:02,360 --> 00:12:07,160
 So to summarize, what the robot's doing here is it has to plan for a sequence of modes.

212
00:12:07,160 --> 00:12:13,320
 It has to plan for single mode motion, and it has to plan for mode switches.

213
00:12:13,320 --> 00:12:18,320
 So if we return to our question from before, but slightly modified, if I were to give you

214
00:12:18,320 --> 00:12:24,000
 kind of a start configuration and a start mode, a goal configuration, a goal mode, and

215
00:12:24,000 --> 00:12:30,240
 a multimodal motion planner that does what we just described, can you cook the pizza?

216
00:12:30,240 --> 00:12:31,840
 Can the robot now accomplish the task?

217
00:12:31,840 --> 00:12:39,440
 I'm going to give everyone like 15 or 20 seconds to really think this one through.

218
00:12:39,440 --> 00:12:40,440
 If it can, why?

219
00:12:40,440 --> 00:12:52,520
 If it can't, why not?

220
00:12:52,520 --> 00:12:53,520
 Any thoughts?

221
00:12:53,520 --> 00:12:54,520
 Yeah?

222
00:12:54,520 --> 00:13:15,440
 [INAUDIBLE] Can you explain what you mean?

223
00:13:15,440 --> 00:13:16,960
 [INAUDIBLE] So the assumption in normal-- sorry, I should

224
00:13:16,960 --> 00:13:20,960
 have mentioned this-- is that we know the set of possible mode transitions.

225
00:13:20,960 --> 00:13:24,320
 So we know how we can transition from one mode to another.

226
00:13:24,320 --> 00:13:25,320
 Yeah?

227
00:13:25,320 --> 00:13:31,160
 [INAUDIBLE] That is exactly correct.

228
00:13:31,160 --> 00:13:35,480
 So you can actually solve this problem with multimodal motion planning.

229
00:13:35,480 --> 00:13:36,480
 This is enough.

230
00:13:36,480 --> 00:13:37,480
 Our robot could go home.

231
00:13:37,480 --> 00:13:42,440
 But in its most basic form, multimodal motion planning is kind of going to do a brute force

232
00:13:42,440 --> 00:13:43,440
 search.

233
00:13:43,440 --> 00:13:46,720
 So it's going to be horribly inefficient.

234
00:13:46,720 --> 00:13:49,720
 Actually for this problem, this problem is so simple enough that it'll be able to solve

235
00:13:49,720 --> 00:13:50,720
 it.

236
00:13:50,720 --> 00:13:54,240
 But if we wanted the robot to be able to escape the lab, then it's going to become quite a

237
00:13:54,240 --> 00:13:55,240
 problem.

238
00:13:55,240 --> 00:13:56,240
 Yeah?

239
00:13:56,240 --> 00:14:10,280
 [INAUDIBLE] This is my favorite question.

240
00:14:10,280 --> 00:14:13,760
 So there are two multimodal motion planning papers.

241
00:14:13,760 --> 00:14:16,360
 And the second one deals exactly with what you're talking about.

242
00:14:16,360 --> 00:14:20,540
 And so what it does is rather than having a mode for each grasp, which as you mentioned

243
00:14:20,540 --> 00:14:24,120
 could be infinite, they formalize it as that you have a mode family.

244
00:14:24,120 --> 00:14:26,640
 And there's a parameter for that family.

245
00:14:26,640 --> 00:14:29,240
 So the family is defined as grasping that object.

246
00:14:29,240 --> 00:14:32,480
 And the parameter for that is what is your actual grasp.

247
00:14:32,480 --> 00:14:34,480
 [INAUDIBLE] Yeah.

248
00:14:34,480 --> 00:14:42,480
 It has the-- wait, what do you mean by changing?

249
00:14:42,480 --> 00:15:02,580
 [INAUDIBLE] You would have a different manifold for each

250
00:15:02,580 --> 00:15:05,580
 grasp.

251
00:15:05,580 --> 00:15:11,500
 In picking the mode switch, it is picking up what grasp to do.

252
00:15:11,500 --> 00:15:15,740
 And the description of it being a little bit off would be if you were trying to do online

253
00:15:15,740 --> 00:15:21,380
 re-planning in the loop.

254
00:15:21,380 --> 00:15:22,380
 Other questions?

255
00:15:22,380 --> 00:15:23,380
 Yeah?

256
00:15:23,380 --> 00:15:24,380
 [INAUDIBLE] Yeah.

257
00:15:24,380 --> 00:15:25,380
 Sorry.

258
00:15:25,380 --> 00:15:26,380
 [INAUDIBLE] Yeah.

259
00:15:26,380 --> 00:15:42,820
 Oh, dear.

260
00:15:42,820 --> 00:15:43,820
 My bad.

261
00:15:43,820 --> 00:15:50,460
 So the question is, could you deal with basically not sticking contact is, I think, a way to

262
00:15:50,460 --> 00:15:53,140
 summarize that.

263
00:15:53,140 --> 00:15:55,620
 Generally in multi-modal motion planning, the assumption is made is that you have sticking

264
00:15:55,620 --> 00:15:56,620
 contact.

265
00:15:56,620 --> 00:16:01,420
 But you can imagine because the representation is like you are doing a single-mode motion

266
00:16:01,420 --> 00:16:05,780
 planning that if your mode was I do not have sticking contact, you would need a more complex

267
00:16:05,780 --> 00:16:06,780
 planner to handle that.

268
00:16:06,780 --> 00:16:07,780
 But you could.

269
00:16:07,780 --> 00:16:08,780
 OK.

270
00:16:08,780 --> 00:16:18,380
 So multi-modal motion planning might not be efficient enough.

271
00:16:18,380 --> 00:16:22,980
 This is where what we're going to do to get around that is we're going to leverage the

272
00:16:22,980 --> 00:16:25,780
 representational power that comes from task planning.

273
00:16:25,780 --> 00:16:29,500
 And I'm going to go through this part a little bit faster because you all have seen this

274
00:16:29,500 --> 00:16:30,940
 to an extent.

275
00:16:30,940 --> 00:16:34,460
 So for the next few slides, we're going to be in discrete world.

276
00:16:34,460 --> 00:16:36,660
 So you might imagine we have a discrete set of states.

277
00:16:36,660 --> 00:16:40,580
 You have some transition function that says what is your legal changes between states.

278
00:16:40,580 --> 00:16:44,380
 You have some start states, some goal states.

279
00:16:44,380 --> 00:16:49,100
 And your goal is to find a path from start state to goal state following your transitions.

280
00:16:49,100 --> 00:16:53,220
 This is the normal setup in task planning.

281
00:16:53,220 --> 00:16:58,340
 And you can imagine this as a graph where your nodes are your states and your transition

282
00:16:58,340 --> 00:17:02,660
 function just defines your possible, in this case, directed edges.

283
00:17:02,660 --> 00:17:07,420
 And so you could just apply graph search if you want to solve this.

284
00:17:07,420 --> 00:17:11,620
 So we take this formalism and we're going to apply it to a version of our pizza problem.

285
00:17:11,620 --> 00:17:14,940
 But I'm going to switch to making everything discrete for a minute.

286
00:17:14,940 --> 00:17:18,100
 And apologies for the icons.

287
00:17:18,100 --> 00:17:20,300
 But let's imagine that we have some set of movable bodies.

288
00:17:20,300 --> 00:17:23,460
 We have our robot got cuter, our pizza got prettier.

289
00:17:23,460 --> 00:17:27,900
 And we have some discrete set of locations that we could be at.

290
00:17:27,900 --> 00:17:31,180
 If this is the state of our world, there's a question of how do we define state and how

291
00:17:31,180 --> 00:17:33,420
 do we define transitions.

292
00:17:33,420 --> 00:17:37,780
 And so for state, we're going to leverage an idea that is critical but seems so obvious

293
00:17:37,780 --> 00:17:40,060
 that it's sometimes difficult to understand how critical it is.

294
00:17:40,060 --> 00:17:44,940
 And this is the idea called factoring, which is that I'm going to represent the state of

295
00:17:44,940 --> 00:17:50,260
 the world by different state variables.

296
00:17:50,260 --> 00:17:53,980
 And then I'm going to compose that by taking the Cartesian product of it.

297
00:17:53,980 --> 00:17:59,220
 That is to say, I'm going to actually break down what the state is and say, my robot is

298
00:17:59,220 --> 00:18:01,460
 at, in this case, the plate.

299
00:18:01,460 --> 00:18:02,580
 My pizza is at the box.

300
00:18:02,580 --> 00:18:03,900
 My book is at the sofa.

301
00:18:03,900 --> 00:18:04,980
 My pizza is not cooked.

302
00:18:04,980 --> 00:18:07,020
 And my robot is not holding anything.

303
00:18:07,020 --> 00:18:12,460
 And there are like-- we did up math-- like 600 possible states that the state of the

304
00:18:12,460 --> 00:18:13,540
 world could be at.

305
00:18:13,540 --> 00:18:18,820
 And by factoring things down very nicely, you can represent that super sparsely.

306
00:18:18,820 --> 00:18:23,240
 It's very obvious but super critical to being efficient.

307
00:18:23,240 --> 00:18:25,480
 So we're going to represent our states in this way.

308
00:18:25,480 --> 00:18:27,500
 How are we going to represent our transitions?

309
00:18:27,500 --> 00:18:29,500
 This is something you all have actually seen before.

310
00:18:29,500 --> 00:18:34,580
 This was in lecture 10, if people recall, preconditions and effects.

311
00:18:34,580 --> 00:18:38,020
 Does that vaguely ring a bell?

312
00:18:38,020 --> 00:18:43,060
 So preconditions is what needs to be true about our states in order to take some action.

313
00:18:43,060 --> 00:18:47,260
 And our effect is, what are the changes in our state once we take that action?

314
00:18:47,260 --> 00:18:51,980
 And so if I want to pick up an object at some location, we're going to say that the robot

315
00:18:51,980 --> 00:18:52,980
 has to be at that location.

316
00:18:52,980 --> 00:18:54,860
 You have to not already be holding something.

317
00:18:54,860 --> 00:18:57,020
 The object has to be at that location.

318
00:18:57,020 --> 00:19:00,980
 And then the effect, once I've actually done the pick action, is that now the object is

319
00:19:00,980 --> 00:19:03,900
 not at that location and I am holding the object.

320
00:19:03,900 --> 00:19:09,340
 That is what it means to define our pick operator.

321
00:19:09,340 --> 00:19:17,660
 So you can imagine defining a series of operators-- move, move holding, pick, place, cook.

322
00:19:17,660 --> 00:19:22,080
 In this case, cook is just going to be a discrete action of being on the oven.

323
00:19:22,080 --> 00:19:28,140
 And so if our plan was that we wanted our pizza to be cooked and our pizza to be at

324
00:19:28,140 --> 00:19:32,020
 the plate, does someone want to pretend to be a task planner for a minute and give a

325
00:19:32,020 --> 00:19:36,020
 feasible plan?

326
00:19:36,020 --> 00:19:39,940
 Yeah?

327
00:19:39,940 --> 00:19:43,940
 Yes.

328
00:19:43,940 --> 00:19:54,940
 You are an excellent task planner.

329
00:19:54,940 --> 00:20:04,260
 So that is that we can now find a plan for our task planning.

330
00:20:04,260 --> 00:20:09,460
 So that covers all of the preliminaries, all of the building blocks of that we have motion

331
00:20:09,460 --> 00:20:11,780
 planning, multimodal motion planning, and task planning.

332
00:20:11,780 --> 00:20:20,020
 And with that, I can give the definition of TAMP that I prefer, which is that TAMP is

333
00:20:20,020 --> 00:20:27,580
 an extension of multimodal motion planning that leverages the representational efficiency

334
00:20:27,580 --> 00:20:32,140
 of task planning.

335
00:20:32,140 --> 00:20:37,020
 Multimodal motion planning is abbreviated as MMMP, or you can just add arbitrary M's

336
00:20:37,020 --> 00:20:44,940
 as you say it.

337
00:20:44,940 --> 00:20:49,740
 OK.

338
00:20:49,740 --> 00:21:01,340
 TAMP is an extension of multimodal motion planning that uses the compact representational

339
00:21:01,340 --> 00:21:05,640
 strategies from task planning.

340
00:21:05,640 --> 00:21:11,340
 So if we have our representations from task planning, and now we want to bring it into

341
00:21:11,340 --> 00:21:16,940
 MMMP, we want to bring it into our robot, the question is, what has to change?

342
00:21:16,940 --> 00:21:22,500
 I would argue there are two things that we now have to account for, and that is continuous

343
00:21:22,500 --> 00:21:35,220
 parameters and constraints on those continuous parameters.

344
00:21:35,220 --> 00:21:37,860
 What does that mean?

345
00:21:37,860 --> 00:21:41,820
 So we have our pick action from before that we spent some time understanding.

346
00:21:41,820 --> 00:21:45,780
 And now if instead of being in a discrete world, you want it to be a real robot, what

347
00:21:45,780 --> 00:21:48,260
 has to change?

348
00:21:48,260 --> 00:21:52,820
 So now instead of being I have an object, and it's at a discrete location, now we're

349
00:21:52,820 --> 00:21:55,420
 going to be dealing with continuous variables.

350
00:21:55,420 --> 00:21:59,100
 And so in this case, we're going to have that we have some object.

351
00:21:59,100 --> 00:22:03,700
 Our robot is at a configuration Q. Q is a continuous variable.

352
00:22:03,700 --> 00:22:08,820
 Our object, instead of being at some discrete location, now we can describe our object as

353
00:22:08,820 --> 00:22:09,820
 being at a pose.

354
00:22:09,820 --> 00:22:13,100
 Pick your favorite pose representation.

355
00:22:13,100 --> 00:22:15,100
 And that we have some grasp.

356
00:22:15,100 --> 00:22:20,420
 And so we have a mix of possibly discrete and continuous parameters.

357
00:22:20,420 --> 00:22:23,260
 So this makes it a hybrid problem.

358
00:22:23,260 --> 00:22:30,500
 Additionally, we have some of the same preconditions and effects that we had before.

359
00:22:30,500 --> 00:22:34,540
 In order to pick something up, we assume that our robot is not already holding something.

360
00:22:34,540 --> 00:22:40,060
 But now we have to have constraints on our continuous parameters.

361
00:22:40,060 --> 00:22:47,180
 For example, the grasp operator-- sorry, Danny, I'm going to go horribly off screen-- is that

362
00:22:47,180 --> 00:22:54,420
 it's a constraint that our grasp G is a valid grasp on our object obj.

363
00:22:54,420 --> 00:23:00,980
 And we have the constraint that our pose P must be a stable pose for our object obj.

364
00:23:00,980 --> 00:23:05,740
 And Ken is that we have some constraint that if our robot is at configuration Q and our

365
00:23:05,740 --> 00:23:13,860
 object is at pose P, that is a valid grasp G on our object.

366
00:23:13,860 --> 00:23:14,860
 Questions about this?

367
00:23:14,860 --> 00:23:20,220
 We've transformed into now dealing with hybrid spaces.

368
00:23:20,220 --> 00:23:22,220
 [INAUDIBLE]

369
00:23:22,220 --> 00:23:26,300
 Ken is just a grasp.

370
00:23:26,300 --> 00:23:29,260
 It's just is that a valid grasp on the object?

371
00:23:29,260 --> 00:23:33,520
 And Ken relates in the robot as well.

372
00:23:33,520 --> 00:23:38,340
 So Ken is-- notice that grasp is just is that a valid grasp on the object relative to the

373
00:23:38,340 --> 00:23:52,980
 object versus Ken is like is your robot in a position where it can now use that grasp.

374
00:23:52,980 --> 00:23:57,340
 So we went through a little bit of detail for PIC.

375
00:23:57,340 --> 00:24:01,540
 You could do all of this for the same actions we described before.

376
00:24:01,540 --> 00:24:03,420
 Now we have to deal with trajectories.

377
00:24:03,420 --> 00:24:05,820
 We have to deal with poses and configurations.

378
00:24:05,820 --> 00:24:10,100
 And there's continuous but also discrete because we have objects.

379
00:24:10,100 --> 00:24:14,580
 So we have this set of operators.

380
00:24:14,580 --> 00:24:17,940
 So now we have discrete and continuous operators.

381
00:24:17,940 --> 00:24:22,540
 If we were to return to our goal, like our goal is to cook the pizza, I would argue that

382
00:24:22,540 --> 00:24:30,020
 a valid solution-- if we run our planner from before, a valid solution would be to move,

383
00:24:30,020 --> 00:24:35,100
 pick up the pizza, move, holding it, place it, and cook it.

384
00:24:35,100 --> 00:24:40,860
 And the difference here is that now these are over-- we have continuous parameters to

385
00:24:40,860 --> 00:24:41,860
 deal with.

386
00:24:41,860 --> 00:24:49,580
 It's that you move given a certain trajectory.

387
00:24:49,580 --> 00:24:53,460
 There's a reason that I like putting the solution in front of you.

388
00:24:53,460 --> 00:24:58,580
 And that is because to me it outlines what are the two things that you need to solve

389
00:24:58,580 --> 00:24:59,580
 for.

390
00:24:59,580 --> 00:25:04,780
 So I would argue that if we are leveraging all of this in order to find a solution like

391
00:25:04,780 --> 00:25:15,060
 this, what we have to do is search over action sequences.

392
00:25:15,060 --> 00:25:20,180
 So searching over action sequences is what is the strategy that I'm using.

393
00:25:20,180 --> 00:25:24,060
 Here the one that we find is move, pick, move, place, cook.

394
00:25:24,060 --> 00:25:30,300
 And then the other thing that we have to do is solve for those continuous parameters.

395
00:25:30,300 --> 00:25:37,620
 If that is the strategy that I'm taking, what are valid configurations and poses and grasps?

396
00:25:37,620 --> 00:25:43,900
 And you have the constraint that the pose that-- the grasp that you pick at is going

397
00:25:43,900 --> 00:25:46,740
 to be the grasp that you're move, holding, and that you're picking with.

398
00:25:46,740 --> 00:25:50,460
 And so there's constraints between the different actions.

399
00:25:50,460 --> 00:25:53,860
 Does it make sense that the-- sorry.

400
00:25:53,860 --> 00:25:56,980
 HDSP is hybrid constraint satisfaction problem.

401
00:25:56,980 --> 00:25:59,300
 We are hybrid because we have discrete and continuous parameters.

402
00:25:59,300 --> 00:26:03,580
 We're basically trying to find what is a set of variables that satisfies our constraints.

403
00:26:03,580 --> 00:26:05,580
 So it's a constraint satisfaction problem.

404
00:26:05,580 --> 00:26:06,580
 Yeah?

405
00:26:06,580 --> 00:26:13,580
 Which hybrid parameters are considered during the search and which are considered during

406
00:26:13,580 --> 00:26:14,580
 the HDSP?

407
00:26:14,580 --> 00:26:15,580
 Can you repeat the question?

408
00:26:15,580 --> 00:26:16,580
 Yeah.

409
00:26:16,580 --> 00:26:18,660
 So it's which parameters are considered during the search and which are considered during

410
00:26:18,660 --> 00:26:19,980
 the HDSP.

411
00:26:19,980 --> 00:26:24,300
 The exact ones may vary depending on implementation.

412
00:26:24,300 --> 00:26:30,620
 But in general, if it is a-- the parameters of the actions are going to be what you have

413
00:26:30,620 --> 00:26:33,300
 to find satisfying values for in the HDSP.

414
00:26:33,300 --> 00:26:42,500
 And so in this case, it would be q0, all the trajectories, but also a, in this case, object

415
00:26:42,500 --> 00:26:43,500
 that's found over.

416
00:26:43,500 --> 00:26:44,500
 Yeah?

417
00:26:44,500 --> 00:26:51,500
 So to compare this with the most naive level of the MMMT, would you do something like randomly

418
00:26:51,500 --> 00:27:02,420
 sample-- because in MMMT, you still need the discrete symbols to specify the goal.

419
00:27:02,420 --> 00:27:03,420
 You still need that--

420
00:27:03,420 --> 00:27:04,420
 You do not have access to those discrete symbols in the same way.

421
00:27:04,420 --> 00:27:05,420
 So then how can you then set the path?

422
00:27:05,420 --> 00:27:09,940
 How can you say, cook the food?

423
00:27:09,940 --> 00:27:15,660
 So you can define the mode where being cooked is true, but you do not have this ability

424
00:27:15,660 --> 00:27:23,780
 to describe this discrete notion of an object being cooked.

425
00:27:23,780 --> 00:27:25,580
 You do not have access to that representation.

426
00:27:25,580 --> 00:27:27,580
 That is what some of the representational power that we get.

427
00:27:27,580 --> 00:27:28,580
 So does that mean you just-- like in MMMT, if you wanted to do the figure, you would

428
00:27:28,580 --> 00:27:39,500
 have to specify the exact goal as well, if you're going to do the optional?

429
00:27:39,500 --> 00:27:43,100
 You would-- let's see.

430
00:27:43,100 --> 00:27:47,100
 You could specify the mode in a set of valid configurations.

431
00:27:47,100 --> 00:27:48,100
 You might not have to give the specific configuration.

432
00:27:48,100 --> 00:27:49,100
 I see.

433
00:27:49,100 --> 00:27:50,100
 So in MMMT, basically, you're trying to chain together these subsets of configurations.

434
00:27:50,100 --> 00:27:51,100
 So the idea is you-- so you have a bunch of subsets.

435
00:27:51,100 --> 00:27:52,100
 And I guess the thing that the PAMP is doing is replacing-- I guess it's kind of hard to

436
00:27:52,100 --> 00:28:12,900
 decide what order you would give the subset.

437
00:28:12,900 --> 00:28:16,300
 Which is why MMMT often ends up doing a brute force search.

438
00:28:16,300 --> 00:28:17,300
 OK.

439
00:28:17,300 --> 00:28:21,140
 So they just randomly sample the order of the subset.

440
00:28:21,140 --> 00:28:22,140
 Well, yeah.

441
00:28:22,140 --> 00:28:26,300
 We'll get back to what TAMP does instead in like two minutes.

442
00:28:26,300 --> 00:28:27,300
 OK.

443
00:28:27,300 --> 00:28:28,300
 Good question.

444
00:28:28,300 --> 00:28:33,820
 Which I'm probably not repeating.

445
00:28:33,820 --> 00:28:39,420
 So this is the mini rant that I promised.

446
00:28:39,420 --> 00:28:44,780
 My preferred way to think about what is task in motion planning is that your goal is that

447
00:28:44,780 --> 00:28:47,300
 you want to search over a set of action sequences.

448
00:28:47,300 --> 00:28:52,220
 And then you want to solve for those resulting parameters.

449
00:28:52,220 --> 00:28:54,500
 You have these two components.

450
00:28:54,500 --> 00:28:58,740
 And the reason that I prefer that is that, to me, it gets at the heart of what you actually

451
00:28:58,740 --> 00:29:04,340
 need to do and gives a point towards what algorithmically are going to be the components.

452
00:29:04,340 --> 00:29:08,300
 A lot of times people-- I understand why people do this.

453
00:29:08,300 --> 00:29:14,980
 They explain task in motion planning as there's some high level, symbolic, discrete task planning.

454
00:29:14,980 --> 00:29:18,740
 And then there's some low level, continuous motion planning.

455
00:29:18,740 --> 00:29:20,780
 And you just put them together.

456
00:29:20,780 --> 00:29:24,580
 And the more I work on TAMP, the more that deeply frustrates me.

457
00:29:24,580 --> 00:29:27,340
 And the problem is that it's not entirely wrong.

458
00:29:27,340 --> 00:29:32,060
 But the reason why I find it frustrating is that I don't think it's a helpful framing.

459
00:29:32,060 --> 00:29:34,100
 Because it leads you to be like, what is a task?

460
00:29:34,100 --> 00:29:36,100
 And what is high level versus low level?

461
00:29:36,100 --> 00:29:38,780
 And what do you mean by symbolic?

462
00:29:38,780 --> 00:29:43,300
 Jokingly, Leslie banned us from using the word symbolic when we were writing the TAMP

463
00:29:43,300 --> 00:29:44,300
 survey.

464
00:29:44,300 --> 00:29:48,460
 And I was like, what does it mean anyway?

465
00:29:48,460 --> 00:29:51,980
 And I think a lot of misconceptions people often have come from people thinking of it

466
00:29:51,980 --> 00:29:57,740
 as these two separate things, when actually what you need to do is you're finding a strategy,

467
00:29:57,740 --> 00:29:58,740
 a sequence of actions.

468
00:29:58,740 --> 00:30:01,060
 And then you're finding the parameters for those actions.

469
00:30:01,060 --> 00:30:05,300
 And you can't decompose high level and low level, because your continuous parameters

470
00:30:05,300 --> 00:30:07,140
 have an impact on what strategy you're doing.

471
00:30:07,140 --> 00:30:10,700
 And they're deeply intertwined.

472
00:30:10,700 --> 00:30:16,540
 So that is my-- you cannot think of these as two separate things.

473
00:30:16,540 --> 00:30:20,780
 And although we pull from motion planning and task planning, TAMP is not simply gluing

474
00:30:20,780 --> 00:30:21,780
 those two together.

475
00:30:21,780 --> 00:30:25,180
 There's a lot more deeper going on.

476
00:30:25,180 --> 00:30:30,940
 OK, thank you for listening to my rant.

477
00:30:30,940 --> 00:30:35,820
 So the two components that we've outlined is that you have to search over action sequences

478
00:30:35,820 --> 00:30:42,340
 and that you have to solve the constraint satisfaction problem.

479
00:30:42,340 --> 00:30:47,980
 Searching over action sequences, as we mentioned before, you can think of this as graph search.

480
00:30:47,980 --> 00:30:53,260
 And in the very simplest form, you could actually frame searching over the set of possible action

481
00:30:53,260 --> 00:30:56,060
 sequences as just A* search.

482
00:30:56,060 --> 00:31:01,140
 Luckily, the AI planning community, this is their bread and butter.

483
00:31:01,140 --> 00:31:04,740
 And they've developed really awesome planners that take advantage of domain independent

484
00:31:04,740 --> 00:31:05,740
 heuristics.

485
00:31:05,740 --> 00:31:09,780
 So something called fast forward or fast downward that are really great at doing this search.

486
00:31:09,780 --> 00:31:14,500
 So Richard, this goes back to your point of we can now leverage all of the awesome planners

487
00:31:14,500 --> 00:31:15,500
 from the AI planning community.

488
00:31:15,500 --> 00:31:18,860
 Fortunately, they're not open source, but that's a whole other thing.

489
00:31:18,860 --> 00:31:22,060
 So that's how we're going to deal with searching over action sequences.

490
00:31:22,060 --> 00:31:27,060
 For searching over hybrid-- for solving constraint satisfaction problems, it's actually a similar

491
00:31:27,060 --> 00:31:31,260
 story to the one we told in motion planning, which is that some people do it with sampling

492
00:31:31,260 --> 00:31:33,820
 base and some people do it with optimization.

493
00:31:33,820 --> 00:31:36,020
 And there are pros and cons between them.

494
00:31:36,020 --> 00:31:40,740
 But I don't think we're-- we can talk about that if we have extra time.

495
00:31:40,740 --> 00:31:46,500
 But the idea is that there are different ways that you can solve for constraining these

496
00:31:46,500 --> 00:31:47,500
 values.

497
00:31:47,500 --> 00:31:49,500
 OK, questions?

498
00:31:49,500 --> 00:31:53,300
 OK, these are our two components.

499
00:31:53,300 --> 00:31:58,700
 What we actually did, if I go back to our survey paper, is that you can actually group

500
00:31:58,700 --> 00:32:06,560
 most of the state of the art TAMP methodologies by how they order these components.

501
00:32:06,560 --> 00:32:13,500
 And so there's some category that primarily they first focus on.

502
00:32:13,500 --> 00:32:22,140
 I want to generate possible values that could be satisfying values for my constraint satisfaction.

503
00:32:22,140 --> 00:32:25,820
 And then I'm going to use those values to try to find possible action sequences.

504
00:32:25,820 --> 00:32:29,940
 And if I can't do that, I'm going to repeat.

505
00:32:29,940 --> 00:32:33,340
 That's like I'm going to try to satisfy my constraints and then sequence them into a

506
00:32:33,340 --> 00:32:35,340
 valid plan.

507
00:32:35,340 --> 00:32:41,500
 FF Robb, which is work done by my lab mate, is a good example of this.

508
00:32:41,500 --> 00:32:45,700
 On the other end of the spectrum, you can imagine, first I'm going to try to find my

509
00:32:45,700 --> 00:32:46,700
 action sequences.

510
00:32:46,700 --> 00:32:50,620
 And then once I have my action sequences, I'm going to try to find satisfying values

511
00:32:50,620 --> 00:32:51,620
 to those constraints.

512
00:32:51,620 --> 00:32:56,660
 And a great example of a work that does basically this, but using optimization, is Mark Toussaint's

513
00:32:56,660 --> 00:32:58,700
 Planner that he published a couple years back.

514
00:32:58,700 --> 00:33:01,500
 Those are two ends of the spectrum.

515
00:33:01,500 --> 00:33:06,540
 It will perhaps not surprise you that the majority of work is people who do interleaved,

516
00:33:06,540 --> 00:33:11,780
 that you more tightly couple searching over action sequences and solving for your hybrid

517
00:33:11,780 --> 00:33:14,460
 constraint satisfaction problems.

518
00:33:14,460 --> 00:33:19,540
 So we're going to look at one example to go into a little bit more detail of how this

519
00:33:19,540 --> 00:33:22,620
 actually ends up working out.

520
00:33:22,620 --> 00:33:27,420
 And specifically, again, this is work done by my lab mate, which is this planner called

521
00:33:27,420 --> 00:33:28,420
 Pitital Stream.

522
00:33:28,420 --> 00:33:34,140
 We're going to understand it graphically at a somewhat high level.

523
00:33:34,140 --> 00:33:39,660
 So what Pitital Stream does-- and again, this is a planner for solving TAMP problems-- is

524
00:33:39,660 --> 00:33:43,220
 that it's going to take in a domain, and you have a series of what's called streams.

525
00:33:43,220 --> 00:33:45,220
 This is why it's called Pitital Stream.

526
00:33:45,220 --> 00:33:48,940
 And those streams basically work to sample possible values.

527
00:33:48,940 --> 00:33:54,460
 So this is handling the solving the CSP.

528
00:33:54,460 --> 00:33:55,780
 We are sampling possible values.

529
00:33:55,780 --> 00:33:58,420
 So that might mean I am sampling possible graphs.

530
00:33:58,420 --> 00:34:04,780
 I am sampling possible poses, possible trajectories, possible wrenches, all my possible values.

531
00:34:04,780 --> 00:34:10,700
 Once I have that set of variables that I've sampled, I'm going to take my operators, start

532
00:34:10,700 --> 00:34:17,020
 state and a goal state, and I'm going to search over my action sequences.

533
00:34:17,020 --> 00:34:21,100
 In this case, we're going to use something from the AI planning community.

534
00:34:21,100 --> 00:34:23,500
 In this specific case, fast downward.

535
00:34:23,500 --> 00:34:28,660
 And it's going to search over possible action sequences using those sampled values from

536
00:34:28,660 --> 00:34:30,980
 our streams.

537
00:34:30,980 --> 00:34:34,580
 If it can't find something, it's going to use that information to kind of sample for

538
00:34:34,580 --> 00:34:35,660
 more values.

539
00:34:35,660 --> 00:34:41,940
 It's going to keep doing that until we find a possible plan.

540
00:34:41,940 --> 00:34:47,940
 Now one way to think about this is that if we think back to lecture 16, we talked about

541
00:34:47,940 --> 00:34:48,940
 PRMs.

542
00:34:48,940 --> 00:34:51,660
 People remember PRMs?

543
00:34:51,660 --> 00:34:54,480
 So PRMs sample configurations.

544
00:34:54,480 --> 00:34:59,980
 Then they build that graph and configuration space, and you search over for a plan.

545
00:34:59,980 --> 00:35:03,580
 Pitital Stream is the PRM of TAMP.

546
00:35:03,580 --> 00:35:08,380
 And that you can think of it in that it is sampling values, again, which may be discrete

547
00:35:08,380 --> 00:35:09,380
 and may be continuous.

548
00:35:09,380 --> 00:35:15,500
 It's going to use that to build a pitital search problem, which is then searched through

549
00:35:15,500 --> 00:35:18,420
 using an AI planner.

550
00:35:18,420 --> 00:35:22,020
 Sample values, search, repeat.

551
00:35:22,020 --> 00:35:25,220
 Set check out.

552
00:35:25,220 --> 00:35:26,220
 OK.

553
00:35:26,220 --> 00:35:32,140
 I'm going to skip over one part.

554
00:35:32,140 --> 00:35:33,260
 Not everything is perfect.

555
00:35:33,260 --> 00:35:35,100
 There are computational issues.

556
00:35:35,100 --> 00:35:42,220
 If we have time, we will come back to this at the very end.

557
00:35:42,220 --> 00:35:47,660
 Does the algorithmic components and then Pitital Stream as a specific example make sense to

558
00:35:47,660 --> 00:35:48,660
 people?

559
00:35:48,660 --> 00:35:49,660
 Are there questions so far?

560
00:35:49,660 --> 00:35:50,660
 Yeah.

561
00:35:50,660 --> 00:35:51,660
 Isn't the guidance for sampling required?

562
00:35:51,660 --> 00:35:57,260
 That was the part I was going to skip.

563
00:35:57,260 --> 00:36:02,580
 So the question for guidance for sampling in the shortest form, which you should go

564
00:36:02,580 --> 00:36:07,820
 read the paper if you want to know more, or you should already know, is that it's basically

565
00:36:07,820 --> 00:36:09,900
 going to use lazy instantiations.

566
00:36:09,900 --> 00:36:17,100
 And so it's going to delay sampling for as long as possible and use the information from

567
00:36:17,100 --> 00:36:20,900
 the search in order to be more specific about how it picks those samples.

568
00:36:20,900 --> 00:36:21,900
 Yes.

569
00:36:21,900 --> 00:36:44,380
 This is maybe going back a little bit, but the definition you wrote up there of sampling

570
00:36:44,380 --> 00:36:45,380
 and extension of MMMT, representational power of pathfinding, it seems like we not only

571
00:36:45,380 --> 00:36:46,380
 get representational power from pathfinding, but also computational efficiency.

572
00:36:46,380 --> 00:36:47,380
 Is that accurate?

573
00:36:47,380 --> 00:36:48,380
 Yes.

574
00:36:48,380 --> 00:36:49,380
 I would say that the representational power is what enables you to leverage that computational

575
00:36:49,380 --> 00:36:50,380
 efficiency.

576
00:36:50,380 --> 00:36:51,380
 But yeah, that's it.

577
00:36:51,380 --> 00:36:52,380
 But yeah, that's correct.

578
00:36:52,380 --> 00:36:53,380
 OK.

579
00:36:53,380 --> 00:37:04,700
 So what I want to do, we're kind of moving into the third segment, is that to make this

580
00:37:04,700 --> 00:37:09,620
 all a little bit concrete and kind of give you all a sense for like, if you had a problem

581
00:37:09,620 --> 00:37:14,340
 and you wanted to apply task and motion planning to it, what would that concretely look like?

582
00:37:14,340 --> 00:37:20,380
 And kind of give you a flavor of what it is like to use those systems.

583
00:37:20,380 --> 00:37:28,340
 So we're going to return-- and this is my bias, due to my work-- we're going to return

584
00:37:28,340 --> 00:37:33,180
 to an example that we presented earlier when we were dealing with the case study.

585
00:37:33,180 --> 00:37:37,020
 If you all remember, this is when we were talking about impedance control and hybrid

586
00:37:37,020 --> 00:37:38,020
 position control.

587
00:37:38,020 --> 00:37:39,460
 I introduced this problem.

588
00:37:39,460 --> 00:37:42,020
 I'll reintroduce it here.

589
00:37:42,020 --> 00:37:47,140
 But you might imagine that I want my robot to get me medicine when I am sick and old,

590
00:37:47,140 --> 00:37:48,700
 or either.

591
00:37:48,700 --> 00:37:53,500
 And so I want my robot to be able to open childproof bottles.

592
00:37:53,500 --> 00:37:58,220
 I'll argue that specifically for a push-twist childproof bottle, what the robot needs to

593
00:37:58,220 --> 00:38:04,100
 do in order to open it is that it has to both push down on the cap while twisting.

594
00:38:04,100 --> 00:38:08,540
 And that if we are exerting this kind of wrench onto our object, we also have to fixture in

595
00:38:08,540 --> 00:38:09,540
 place.

596
00:38:09,540 --> 00:38:11,620
 We have to hold it still.

597
00:38:11,620 --> 00:38:16,940
 My goal is I want my robot to be able to push-twist the lid and then be able to pull it off so

598
00:38:16,940 --> 00:38:20,500
 that it can then, I don't know, give me my vitamins.

599
00:38:20,500 --> 00:38:23,380
 Does the context for this problem make sense?

600
00:38:23,380 --> 00:38:31,380
 We're going to spend the next, I don't know, 15 minutes with it.

601
00:38:31,380 --> 00:38:38,040
 So in thinking through, if I think first about that push-twist operation, there are a lot

602
00:38:38,040 --> 00:38:42,860
 of different ways that we could get our robot to do that.

603
00:38:42,860 --> 00:38:48,020
 And so the way we brainstormed up is that we wrote out four different ways you can imagine

604
00:38:48,020 --> 00:38:52,340
 using the robot's hand or fingers in order to actually exert that push-twist.

605
00:38:52,340 --> 00:38:57,860
 I think we only talked about one of them in the context of the control before.

606
00:38:57,860 --> 00:39:00,540
 The exact details of them are not terribly important at the moment, but you can imagine

607
00:39:00,540 --> 00:39:05,940
 using your grasping it and twisting it, or using your fingers, or using what we call

608
00:39:05,940 --> 00:39:08,020
 the palm of the robot, or grasping it.

609
00:39:08,020 --> 00:39:09,020
 It could pick up and use a tool.

610
00:39:09,020 --> 00:39:14,140
 So these are a couple of different ways that the robot could do that.

611
00:39:14,140 --> 00:39:19,100
 If we think about the fixturing side of things, the robot has to hold the bottle still.

612
00:39:19,100 --> 00:39:22,180
 There are a couple of different ways that it could do that.

613
00:39:22,180 --> 00:39:25,180
 You could get another robot to actually hold the bottle still.

614
00:39:25,180 --> 00:39:32,140
 You could put the-- if you have a vice in your kitchen, which maybe you do, the robot

615
00:39:32,140 --> 00:39:38,580
 could put the bottle in a vice, or it could use frictional contact in order to hold the

616
00:39:38,580 --> 00:39:41,500
 bottle still.

617
00:39:41,500 --> 00:39:47,300
 So these are the different components of the different ways that I want to get my robot

618
00:39:47,300 --> 00:39:50,500
 to do things.

619
00:39:50,500 --> 00:39:59,460
 From this, we can think of is, what is the set of operators concretely for our task?

620
00:39:59,460 --> 00:40:03,180
 Before in our pizza example, we had pick, place, and move.

621
00:40:03,180 --> 00:40:07,940
 And we do have those same examples, because moving, picking, and placing is almost always

622
00:40:07,940 --> 00:40:08,940
 helpful.

623
00:40:08,940 --> 00:40:12,660
 We almost always need our robots to move, and pick, and place things.

624
00:40:12,660 --> 00:40:17,740
 But then we're going to define a series of operators that are those push-twist actions.

625
00:40:17,740 --> 00:40:22,980
 And for our fixturing methods, you don't actually have to-- some of this is just picking and

626
00:40:22,980 --> 00:40:24,860
 placing, so you don't have to find new operators.

627
00:40:24,860 --> 00:40:28,700
 All you have to do is define opening and closing the vice.

628
00:40:28,700 --> 00:40:31,700
 And then we're going to define a special operator, which is removing the cap.

629
00:40:31,700 --> 00:40:32,700
 Yeah?

630
00:40:32,700 --> 00:40:39,700
 So for these operators, you just define them ahead of time, and then you learn individual

631
00:40:39,700 --> 00:40:44,380
 skills, like with whatever type of controller you want ahead of time?

632
00:40:44,380 --> 00:40:45,900
 So we will define them.

633
00:40:45,900 --> 00:40:50,140
 In this case, we are also going to write the controller.

634
00:40:50,140 --> 00:40:55,540
 But later on, I'll show you a method that actually does learn the controllers.

635
00:40:55,540 --> 00:40:57,020
 Can you repeat the question?

636
00:40:57,020 --> 00:40:58,020
 Yes.

637
00:40:58,020 --> 00:40:59,020
 Sorry.

638
00:40:59,020 --> 00:41:00,780
 The question was, do you write down these controllers and then learn them?

639
00:41:00,780 --> 00:41:04,340
 And the answer is, you do write down the operators.

640
00:41:04,340 --> 00:41:07,540
 Whether you learn the controllers or you write them down is kind of a design choice.

641
00:41:07,540 --> 00:41:13,100
 But I promise we will get back to it.

642
00:41:13,100 --> 00:41:20,100
 So yeah, what you concretely do in this case is that-- what I did as the programmer is

643
00:41:20,100 --> 00:41:25,580
 I wrote down this set of operators and the samplers that go with it.

644
00:41:25,580 --> 00:41:29,100
 And so to make that a little bit more concrete, I'm going to look at, what does it mean to

645
00:41:29,100 --> 00:41:31,860
 actually write one of these operators?

646
00:41:31,860 --> 00:41:34,980
 If you had to think through for your problem, what does it mean to write an operator?

647
00:41:34,980 --> 00:41:42,900
 Because we've only worked through pick, and pick is one of the simpler ones.

648
00:41:42,900 --> 00:41:48,220
 So let's say that this action that we want to do is that the robot grasps the cap, and

649
00:41:48,220 --> 00:41:52,220
 it does this push twist.

650
00:41:52,220 --> 00:41:58,300
 And if we recall, what we talked about in the previous case study is that the controller

651
00:41:58,300 --> 00:42:01,380
 that's actually running to do that push twist is the impedance controller.

652
00:42:01,380 --> 00:42:04,500
 So we actually know how to write down that impedance controller, and we're not going

653
00:42:04,500 --> 00:42:05,860
 to do any learning in this case.

654
00:42:05,860 --> 00:42:10,420
 We're going to use the impedance controller we already wrote down.

655
00:42:10,420 --> 00:42:17,140
 So if I'm sitting in my computer, and I want to define the operator, I'm going to define

656
00:42:17,140 --> 00:42:20,020
 it over what are the parameters to this action.

657
00:42:20,020 --> 00:42:22,820
 In this case, I'm sorry, there are a lot of parameters.

658
00:42:22,820 --> 00:42:25,020
 We'll kind of walk through each one.

659
00:42:25,020 --> 00:42:28,480
 But we have the parameters.

660
00:42:28,480 --> 00:42:30,480
 Some of these are continuous, and some of these are discrete.

661
00:42:30,480 --> 00:42:33,300
 A in this case stands for arm, because I have two robots.

662
00:42:33,300 --> 00:42:37,740
 And so one of the discrete things that the planner has to reason over is which robot

663
00:42:37,740 --> 00:42:39,700
 arm do I use?

664
00:42:39,700 --> 00:42:46,300
 And it has two objects, and it has poses for those objects, P0, P1, a relative pose between

665
00:42:46,300 --> 00:42:51,260
 them, a grasp that it needs to choose, a wrench that it needs to decide to exert, and then

666
00:42:51,260 --> 00:42:54,380
 it needs to decide what is the actual trajectory.

667
00:42:54,380 --> 00:42:58,460
 These are the parameters of our action.

668
00:42:58,460 --> 00:42:59,660
 What are the preconditions?

669
00:42:59,660 --> 00:43:02,260
 What needs to be true?

670
00:43:02,260 --> 00:43:07,180
 I also say that before I showed that a thing that needs to happen is that you need to define

671
00:43:07,180 --> 00:43:09,460
 constraints.

672
00:43:09,460 --> 00:43:13,220
 We're going to actually represent those constraints on the continuous parameters by shoving them

673
00:43:13,220 --> 00:43:14,220
 inside our precondition.

674
00:43:14,220 --> 00:43:18,620
 And so we're only going to have preconditions of effects and not a separate kind of constraints.

675
00:43:18,620 --> 00:43:21,300
 Does that make sense?

676
00:43:21,300 --> 00:43:22,580
 So what are our preconditions?

677
00:43:22,580 --> 00:43:23,580
 I'm a programmer.

678
00:43:23,580 --> 00:43:24,580
 I'm going to write it down.

679
00:43:24,580 --> 00:43:29,420
 What I'm going to define is that our object that we're operating on has to be of type

680
00:43:29,420 --> 00:43:31,620
 cap, and the other one has to be of type bottle.

681
00:43:31,620 --> 00:43:35,180
 This is because in this particular framework, I have specific things that are true about

682
00:43:35,180 --> 00:43:40,060
 that object type, and so I want to give that object a particular type.

683
00:43:40,060 --> 00:43:44,900
 I'll then specify a constraint that I want to have on my continuous parameters is that

684
00:43:44,900 --> 00:43:50,020
 I want P0 to be the pose of the cap and P1 to be the pose of the bottle, and I have some

685
00:43:50,020 --> 00:43:53,420
 relative pose defined between them.

686
00:43:53,420 --> 00:43:58,700
 So these so far are kind of obvious constraints.

687
00:43:58,700 --> 00:44:03,540
 I want my robot to be at a certain starting configuration, Q0, and before I do all this,

688
00:44:03,540 --> 00:44:09,420
 I want the hand of my robot arm to be empty because it needs to be able to do this operation.

689
00:44:09,420 --> 00:44:10,420
 People following so far?

690
00:44:10,420 --> 00:44:16,300
 I know we're getting a little bit into the weeds.

691
00:44:16,300 --> 00:44:21,100
 The next two things-- first one is that I want my graph to be stable.

692
00:44:21,100 --> 00:44:26,900
 Now, I didn't do a mini lecture on mechanics, so in this case, we'll just say that this

693
00:44:26,900 --> 00:44:28,900
 grasp is stable with respect to some wrench.

694
00:44:28,900 --> 00:44:34,380
 Honestly, if you want to know more details about grasp stability and mechanics, come

695
00:44:34,380 --> 00:44:35,380
 talk to me after.

696
00:44:35,380 --> 00:44:36,380
 I love to talk about it.

697
00:44:36,380 --> 00:44:41,620
 In this case, we want a grasp such that our grasp is stable, and we want to make sure

698
00:44:41,620 --> 00:44:43,380
 that our bottle is stabilized.

699
00:44:43,380 --> 00:44:45,820
 And so that is that one of those things from before is true.

700
00:44:45,820 --> 00:44:49,420
 Either another robot is holding our bottle, or our bottle is in our vice, or we have enough

701
00:44:49,420 --> 00:44:52,460
 frictional contact in order to stabilize that bottle, and this is with respect to a given

702
00:44:52,460 --> 00:44:53,460
 wrench.

703
00:44:53,460 --> 00:45:02,980
 Wrench is a force and a torque.

704
00:45:02,980 --> 00:45:09,140
 Then comes the biggest and most powerful sampler, which is that we now want to define a relation

705
00:45:09,140 --> 00:45:13,340
 over all of our objects, and this is the sampler that's actually going to generate the trajectory.

706
00:45:13,340 --> 00:45:18,020
 And if we remember that this is the trajectory that it's generating, it's generating that

707
00:45:18,020 --> 00:45:21,220
 impedance controls parameters.

708
00:45:21,220 --> 00:45:33,780
 Does that stop me if that doesn't make sense?

709
00:45:33,780 --> 00:45:38,420
 So what this is generating is it's going to take in the object that is the cap and the

710
00:45:38,420 --> 00:45:45,140
 bottle in those poses, and it's going to say, what is the motion that the robot has to achieve

711
00:45:45,140 --> 00:45:51,020
 in order to, in this case, do this twisting motion?

712
00:45:51,020 --> 00:45:55,300
 So when we talked about the control parameters before, because of the impedance control,

713
00:45:55,300 --> 00:46:01,460
 it's generating a series of set points and a series of stiffnesses for what are our impedances.

714
00:46:01,460 --> 00:46:04,580
 And so what you can think of is that this is a sampler that basically takes in information

715
00:46:04,580 --> 00:46:08,500
 about our current state and outputs what our robot should do, in this case, Cartesian set

716
00:46:08,500 --> 00:46:15,980
 points and impedances.

717
00:46:15,980 --> 00:46:16,980
 Yeah?

718
00:46:16,980 --> 00:46:25,740
 So where do you encode the fact that how much of rotation it needs to have a [INAUDIBLE]

719
00:46:25,740 --> 00:46:29,100
 So the question is, where do I actually encode what it means to do this motion?

720
00:46:29,100 --> 00:46:32,180
 In this case, it's how much do I twist.

721
00:46:32,180 --> 00:46:37,900
 In this case, that is a predefined thing within the sampler, but you could also imagine that

722
00:46:37,900 --> 00:46:39,860
 being a parameter.

723
00:46:39,860 --> 00:46:43,060
 It could be yet another continuous parameter.

724
00:46:43,060 --> 00:46:45,260
 Yeah?

725
00:46:45,260 --> 00:46:47,660
 [INAUDIBLE]

726
00:46:47,660 --> 00:46:57,260
 It takes in, what is my robot, what are my objects, and where are those objects, and

727
00:46:57,260 --> 00:47:00,980
 what is the wrench that I want to be exerting as I do that push twist?

728
00:47:00,980 --> 00:47:05,460
 And it is going to return you the trajectory, which in this case is your Cartesian impedances

729
00:47:05,460 --> 00:47:06,460
 and your set points.

730
00:47:06,460 --> 00:47:07,460
 [INAUDIBLE]

731
00:47:07,460 --> 00:47:08,460
 Those are the outputs of your sampler.

732
00:47:08,460 --> 00:47:09,460
 [INAUDIBLE]

733
00:47:09,460 --> 00:47:30,340
 Some of these are inputs, and some of these are outputs, because it is simply defining

734
00:47:30,340 --> 00:47:31,340
 a relation over all of them.

735
00:47:31,340 --> 00:47:32,340
 Yeah?

736
00:47:32,340 --> 00:47:43,780
 [INAUDIBLE]

737
00:47:43,780 --> 00:47:47,940
 So this is-- yeah, that's an excellent question.

738
00:47:47,940 --> 00:47:52,060
 How do I go from-- you notice that there is an and on top, and so this is the precondition

739
00:47:52,060 --> 00:47:53,660
 has to be true.

740
00:47:53,660 --> 00:47:59,820
 And so what's happening here is that twist hand can is a relation over all of these parameters

741
00:47:59,820 --> 00:48:05,940
 and connected to that relation is a sampler that is generating satisfying values of those

742
00:48:05,940 --> 00:48:07,660
 parameters.

743
00:48:07,660 --> 00:48:14,540
 And so basically, if the sampler is able to return values, then that constraint is satisfied.

744
00:48:14,540 --> 00:48:19,460
 If it can't return things, then there isn't satisfying solutions, so it isn't satisfied,

745
00:48:19,460 --> 00:48:20,460
 and this thing would render as false.

746
00:48:20,460 --> 00:48:21,460
 Yeah?

747
00:48:21,460 --> 00:48:40,420
 [INAUDIBLE]

748
00:48:40,420 --> 00:48:41,420
 Don't believe I understand your question.

749
00:48:41,420 --> 00:48:42,420
 [INAUDIBLE]

750
00:48:42,420 --> 00:48:48,820
 It will also return the trajectory.

751
00:48:48,820 --> 00:48:53,660
 So what it does is it returns where there's true, and it populates that variable t with

752
00:48:53,660 --> 00:48:54,660
 the solution.

753
00:48:54,660 --> 00:48:55,660
 [INAUDIBLE]

754
00:48:55,660 --> 00:48:56,660
 Gets stored.

755
00:48:56,660 --> 00:48:57,660
 Yeah?

756
00:48:57,660 --> 00:48:58,660
 [INAUDIBLE]

757
00:48:58,660 --> 00:49:14,180
 It is just enough to loosen the cap.

758
00:49:14,180 --> 00:49:21,060
 We made the design choice that there is another operator which actually pops it off.

759
00:49:21,060 --> 00:49:26,780
 Actually the reason why we wanted to separate the twisting motion from the removing motion

760
00:49:26,780 --> 00:49:31,100
 is because I gave that picture that there are four different ways that you could do

761
00:49:31,100 --> 00:49:36,580
 the twisting, and so I want to separate twisting from removing it.

762
00:49:36,580 --> 00:49:43,580
 Because I'd have to copy the removing it into all four of those.

763
00:49:43,580 --> 00:49:45,580
 Good.

764
00:49:45,580 --> 00:49:47,580
 OK.

765
00:49:47,580 --> 00:49:52,020
 We're actually not done.

766
00:49:52,020 --> 00:49:56,180
 There's one other thing, which is that we want to check that our trajectory is collision-free.

767
00:49:56,180 --> 00:49:57,180
 So those are all of our preconditions.

768
00:49:57,180 --> 00:50:01,580
 These are the things that need to be true, and we built it together.

769
00:50:01,580 --> 00:50:06,100
 These are the things that need to be true, and these are the variables that we're basically

770
00:50:06,100 --> 00:50:11,620
 solving for that satisfy these constraints.

771
00:50:11,620 --> 00:50:15,900
 In order to fully characterize this, we also have to define what is the effect of this

772
00:50:15,900 --> 00:50:16,900
 action.

773
00:50:16,900 --> 00:50:20,540
 And so the effect of our action, the main thing is that we're going to say that the

774
00:50:20,540 --> 00:50:25,580
 cap is now twisted off, and that we are not at the configuration that we started at, and

775
00:50:25,580 --> 00:50:28,420
 we are now at the configuration that's basically at the end of our trajectory.

776
00:50:28,420 --> 00:50:33,020
 Our robot has moved as a result of this action.

777
00:50:33,020 --> 00:50:41,940
 Constraints are almost always easier to specify than preconditions.

778
00:50:41,940 --> 00:50:48,380
 That is a deep dive into what is it like to actually specify one operator.

779
00:50:48,380 --> 00:50:53,660
 And so that hopefully gives you all a sense for what it is like to write these operators,

780
00:50:53,660 --> 00:51:00,220
 is that you write what is the specification in terms of preconditions and effects, specifically

781
00:51:00,220 --> 00:51:03,780
 in this framework in Prediddle, and then you write all of those samplers that actually

782
00:51:03,780 --> 00:51:06,780
 does the controller generation.

783
00:51:06,780 --> 00:51:11,380
 In this case, we write it in Python.

784
00:51:11,380 --> 00:51:15,220
 So now you've done that work.

785
00:51:15,220 --> 00:51:16,700
 You've written all of your operators.

786
00:51:16,700 --> 00:51:21,060
 We're going to tape our operators, and we're going to put it in Prediddle stream, and we

787
00:51:21,060 --> 00:51:24,980
 can now actually appreciate the video that I showed from before, which is that the goal

788
00:51:24,980 --> 00:51:27,700
 of our robot is that we want to uncap.

789
00:51:27,700 --> 00:51:35,420
 So the robot is going to first do a move, pick, and then place it in the vice.

790
00:51:35,420 --> 00:51:40,020
 It's then going to do that push-twist that we just spent a while discussing before removing

791
00:51:40,020 --> 00:51:42,860
 that cap.

792
00:51:42,860 --> 00:51:49,620
 So it searched over to find that action sequence of move, pick, move, place, and it solved

793
00:51:49,620 --> 00:51:52,060
 for all of the continuous parameters.

794
00:51:52,060 --> 00:51:53,060
 What are the trajectories?

795
00:51:53,060 --> 00:51:54,060
 What are the paths?

796
00:51:54,060 --> 00:51:55,060
 What are the actual configurations and the grasps?

797
00:51:55,060 --> 00:51:56,060
 Yeah?

798
00:51:56,060 --> 00:52:02,220
 It has the on-flip, and then it's just dividing, so it's just going to do a--

799
00:52:02,220 --> 00:52:03,220
 It did.

800
00:52:03,220 --> 00:52:04,780
 Can you repeat the question?

801
00:52:04,780 --> 00:52:08,820
 So the question is, did it have all of the operators possible?

802
00:52:08,820 --> 00:52:09,820
 Could it have picked-- yes.

803
00:52:09,820 --> 00:52:12,460
 In that case, it chose to do a grasp twist.

804
00:52:12,460 --> 00:52:16,740
 And the beautiful thing is that if I give my robot the list of operators, there are

805
00:52:16,740 --> 00:52:21,300
 many, many different ways that it can solve the same task.

806
00:52:21,300 --> 00:52:26,620
 I've learned I can't talk while this video is playing because everyone just watches the

807
00:52:26,620 --> 00:52:27,620
 video.

808
00:52:27,620 --> 00:52:28,620
 Let it play.

809
00:52:28,620 --> 00:52:35,060
 I was asking it to do the same task.

810
00:52:35,060 --> 00:52:39,700
 The environment was different in each one in that the bottle was in different starting

811
00:52:39,700 --> 00:52:41,700
 locations and the objects were in different starting locations.

812
00:52:41,700 --> 00:52:44,540
 And in some cases, there was the tool, and in some cases, there was the mat, and there

813
00:52:44,540 --> 00:52:46,100
 was only a vice in one of them.

814
00:52:46,100 --> 00:52:52,140
 And the robot is essentially doing the planning of how do I sequence those set of actions

815
00:52:52,140 --> 00:52:54,180
 to accomplish this task?

816
00:52:54,180 --> 00:52:59,620
 And the really beautiful thing about this is that it is searching over a space that

817
00:52:59,620 --> 00:53:01,620
 is combinatorial.

818
00:53:01,620 --> 00:53:07,340
 This is showing not even all the possibilities, but I put all the possible push twists versus

819
00:53:07,340 --> 00:53:08,340
 all the possible fixturings.

820
00:53:08,340 --> 00:53:16,060
 And the beautiful thing is what I love so much about this is I gave my robot-- here

821
00:53:16,060 --> 00:53:17,540
 is a list of operators.

822
00:53:17,540 --> 00:53:21,340
 Here are the different things that you can do.

823
00:53:21,340 --> 00:53:26,300
 And then it does the work to find all of the different possibilities.

824
00:53:26,300 --> 00:53:32,740
 It does the combinatorial search to find how can I compose these operators to find a satisfying

825
00:53:32,740 --> 00:53:35,740
 plan to achieve my goal.

826
00:53:35,740 --> 00:53:36,740
 Yeah?

827
00:53:36,740 --> 00:54:00,100
 Is it possible to use the first two different levels?

828
00:54:00,100 --> 00:54:01,100
 I can imagine one of the steps would be like, I'm Captain Medicine Bottle, and then the

829
00:54:01,100 --> 00:54:02,100
 next thing would be like, do a bunch of other tasks.

830
00:54:02,100 --> 00:54:03,100
 Can you superimpose multiple levels of this?

831
00:54:03,100 --> 00:54:04,100
 Yeah.

832
00:54:04,100 --> 00:54:05,100
 So the question is, can you have hierarchy?

833
00:54:05,100 --> 00:54:10,060
 So the famous task in motion planners is hierarchical planning in the now.

834
00:54:10,060 --> 00:54:14,580
 It is actually Leslie and Tomas's task in motion planner is built upon this idea that

835
00:54:14,580 --> 00:54:19,840
 if you want to do truly long horizon tasks, then you have to have notions of hierarchy.

836
00:54:19,840 --> 00:54:22,840
 So yes, and a lot of people have thought about it.

837
00:54:22,840 --> 00:54:23,840
 Yeah?

838
00:54:23,840 --> 00:54:24,840
 It says a point of reference.

839
00:54:24,840 --> 00:54:30,540
 How long does it take to find a process in wall process?

840
00:54:30,540 --> 00:54:33,140
 You mean for each individual one?

841
00:54:33,140 --> 00:54:34,140
 If I wanted to find a plan?

842
00:54:34,140 --> 00:54:35,140
 A plan.

843
00:54:35,140 --> 00:54:43,900
 So I have the results of that in the paper that this work is based off of.

844
00:54:43,900 --> 00:54:50,340
 But if you want to do order of magnitude, sometimes under a minute or up to two to three

845
00:54:50,340 --> 00:54:53,460
 minutes in this case.

846
00:54:53,460 --> 00:55:03,900
 Part of that is because there are two reasons why it takes-- well, I don't know whether

847
00:55:03,900 --> 00:55:07,940
 you think a few minutes is a long time or not.

848
00:55:07,940 --> 00:55:09,100
 But there are a few reasons.

849
00:55:09,100 --> 00:55:11,500
 One is that I don't optimize any of my code for speed.

850
00:55:11,500 --> 00:55:12,780
 And so it almost certainly could be faster.

851
00:55:12,780 --> 00:55:15,900
 And I just don't care.

852
00:55:15,900 --> 00:55:21,260
 And the second is that there are actually-- and this is something that's good-- computational

853
00:55:21,260 --> 00:55:26,500
 bottlenecks that can make this search difficult.

854
00:55:26,500 --> 00:55:32,100
 And that you can imagine-- if you were solving a constraint satisfaction problem, and the

855
00:55:32,100 --> 00:55:36,740
 space of satisfying solutions is rather small, then-- and especially given that we, in this

856
00:55:36,740 --> 00:55:40,180
 case, are taking a sampling-based approach-- that it's going to take a while to sample

857
00:55:40,180 --> 00:55:42,860
 satisfying solutions.

858
00:55:42,860 --> 00:55:46,500
 So sometimes I can set up this problem such that it's like if I require exerting a lot

859
00:55:46,500 --> 00:55:51,700
 of force, such as there are only a few configurations that actually can achieve that, then I've

860
00:55:51,700 --> 00:55:54,180
 basically made my constraint satisfaction problem very hard.

861
00:55:54,180 --> 00:55:55,180
 And so the planer struggles.

862
00:55:55,180 --> 00:55:56,180
 And it takes longer.

863
00:55:56,180 --> 00:56:06,060
 OK.

864
00:56:06,060 --> 00:56:16,660
 So this is hopefully a little bit of an example of what it is like to use a task in motion

865
00:56:16,660 --> 00:56:17,660
 planer.

866
00:56:17,660 --> 00:56:23,500
 And in this case, although I did not emphasize it too terribly, this is a task in motion

867
00:56:23,500 --> 00:56:31,260
 planer instance where we are also bringing in aspects of control, leveraging impedance

868
00:56:31,260 --> 00:56:33,500
 control, and different mechanics.

869
00:56:33,500 --> 00:56:37,540
 I want to expand upon that point-- this is going to bring us to our last section-- about

870
00:56:37,540 --> 00:56:42,020
 TAMP as a computational framework.

871
00:56:42,020 --> 00:56:46,540
 And I want to hammer this home by showing-- I've been showing mainly kinematic things

872
00:56:46,540 --> 00:56:48,060
 and taking a very planning-based approach.

873
00:56:48,060 --> 00:56:52,980
 And I want to show you that a lot of the pieces that we've learned in this class so far fit

874
00:56:52,980 --> 00:56:55,620
 within this framework and that you can integrate them in.

875
00:56:55,620 --> 00:57:00,060
 And this enables you to do super awesome things.

876
00:57:00,060 --> 00:57:04,700
 Admittedly, this is also just going to be me showing off a lot of the work that our

877
00:57:04,700 --> 00:57:07,260
 lab has done.

878
00:57:07,260 --> 00:57:10,060
 Because nothing is more fun than bragging about your friends.

879
00:57:10,060 --> 00:57:13,220
 And so we're going to show a lot of videos of awesome stuff that task in motion planning

880
00:57:13,220 --> 00:57:18,980
 can do, which maybe hopefully gets you excited about things that you could do with task in

881
00:57:18,980 --> 00:57:19,980
 motion planning.

882
00:57:19,980 --> 00:57:22,980
 OK.

883
00:57:22,980 --> 00:57:27,740
 A valid complaint you can make about what I've shown you so far is that there is no

884
00:57:27,740 --> 00:57:29,980
 perception involved.

885
00:57:29,980 --> 00:57:32,420
 And personally, in my work, I do not deal with perception.

886
00:57:32,420 --> 00:57:35,700
 But that is not a limitation of task in motion planning.

887
00:57:35,700 --> 00:57:41,020
 So we've had people in the lab who wanted to integrate perception in to task in motion

888
00:57:41,020 --> 00:57:42,020
 planning.

889
00:57:42,020 --> 00:57:44,460
 And so you have your task in motion planner from before.

890
00:57:44,460 --> 00:57:48,340
 But instead of a priori assuming you know where everything in the world is, which is

891
00:57:48,340 --> 00:57:52,780
 what I do, is that we're actually going to use all the perception tools that we've learned

892
00:57:52,780 --> 00:57:53,780
 throughout this class.

893
00:57:53,780 --> 00:57:58,620
 In this case, they're going to take an image and operate on point clouds.

894
00:57:58,620 --> 00:58:01,740
 And in this work, they used a lot of pre-trained models and a lot of awesome stuff.

895
00:58:01,740 --> 00:58:08,020
 We talked about math, RCNN, in lecture 9, maybe?

896
00:58:08,020 --> 00:58:12,100
 No, I don't remember.

897
00:58:12,100 --> 00:58:17,460
 In this case, instead of operating on known poses and known objects, that your task in

898
00:58:17,460 --> 00:58:25,580
 motion planner is operating on the output of these pre-trained perception models.

899
00:58:25,580 --> 00:58:32,860
 And that allows you to do super cool stuff, like instead of having to have a notion of

900
00:58:32,860 --> 00:58:40,500
 object state, what you can do is I want to put everything that's red in the red bowl

901
00:58:40,500 --> 00:58:44,380
 and everything that is green in the green bowl.

902
00:58:44,380 --> 00:58:48,980
 Notice that bananas are green, which is-- I don't know what perception system did that,

903
00:58:48,980 --> 00:58:51,740
 but it's the decision made.

904
00:58:51,740 --> 00:58:54,900
 And right here, it's putting all of the objects in the opposite color regions.

905
00:58:54,900 --> 00:58:59,500
 And to go into a little bit of detail, the different perception elements that are getting

906
00:58:59,500 --> 00:59:05,820
 used is that it is segmenting out the table, and then it's segmenting out all of the objects.

907
00:59:05,820 --> 00:59:12,260
 In this case, for a lot of these, doing color detection and is operating directly on those

908
00:59:12,260 --> 00:59:13,260
 point clouds.

909
00:59:13,260 --> 00:59:19,980
 The other thing that it's doing is to specify a set of graphs that is using GDP, which is

910
00:59:19,980 --> 00:59:25,340
 the learning-based method, to generate those graphs as opposed to those graphs being generated

911
00:59:25,340 --> 00:59:26,340
 a priority.

912
00:59:26,340 --> 00:59:28,940
 So this gets back a little bit to the question of are things learned?

913
00:59:28,940 --> 00:59:36,180
 In this case, for this system, some elements are learned.

914
00:59:36,180 --> 00:59:38,780
 For each of these, I'm going to have to say, if you want to learn more, I've listed the

915
00:59:38,780 --> 00:59:40,660
 paper down below.

916
00:59:40,660 --> 00:59:47,700
 So this is just a little bit of a sampling.

917
00:59:47,700 --> 00:59:52,940
 There was a question before, which is you write out all of these things, and do you

918
00:59:52,940 --> 00:59:55,700
 learn your controllers, or do you specify your controllers?

919
00:59:55,700 --> 00:59:57,740
 This was your question.

920
00:59:57,740 --> 01:00:02,460
 And in the case that I showed, we wrote down our controllers.

921
01:00:02,460 --> 01:00:06,100
 But maybe you don't want to write down controllers all day.

922
01:00:06,100 --> 01:00:13,500
 And so there's a project in the lab that was, what if we want to acquire new skills by actually

923
01:00:13,500 --> 01:00:17,540
 assuming that we have the controller, and we want to learn the parameters of our controller

924
01:00:17,540 --> 01:00:18,540
 in order to use it?

925
01:00:18,540 --> 01:00:22,620
 Let's make that a little bit more concrete.

926
01:00:22,620 --> 01:00:28,620
 Let's say that I would like my robot to learn how to pour.

927
01:00:28,620 --> 01:00:32,460
 And I have some specification for what it's like to pour, and I want to learn how do I

928
01:00:32,460 --> 01:00:36,220
 have to move my arm such that I can have a successful pour?

929
01:00:36,220 --> 01:00:41,260
 And I do not want to have to write down this controller from scratch.

930
01:00:41,260 --> 01:00:48,700
 So what they did, step one of learning is we need to collect data.

931
01:00:48,700 --> 01:00:54,480
 And oh, man, I hope this video loads.

932
01:00:54,480 --> 01:00:58,620
 So our robot needs to learn how to scoop, how to pour.

933
01:00:58,620 --> 01:01:01,060
 And so we're going to first collect a lot of data.

934
01:01:01,060 --> 01:01:05,020
 I will point out that it is times 40x.

935
01:01:05,020 --> 01:01:07,860
 And we're going to have our robot collect a lot of data.

936
01:01:07,860 --> 01:01:11,220
 Z is the lovely grad student running around in the background.

937
01:01:11,220 --> 01:01:14,880
 The nice thing about this is that what we're going to do is it's going to pour over and

938
01:01:14,880 --> 01:01:15,880
 over again.

939
01:01:15,880 --> 01:01:20,380
 And this is actually labeled data for whether the pour is successful, because you can measure

940
01:01:20,380 --> 01:01:21,820
 that's actually a scale.

941
01:01:21,820 --> 01:01:24,180
 It's what is the weight of the amount that I've poured.

942
01:01:24,180 --> 01:01:27,340
 And so you can imagine if the weight is very high, then I've had a successful pour, because

943
01:01:27,340 --> 01:01:29,420
 most of-- those are chickpeas.

944
01:01:29,420 --> 01:01:31,380
 So the chickpeas went in the bowl.

945
01:01:31,380 --> 01:01:34,900
 And if the weight is very low, then that's an unsuccessful pour.

946
01:01:34,900 --> 01:01:37,140
 And so we ask our robot to do this over and over again.

947
01:01:37,140 --> 01:01:41,060
 And we collect a lot of labeled data about what are the control parameters that lead

948
01:01:41,060 --> 01:01:42,980
 to a successful pour.

949
01:01:42,980 --> 01:01:46,100
 Does the data collection make sense?

950
01:01:46,100 --> 01:01:50,100
 If you were worried about what happened during COVID, what did the statum mice eat?

951
01:01:50,100 --> 01:01:52,100
 They ate all of our chickpeas.

952
01:01:52,100 --> 01:01:54,700
 It was gross.

953
01:01:54,700 --> 01:02:01,260
 So you have some grad student, in this case, Z, collect a lot of data.

954
01:02:01,260 --> 01:02:04,340
 And it's labeled training data, which is super awesome.

955
01:02:04,340 --> 01:02:09,660
 And what they did in this case is given the kind of specification of our action and given

956
01:02:09,660 --> 01:02:15,380
 a lot of labeled data, what we're going to do is we're going to learn a constraint, which

957
01:02:15,380 --> 01:02:19,780
 defines what are the valid control parameters that lead to a successful pour.

958
01:02:19,780 --> 01:02:23,340
 In this case, they use a Gaussian process regression.

959
01:02:23,340 --> 01:02:26,140
 Their argument, which again, they make more beautifully in the paper, is that this is

960
01:02:26,140 --> 01:02:30,700
 useful for sampling and that it is great for data efficiency.

961
01:02:30,700 --> 01:02:35,020
 And having watched the video from before, you might imagine why they really cared about

962
01:02:35,020 --> 01:02:37,660
 data efficiency in this context.

963
01:02:37,660 --> 01:02:40,860
 So to summarize, they gathered a lot of data.

964
01:02:40,860 --> 01:02:45,340
 And they used learning method in order to characterize what are the control parameters

965
01:02:45,340 --> 01:02:48,220
 that lead to a successful pour.

966
01:02:48,220 --> 01:02:51,260
 I will say they use Gaussian process regression.

967
01:02:51,260 --> 01:02:55,660
 You could swap in any learning method that you wanted to if you wanted to learn the control

968
01:02:55,660 --> 01:02:58,180
 parameters.

969
01:02:58,180 --> 01:03:02,180
 But the nice thing is that they gathered enough data.

970
01:03:02,180 --> 01:03:04,780
 We cleaned up the chickpeas.

971
01:03:04,780 --> 01:03:11,460
 And that now our robot has effectively acquired a new skill, and that it can now do pouring.

972
01:03:11,460 --> 01:03:16,440
 There's nothing in the cup, the first pour, which I find super weird.

973
01:03:16,440 --> 01:03:17,700
 But there is stuff in the second pour.

974
01:03:17,700 --> 01:03:22,460
 So we'll wait for the second pour.

975
01:03:22,460 --> 01:03:26,180
 We'll notice the goal is to pour.

976
01:03:26,180 --> 01:03:30,500
 But because we've added a new skill, we haven't lost what we've had before.

977
01:03:30,500 --> 01:03:34,260
 And so we still have all of-- yeah, there it goes.

978
01:03:34,260 --> 01:03:36,620
 Is it still doing all of that geometric reasoning?

979
01:03:36,620 --> 01:03:39,580
 I'll pause it for a minute.

980
01:03:39,580 --> 01:03:41,900
 We've added a new skill of how to do pouring.

981
01:03:41,900 --> 01:03:44,500
 But we haven't lost the fact that we know how to do pick and place.

982
01:03:44,500 --> 01:03:46,660
 We know how to do all of these other things.

983
01:03:46,660 --> 01:03:52,140
 We've just added something in into our existing repertoire of skills.

984
01:03:52,140 --> 01:03:56,300
 And once we've added in our skill, we can now search over action sequences that involve

985
01:03:56,300 --> 01:03:57,300
 that new skill.

986
01:03:57,300 --> 01:03:59,140
 And you can imagine maybe you use a different method.

987
01:03:59,140 --> 01:04:00,140
 You learn a new skill.

988
01:04:00,140 --> 01:04:01,140
 You add it in.

989
01:04:01,140 --> 01:04:02,140
 Now your robot has more capability.

990
01:04:02,140 --> 01:04:04,580
 You just keep building.

991
01:04:04,580 --> 01:04:05,960
 Cool.

992
01:04:05,960 --> 01:04:07,460
 This is one way to integrate learning.

993
01:04:07,460 --> 01:04:09,500
 And there's a lot of different ways.

994
01:04:09,500 --> 01:04:18,860
 But one other way that I'll mention that's just skipping is that something that we talked

995
01:04:18,860 --> 01:04:24,660
 about that Charles asked about is like-- OK, you didn't ask why things are slow.

996
01:04:24,660 --> 01:04:29,940
 But that's an interpretation of what your question could be-- is that you can imagine

997
01:04:29,940 --> 01:04:37,220
 also using learning to speed up your search, that can we use prior experience to speed

998
01:04:37,220 --> 01:04:39,380
 up this search over action sequences?

999
01:04:39,380 --> 01:04:43,020
 And there was some work done by our lab.

1000
01:04:43,020 --> 01:04:48,940
 This again shows off mobile robot manipulation in the PR2 style of moving.

1001
01:04:48,940 --> 01:04:53,060
 And now what this does is actually, if you're searching over action sequences, it learns

1002
01:04:53,060 --> 01:05:00,780
 a Q function in order to bias what action sequences you want to explore.

1003
01:05:00,780 --> 01:05:05,260
 We mentioned that you get computational efficiency from task planning.

1004
01:05:05,260 --> 01:05:09,340
 The question is, what if I'm planning really long horizon stuff and I want to move even

1005
01:05:09,340 --> 01:05:10,580
 faster?

1006
01:05:10,580 --> 01:05:13,220
 And what they showed with this work is that you can basically learn this Q function that

1007
01:05:13,220 --> 01:05:17,500
 speeds up your planning by a couple of factors.

1008
01:05:17,500 --> 01:05:18,500
 Cool.

1009
01:05:18,500 --> 01:05:20,260
 Those are two ways to integrate learning.

1010
01:05:20,260 --> 01:05:23,100
 Those are not all of the possible ways.

1011
01:05:23,100 --> 01:05:28,020
 But I hope it gives you a flavor of the ways so far of how you can integrate perception,

1012
01:05:28,020 --> 01:05:33,180
 how you can integrate control, and how you can integrate learning into task and motion

1013
01:05:33,180 --> 01:05:36,180
 planning.

1014
01:05:36,180 --> 01:05:39,740
 OK.

1015
01:05:39,740 --> 01:05:41,880
 There's one more thing that I want to cover.

1016
01:05:41,880 --> 01:05:50,460
 And to be honest, I'm sneaking a special topic inside a special topic.

1017
01:05:50,460 --> 01:05:57,040
 Something that we haven't talked about so far that I'd be remiss if I didn't mention

1018
01:05:57,040 --> 01:05:59,500
 is uncertainty.

1019
01:05:59,500 --> 01:06:05,980
 If we think about what we've dealt with so far, we've kind of assumed that the world

1020
01:06:05,980 --> 01:06:12,540
 is observable, that things are deterministic, that we know how the world is going to act.

1021
01:06:12,540 --> 01:06:16,220
 I wrote out those operators and I said, this is what's going to happen in the world.

1022
01:06:16,220 --> 01:06:20,700
 And it's making kind of a strong assumption, like I know what's going to happen.

1023
01:06:20,700 --> 01:06:22,460
 Because the world is not deterministic.

1024
01:06:22,460 --> 01:06:24,900
 The world is not observable.

1025
01:06:24,900 --> 01:06:26,100
 The world is stochastic.

1026
01:06:26,100 --> 01:06:27,580
 The world is partially observable.

1027
01:06:27,580 --> 01:06:28,580
 The cabling is correct.

1028
01:06:28,580 --> 01:06:31,100
 The world is a POMDP.

1029
01:06:31,100 --> 01:06:37,060
 So how can we get our-- if we want to use this framework, how can we have a framework

1030
01:06:37,060 --> 01:06:40,060
 that still deals with uncertainty?

1031
01:06:40,060 --> 01:06:43,100
 Does the setup of what we want to do make sense?

1032
01:06:43,100 --> 01:06:45,020
 OK.

1033
01:06:45,020 --> 01:06:50,340
 So I don't know if this was mentioned previously, but we're going to introduce-- instead of

1034
01:06:50,340 --> 01:06:54,340
 saying I know what the state of the world is, we're going to introduce this notion of

1035
01:06:54,340 --> 01:06:55,340
 belief space.

1036
01:06:55,340 --> 01:07:01,220
 And instead of saying the pose of the object is here, we're going to have a probability

1037
01:07:01,220 --> 01:07:04,100
 distribution over your underlying world states.

1038
01:07:04,100 --> 01:07:08,340
 Instead of saying the object poses here, I'm going to say I have a probability distribution

1039
01:07:08,340 --> 01:07:11,100
 of where my object could be.

1040
01:07:11,100 --> 01:07:20,540
 And what this means is I have a belief over where my object is.

1041
01:07:20,540 --> 01:07:27,140
 So the robot, in now planning, has to maintain what is its belief over where things are.

1042
01:07:27,140 --> 01:07:33,220
 And you might imagine that if I am a robot, I have some belief that my computer is on

1043
01:07:33,220 --> 01:07:34,220
 the table.

1044
01:07:34,220 --> 01:07:37,460
 But maybe I do not know exactly where it is because I'm not facing it.

1045
01:07:37,460 --> 01:07:42,300
 And that if I use my perception system and I observe that I can update my belief on where

1046
01:07:42,300 --> 01:07:46,300
 I believe the pose of my computer to be.

1047
01:07:46,300 --> 01:07:50,120
 And so our system now needs to-- instead of saying this is the state of our world and

1048
01:07:50,120 --> 01:07:53,260
 updating our state, we have a belief over our world.

1049
01:07:53,260 --> 01:07:58,820
 And we may need to take actions that allow us to update what is the belief of our world.

1050
01:07:58,820 --> 01:08:05,380
 And now instead of our effects being on state, our effects are going to be on our belief.

1051
01:08:05,380 --> 01:08:06,380
 That setup makes sense.

1052
01:08:06,380 --> 01:08:14,120
 Now, there's been a couple of different ways that people have done belief space planning.

1053
01:08:14,120 --> 01:08:15,660
 This is perhaps one of the earlier ones.

1054
01:08:15,660 --> 01:08:21,000
 This is actually-- the robot escaping the lab from earlier comes from this paper.

1055
01:08:21,000 --> 01:08:25,080
 But the example I specifically want to show is a bit more recent and actually uses that

1056
01:08:25,080 --> 01:08:28,240
 podidal stream planner that we discussed from before.

1057
01:08:28,240 --> 01:08:32,200
 So this is going to keep track of belief specifically using particle filter.

1058
01:08:32,200 --> 01:08:34,080
 If it doesn't mean anything to you, that is OK.

1059
01:08:34,080 --> 01:08:36,720
 It is a representation for how we're going to represent our belief.

1060
01:08:36,720 --> 01:08:41,160
 And what our robot's going to do is I'm going to show this by example.

1061
01:08:41,160 --> 01:08:44,900
 That our robot's goal-- our robot's goal is to cook spam.

1062
01:08:44,900 --> 01:08:47,660
 It's not for me, but it's cooking spam for someone.

1063
01:08:47,660 --> 01:08:52,480
 And it doesn't know where the spam is at the beginning.

1064
01:08:52,480 --> 01:08:56,840
 And so what it starts off is that we say that the robot has a prior that there is a uniform

1065
01:08:56,840 --> 01:09:02,000
 distribution of where the spam could be on the table.

1066
01:09:02,000 --> 01:09:04,440
 It does not know initially where it is.

1067
01:09:04,440 --> 01:09:07,820
 It just knows that there's a uniform prior over positions on the table.

1068
01:09:07,820 --> 01:09:13,440
 And so what the robot decides to do is it says, well, the sugar box is in the way.

1069
01:09:13,440 --> 01:09:19,280
 And so I'm going to make a plan to pick up the sugar box to see if I can perceive the

1070
01:09:19,280 --> 01:09:23,720
 spam and update my belief on where the spam is.

1071
01:09:23,720 --> 01:09:25,960
 It's going to pick up the sugar box.

1072
01:09:25,960 --> 01:09:27,800
 It does an observation.

1073
01:09:27,800 --> 01:09:31,320
 It updates its belief that the spam is not behind the sugar box.

1074
01:09:31,320 --> 01:09:32,920
 And so it says, OK, where else could it be?

1075
01:09:32,920 --> 01:09:34,320
 Maybe it's behind the Cheez-It box.

1076
01:09:34,320 --> 01:09:36,980
 This is the same Cheez-It box from the YCB object.

1077
01:09:36,980 --> 01:09:39,680
 Everyone uses Cheez-It boxes.

1078
01:09:39,680 --> 01:09:42,800
 And so it moves the Cheez-It box.

1079
01:09:42,800 --> 01:09:46,880
 And the first times it moves it, it still can't perceive that the spam is there.

1080
01:09:46,880 --> 01:09:48,120
 It cannot update its belief.

1081
01:09:48,120 --> 01:09:49,680
 And so it tries again.

1082
01:09:49,680 --> 01:09:53,440
 And it actually moves it further away.

1083
01:09:53,440 --> 01:09:56,520
 And now it can finally perceive the spam.

1084
01:09:56,520 --> 01:09:59,040
 It updates its belief about where it believes the spam to be.

1085
01:09:59,040 --> 01:10:03,120
 And now it can cook the spam.

1086
01:10:03,120 --> 01:10:05,120
 It cooks the spam.

1087
01:10:05,120 --> 01:10:11,400
 But what we saw is that the robot had some belief on where things were.

1088
01:10:11,400 --> 01:10:16,160
 And it had to do what's called information gathering actions in terms of, well, I can't

1089
01:10:16,160 --> 01:10:17,160
 see it now.

1090
01:10:17,160 --> 01:10:22,440
 I should-- this is a very weird set of videos to pause on.

1091
01:10:22,440 --> 01:10:25,960
 And it's going to take information gathering actions in order to update its belief in order

1092
01:10:25,960 --> 01:10:31,160
 to basically be sure of where things are before it acts.

1093
01:10:31,160 --> 01:10:33,920
 This is the same Predictable Stream Planner that we had before.

1094
01:10:33,920 --> 01:10:37,520
 And it has basically a few extensions.

1095
01:10:37,520 --> 01:10:41,280
 One is that instead of operating on states, it's going to be operating on belief.

1096
01:10:41,280 --> 01:10:45,480
 There's some notion of replanning, that as soon as you get an update about your belief,

1097
01:10:45,480 --> 01:10:50,440
 you have to replan and pick what is my new sequence of actions and new satisfying values

1098
01:10:50,440 --> 01:10:52,520
 based off that new belief.

1099
01:10:52,520 --> 01:10:57,680
 And those are the two key elements that we need to do in order to enable belief-based

1100
01:10:57,680 --> 01:10:58,680
 planning.

1101
01:10:58,680 --> 01:11:05,160
 I'll show one other video just because it's super neat.

1102
01:11:05,160 --> 01:11:09,160
 Our goal is that we want to have the spam in the bottom drawer.

1103
01:11:09,160 --> 01:11:12,560
 And we have a uniform distribution on where our spam could be.

1104
01:11:12,560 --> 01:11:16,200
 It could be either in the top drawer or the bottom drawer.

1105
01:11:16,200 --> 01:11:19,720
 Our goal is for the spam to be in the bottom drawer.

1106
01:11:19,720 --> 01:11:21,240
 And we do not know where it is initially.

1107
01:11:21,240 --> 01:11:24,000
 So what the robot does is it first opens the bottom drawer.

1108
01:11:24,000 --> 01:11:27,200
 Because if the spam were there, we would already be done.

1109
01:11:27,200 --> 01:11:30,920
 And so it observes-- I will say, in this case, the camera is overhead.

1110
01:11:30,920 --> 01:11:31,920
 And so it observes.

1111
01:11:31,920 --> 01:11:33,720
 It says, the spam is not there.

1112
01:11:33,720 --> 01:11:35,320
 Therefore, I update my belief.

1113
01:11:35,320 --> 01:11:38,680
 Because it was not in the top drawer, it must be in the bottom drawer.

1114
01:11:38,680 --> 01:11:40,480
 So I will go open the bottom drawer.

1115
01:11:40,480 --> 01:11:41,480
 I will observe.

1116
01:11:41,480 --> 01:11:44,280
 Sure enough, my spam container is there.

1117
01:11:44,280 --> 01:11:51,000
 In this case, it actually has to put the spam on the tabletop in order to have its hand

1118
01:11:51,000 --> 01:11:52,000
 free.

1119
01:11:52,000 --> 01:11:53,480
 So it can close the drawer.

1120
01:11:53,480 --> 01:11:56,400
 Then it uses its open hand to open the bottom drawer.

1121
01:11:56,400 --> 01:12:02,520
 And now it can place the spam there and observe that we've achieved our goal, which is that

1122
01:12:02,520 --> 01:12:08,520
 our spam is safely stored away in our bottom drawer.

1123
01:12:08,520 --> 01:12:09,520
 Yes?

1124
01:12:09,520 --> 01:12:10,520
 You said you pick the bottom drawer first.

1125
01:12:10,520 --> 01:12:15,520
 But there's no optimization in that pattern, right?

1126
01:12:15,520 --> 01:12:16,520
 No.

1127
01:12:16,520 --> 01:12:18,840
 So there is actually two versions of this video.

1128
01:12:18,840 --> 01:12:22,200
 One is that it picks the top drawer first.

1129
01:12:22,200 --> 01:12:23,200
 Yeah.

1130
01:12:23,200 --> 01:12:28,640
 So Russ's-- sorry, Russ's question is, there's no optimization happening.

1131
01:12:28,640 --> 01:12:31,640
 So why would it pick the bottom drawer first?

1132
01:12:31,640 --> 01:12:36,360
 And that actually gets to a point-- we've been talking about solving constraint satisfaction

1133
01:12:36,360 --> 01:12:37,360
 problems.

1134
01:12:37,360 --> 01:12:42,360
 But in this case, all of what we've been talking about is finding satisfying values and not

1135
01:12:42,360 --> 01:12:45,220
 necessarily optimal values.

1136
01:12:45,220 --> 01:12:51,480
 You can imagine having a constraint satisfaction solver that leverages optimization such that

1137
01:12:51,480 --> 01:12:52,480
 you actually do get optimal values.

1138
01:12:52,480 --> 01:13:00,520
 But in this case, it's not.

1139
01:13:00,520 --> 01:13:01,520
 Another question?

1140
01:13:01,520 --> 01:13:02,520
 Yeah?

1141
01:13:02,520 --> 01:13:03,520
 [INAUDIBLE]

1142
01:13:03,520 --> 01:13:29,520
 Yes.

1143
01:13:29,520 --> 01:13:50,200
 The most general form of phrasing Richard's question is, why is all of this worth it?

1144
01:13:50,200 --> 01:13:52,520
 And what is it value?

1145
01:13:52,520 --> 01:13:55,720
 And so you could script this behavior.

1146
01:13:55,720 --> 01:14:03,440
 If I gave you this environment and I said, hey, I want you to get the spam in the bottom

1147
01:14:03,440 --> 01:14:08,080
 drawer and the spam is either in the top drawer or the bottom drawer, I have full belief that--

1148
01:14:08,080 --> 01:14:10,320
 OK, pun not intended.

1149
01:14:10,320 --> 01:14:15,320
 I think that you all could write a script where the robot does exactly that.

1150
01:14:15,320 --> 01:14:16,720
 You could recreate this behavior.

1151
01:14:16,720 --> 01:14:21,040
 It'd be kind of a weird final product, but you could do it.

1152
01:14:21,040 --> 01:14:25,680
 If the environment changes at all, you have to re-script it out.

1153
01:14:25,680 --> 01:14:30,440
 If I gave you a new robot or if I gave you a different object or if I said, now there

1154
01:14:30,440 --> 01:14:37,160
 are three drawers or now my probability distribution is that I believe my prior is that the spam

1155
01:14:37,160 --> 01:14:45,160
 is on the tabletop, you would have to re-script out that behavior.

1156
01:14:45,160 --> 01:14:49,880
 And so the generality that this gets is that I have defined each of my operators and that

1157
01:14:49,880 --> 01:14:55,040
 the task and motion planning element composes that in order to solve my problem.

1158
01:14:55,040 --> 01:15:00,520
 And if I give you a new environment or new objects or a new robot or new settings, you

1159
01:15:00,520 --> 01:15:02,720
 can still kind of throw all of this power at it.

1160
01:15:02,720 --> 01:15:09,640
 You do not need to re-script out robot trajectory, then grasp, and then move, and then pick.

1161
01:15:09,640 --> 01:15:12,080
 The robot is doing that sequencing for you.

1162
01:15:12,080 --> 01:15:16,520
 One of the reasons I love task and motion planning is it allows me to be lazy.

1163
01:15:16,520 --> 01:15:19,040
 I do not want to have to tell my robot what to do.

1164
01:15:19,040 --> 01:15:21,560
 I want it to figure it out for itself.

1165
01:15:21,560 --> 01:15:26,280
 And when you're scripting, you are telling it, do this and then this and then this.

1166
01:15:26,280 --> 01:15:31,000
 Task and motion planning, it is figuring out what is my valid sequence of actions given

1167
01:15:31,000 --> 01:15:32,000
 you've told me what I can do.

1168
01:15:32,000 --> 01:15:33,000
 Yeah?

1169
01:15:33,000 --> 01:15:34,000
 Is there any problem with the-- when you have the expectation part, is it a problem that

1170
01:15:34,000 --> 01:15:35,000
 you get something that is resulted in a task?

1171
01:15:35,000 --> 01:15:36,000
 So that you're--

1172
01:15:36,000 --> 01:15:37,000
 Yeah.

1173
01:15:37,000 --> 01:15:53,520
 So what about the deterministic part of each task?

1174
01:15:53,520 --> 01:15:56,680
 So let's say like it drops a can or something.

1175
01:15:56,680 --> 01:15:57,680
 Yeah.

1176
01:15:57,680 --> 01:16:01,440
 So the question is, what if things are not deterministic and something changes midway?

1177
01:16:01,440 --> 01:16:06,440
 So the case study that we walked through with the bottle, it would absolutely be a problem

1178
01:16:06,440 --> 01:16:07,920
 because there is no replanning there.

1179
01:16:07,920 --> 01:16:09,560
 It plans everything ahead of time.

1180
01:16:09,560 --> 01:16:12,080
 And the robot basically closes its eyes and tries to do it.

1181
01:16:12,080 --> 01:16:15,720
 And so if you, as like a pesky human, ran into the middle of my experiments, the robot

1182
01:16:15,720 --> 01:16:18,040
 would not know what to do.

1183
01:16:18,040 --> 01:16:24,000
 In this case, because it is perceiving and continuously updating its belief, it is doing

1184
01:16:24,000 --> 01:16:25,000
 replanning.

1185
01:16:25,000 --> 01:16:26,720
 It is replanning based off its belief.

1186
01:16:26,720 --> 01:16:32,520
 And so if you were to kind of walk in and like steal the spam, it would update its belief

1187
01:16:32,520 --> 01:16:35,520
 and replan accordingly.

1188
01:16:35,520 --> 01:16:38,080
 OK.

1189
01:16:38,080 --> 01:16:46,520
 So we are exactly at time.

1190
01:16:46,520 --> 01:16:54,560
 I'll just leave with-- this is the list of kind of all of the papers in about rough order

1191
01:16:54,560 --> 01:16:55,560
 of the things we covered.

1192
01:16:55,560 --> 01:16:57,720
 We actually didn't cover some middle part of this.

1193
01:16:57,720 --> 01:16:59,400
 But I think they're really cool.

1194
01:16:59,400 --> 01:17:03,600
 And so if you're kind of interested in explaining this more, again, highest priority probably

1195
01:17:03,600 --> 01:17:06,080
 goes to the survey paper, which kind of summarizes all of this.

1196
01:17:06,080 --> 01:17:10,880
 But these are kind of neat extensions of things you can do with task and motion planning.

1197
01:17:10,880 --> 01:17:11,880
 Yeah.

1198
01:17:11,880 --> 01:17:19,840
 If there are no final questions, this has been the special topic on TAMP.

1199
01:17:19,840 --> 01:17:21,040
 Thanks, everybody.

1200
01:17:21,040 --> 01:17:24,380
 [APPLAUSE]

