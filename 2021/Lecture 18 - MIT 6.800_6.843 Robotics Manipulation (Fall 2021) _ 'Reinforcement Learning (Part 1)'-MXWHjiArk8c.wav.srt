1
00:00:00,000 --> 00:00:06,480
 [INAUDIBLE]

2
00:00:06,480 --> 00:00:08,040
 All right.

3
00:00:08,040 --> 00:00:10,920
 OK, we're good.

4
00:00:10,920 --> 00:00:13,960
 Let me list a few administrative things just to kick off,

5
00:00:13,960 --> 00:00:18,240
 since there's a lot of things going on.

6
00:00:18,240 --> 00:00:20,200
 We know that the drop date is Thursday,

7
00:00:20,200 --> 00:00:22,000
 so people are thinking about their grades.

8
00:00:22,000 --> 00:00:22,840
 We've done our best.

9
00:00:22,840 --> 00:00:24,880
 I would say Rachel and Danny have done their best.

10
00:00:24,880 --> 00:00:29,400
 Thank you to grade as many of the p-sets

11
00:00:29,400 --> 00:00:30,400
 as we could possibly do.

12
00:00:30,400 --> 00:00:32,600
 They should be-- all the grades should be available to you

13
00:00:32,600 --> 00:00:33,600
 on Gradescope.

14
00:00:33,600 --> 00:00:37,120
 You get emails, I guess, most of the time that they're released.

15
00:00:37,120 --> 00:00:38,640
 And the rubric is on the website,

16
00:00:38,640 --> 00:00:41,040
 and the percentages should line up.

17
00:00:41,040 --> 00:00:42,820
 There's no intention to curve.

18
00:00:42,820 --> 00:00:44,900
 So you should have a good sense of where you're at.

19
00:00:44,900 --> 00:00:46,820
 If you have questions, of course, you can ask.

20
00:00:46,820 --> 00:00:52,120
 We have our project face-to-face meetings this week.

21
00:00:52,120 --> 00:00:55,320
 I'm excited to see your faces and talk about the project.

22
00:00:55,320 --> 00:00:56,480
 That's my number one goal.

23
00:00:56,480 --> 00:01:01,480
 I mean, I sent in the post just some basic instructions.

24
00:01:01,480 --> 00:01:02,800
 Come and tell us--

25
00:01:02,800 --> 00:01:04,760
 show us a few pictures, talk us through them,

26
00:01:04,760 --> 00:01:06,760
 and tell us how things are going.

27
00:01:06,760 --> 00:01:08,800
 Use it as a chance to ask us questions.

28
00:01:08,800 --> 00:01:10,800
 If you're stuck on anything, we want

29
00:01:10,800 --> 00:01:13,000
 to make sure we're helping you as much as possible

30
00:01:13,000 --> 00:01:16,040
 and that you're still on track.

31
00:01:16,040 --> 00:01:17,840
 If you have a big team and you want

32
00:01:17,840 --> 00:01:19,960
 to help us understand if everybody's

33
00:01:19,960 --> 00:01:23,040
 able to contribute, I think that's an important thing that I

34
00:01:23,040 --> 00:01:24,200
 would like to look out for.

35
00:01:24,800 --> 00:01:27,960
 In general, I think some of you are

36
00:01:27,960 --> 00:01:30,680
 asking lots of good questions on Stack Overflow.

37
00:01:30,680 --> 00:01:32,360
 I think a lot of them are private.

38
00:01:32,360 --> 00:01:34,100
 You guys don't realize how many questions

39
00:01:34,100 --> 00:01:38,640
 are getting answered all, but there's lots of good questions.

40
00:01:38,640 --> 00:01:39,560
 Keep them coming.

41
00:01:39,560 --> 00:01:42,440
 Some of you are asking them on Stack Overflow, which I actually

42
00:01:42,440 --> 00:01:43,560
 really appreciate and love.

43
00:01:43,560 --> 00:01:44,960
 I mean, I think--

44
00:01:44,960 --> 00:01:47,000
 and some of them have gotten-- some of those

45
00:01:47,000 --> 00:01:48,720
 have gotten extremely good answers.

46
00:01:48,720 --> 00:01:52,920
 So don't be shy asking on the main Drake forum.

47
00:01:52,920 --> 00:01:57,600
 I think that's incredibly good for, in general, just

48
00:01:57,600 --> 00:02:01,640
 having more open documentation and community

49
00:02:01,640 --> 00:02:03,040
 building for that.

50
00:02:03,040 --> 00:02:05,960
 And you also get more people answering questions

51
00:02:05,960 --> 00:02:08,920
 because they're on--

52
00:02:08,920 --> 00:02:11,000
 someone's there answering most of the time.

53
00:02:11,000 --> 00:02:18,040
 And the last thing that I guess we haven't said,

54
00:02:18,040 --> 00:02:21,280
 but we sort of decided, is that logistically,

55
00:02:21,280 --> 00:02:26,320
 with 50-some groups, we're going to do the videos again

56
00:02:26,320 --> 00:02:28,200
 for the final project presentation

57
00:02:28,200 --> 00:02:29,600
 rather than the live presentation.

58
00:02:29,600 --> 00:02:31,800
 I think it's actually worked incredibly well.

59
00:02:31,800 --> 00:02:34,960
 It was one of the good things that came out of Zoom semesters,

60
00:02:34,960 --> 00:02:39,160
 I think, is being able to have something-- an artifact

61
00:02:39,160 --> 00:02:41,360
 that you can look back at and share and other things

62
00:02:41,360 --> 00:02:42,960
 is a great thing.

63
00:02:42,960 --> 00:02:49,440
 And also, avoiding the switching laptop conundrum is nice.

64
00:02:49,440 --> 00:02:52,120
 So we're going to go for that again.

65
00:02:52,120 --> 00:02:54,800
 We still have the last day allocated for it.

66
00:02:54,800 --> 00:02:57,480
 I've actually reserved the room for longer.

67
00:02:57,480 --> 00:02:59,040
 We'll have a viewing session.

68
00:02:59,040 --> 00:03:02,440
 So it counts as one lecture from the time we get together,

69
00:03:02,440 --> 00:03:04,680
 but we'll watch as many of them as we can.

70
00:03:04,680 --> 00:03:06,640
 And we'll give you all the details on the website

71
00:03:06,640 --> 00:03:09,760
 about exactly the time durations and how to post

72
00:03:09,760 --> 00:03:10,800
 and everything like that.

73
00:03:10,800 --> 00:03:18,560
 Lots of small things, but any questions

74
00:03:18,560 --> 00:03:20,160
 about the administrative stuff?

75
00:03:20,160 --> 00:03:25,380
 OK.

76
00:03:25,380 --> 00:03:31,240
 So we started-- I kind of gave the prelude last week

77
00:03:31,240 --> 00:03:34,920
 to reinforcement learning, talking about visual motor.

78
00:03:34,920 --> 00:03:37,920
 And this week, we'll squarely focus on reinforcement

79
00:03:37,920 --> 00:03:40,200
 learning in two parts.

80
00:03:40,200 --> 00:03:44,600
 So part one today, we're going to talk about mostly

81
00:03:44,600 --> 00:03:49,400
 sort of the policy gradient view of reinforcement learning.

82
00:03:49,400 --> 00:03:51,160
 And then I'm going to talk--

83
00:03:51,160 --> 00:03:54,760
 I'm going to emphasize sort of a few of the core ideas, I think,

84
00:03:54,760 --> 00:03:57,040
 and maybe not even the most commonly discussed ideas,

85
00:03:57,040 --> 00:04:00,400
 but the ones that I think are most relevant to manipulation

86
00:04:00,400 --> 00:04:04,000
 and that are coming up in our research.

87
00:04:04,000 --> 00:04:06,920
 Some of the important ideas of thinking about it

88
00:04:06,920 --> 00:04:08,920
 as a black box optimization, some

89
00:04:08,920 --> 00:04:10,920
 of the important things that happen when we add

90
00:04:10,920 --> 00:04:13,600
 stochasticity to the formulation.

91
00:04:13,600 --> 00:04:15,280
 We'll talk through those.

92
00:04:15,280 --> 00:04:18,040
 Thursday, we're actually going to have a guest lecture

93
00:04:18,040 --> 00:04:20,560
 from Abhishek Gupta, who's fantastic.

94
00:04:20,560 --> 00:04:24,920
 He's a recent graduate from Peter Abbeel and Sergey

95
00:04:24,920 --> 00:04:25,720
 Levine's group.

96
00:04:25,720 --> 00:04:29,120
 He's done lots of reinforcement learning on real robots

97
00:04:29,120 --> 00:04:30,440
 doing manipulation.

98
00:04:30,440 --> 00:04:33,280
 So he's going to give you a very sort of applied RL view

99
00:04:33,280 --> 00:04:36,160
 and what does it take to do RL with real data

100
00:04:36,160 --> 00:04:37,680
 in the real world on Thursday.

101
00:04:37,680 --> 00:04:40,680
 So I think that'll be very good.

102
00:04:40,680 --> 00:04:43,840
 And he'll build off this, talk about the actor critic

103
00:04:43,840 --> 00:04:47,120
 and the Q-learning varieties.

104
00:04:47,120 --> 00:04:49,360
 Good.

105
00:04:49,360 --> 00:04:52,640
 OK, so let's start talking about RL.

106
00:04:52,640 --> 00:05:01,240
 What is reinforcement learning?

107
00:05:01,240 --> 00:05:04,360
 It means a lot of things to a lot of people.

108
00:05:04,360 --> 00:05:07,920
 The scope of what you might call a reinforcement learning

109
00:05:07,920 --> 00:05:12,120
 algorithm is a dynamic object.

110
00:05:12,120 --> 00:05:17,640
 And it grows aggressively, I would say.

111
00:05:17,640 --> 00:05:22,000
 For me, RL is a set of methods that

112
00:05:22,000 --> 00:05:23,640
 are trying to solve the control problem.

113
00:05:23,640 --> 00:05:27,880
 So the diagram you will always see here

114
00:05:27,880 --> 00:05:31,520
 in every sort of RL talk or book or whatever

115
00:05:31,520 --> 00:05:33,400
 is that you have an environment.

116
00:05:33,400 --> 00:05:34,160
 You have an agent.

117
00:05:34,160 --> 00:05:36,520
 Sometimes that's agent.

118
00:05:36,520 --> 00:05:43,080
 And we're just trying to close the loop with the environment.

119
00:05:43,080 --> 00:05:46,440
 But I think what defines RL for me, which

120
00:05:46,440 --> 00:05:49,960
 is maybe slightly narrower than it's broadly used these days,

121
00:05:49,960 --> 00:05:55,480
 is the idea that we're going to assume

122
00:05:55,480 --> 00:06:05,480
 that the environment, the world, the plant, is a black box.

123
00:06:05,480 --> 00:06:13,200
 So you get to run experiments on the environment.

124
00:06:13,200 --> 00:06:17,160
 You get to send in actions and get observations out.

125
00:06:17,160 --> 00:06:20,000
 But you don't get to know the full detailed equations

126
00:06:20,000 --> 00:06:22,720
 of the environment.

127
00:06:22,720 --> 00:06:24,760
 You don't get to explicitly take gradients of it.

128
00:06:24,760 --> 00:06:26,160
 You don't get to know its convex.

129
00:06:26,160 --> 00:06:27,660
 You don't get to do any of the stuff

130
00:06:27,660 --> 00:06:29,240
 that we've been trying to emphasize.

131
00:06:29,240 --> 00:06:36,560
 And there's a couple of key ideas about policy gradient

132
00:06:36,560 --> 00:06:40,280
 and Q functions and value functions

133
00:06:40,280 --> 00:06:44,080
 that are, I would say, defining in the sense of RL.

134
00:06:44,080 --> 00:06:46,800
 But this, I think, first idea is treating

135
00:06:46,800 --> 00:06:48,680
 the world as a black box.

136
00:06:48,680 --> 00:06:54,400
 And I think another key idea is that RL almost always

137
00:06:54,400 --> 00:06:58,720
 leverages stochastic optimal control as opposed

138
00:06:58,720 --> 00:07:05,600
 to the deterministic formulations

139
00:07:05,600 --> 00:07:07,480
 for algorithmic reasons.

140
00:07:07,480 --> 00:07:09,480
 And we'll see, I think, important reasons

141
00:07:09,480 --> 00:07:15,120
 for the success of the algorithms.

142
00:07:15,120 --> 00:07:22,080
 So last time, we started talking about the visual motor

143
00:07:22,080 --> 00:07:33,160
 policies, which is just so good and so awesome

144
00:07:33,160 --> 00:07:37,360
 that we can finally take a full camera input

145
00:07:37,360 --> 00:07:41,440
 and think about possibly blocking it off a little bit

146
00:07:41,440 --> 00:07:44,780
 and having a smaller pipe that comes down to a controller

147
00:07:44,780 --> 00:07:47,680
 that we think about with our RL tools,

148
00:07:47,680 --> 00:07:51,160
 but still this pipeline that takes images straight

149
00:07:51,160 --> 00:07:54,880
 through to actions and in a feedback loop

150
00:07:54,880 --> 00:07:57,960
 is just so good and so powerful.

151
00:07:57,960 --> 00:08:03,120
 And I really became completely convinced

152
00:08:03,120 --> 00:08:08,880
 when we were doing these experiments, this very, very,

153
00:08:08,880 --> 00:08:12,080
 I think, compelling, robust behavior, at least

154
00:08:12,080 --> 00:08:15,640
 local to the demonstrations, but where you could prod and push

155
00:08:15,640 --> 00:08:20,200
 and watch the robot interact with the world

156
00:08:20,200 --> 00:08:21,440
 in a much more reasonable way.

157
00:08:21,440 --> 00:08:27,840
 But last time, we did visual motor policies

158
00:08:27,840 --> 00:08:28,840
 with behavior cloning.

159
00:08:28,840 --> 00:08:38,560
 And today, we'll try to talk about some

160
00:08:38,560 --> 00:08:41,040
 of the underpinnings.

161
00:08:41,040 --> 00:08:42,760
 Can we find those policies with RL?

162
00:08:42,760 --> 00:09:03,200
, OK.

163
00:09:03,200 --> 00:09:07,040
 So I actually want to start.

164
00:09:07,040 --> 00:09:09,600
 It's been very fun for all of us,

165
00:09:09,600 --> 00:09:11,280
 I think, to read the feedback that you

166
00:09:11,280 --> 00:09:12,360
 give on the problem sets.

167
00:09:12,360 --> 00:09:14,680
 Those of you that are continuing to give good feedback,

168
00:09:14,680 --> 00:09:16,360
 we appreciate it.

169
00:09:16,360 --> 00:09:18,360
 Many of you keep asking about, don't

170
00:09:18,360 --> 00:09:21,280
 forget to throw in some software examples and the like.

171
00:09:21,280 --> 00:09:24,520
 So I actually want to start a little bit with this--

172
00:09:24,520 --> 00:09:29,360
 talk a little bit about RL software.

173
00:09:29,360 --> 00:09:37,320
 And it's actually progressed quite a bit

174
00:09:37,320 --> 00:09:38,880
 since this time last year.

175
00:09:38,880 --> 00:09:40,920
 So this time last year, I was looking around

176
00:09:40,920 --> 00:09:43,720
 at all the possible RL packages that I would recommend or not

177
00:09:43,720 --> 00:09:45,880
 recommend for the class.

178
00:09:45,880 --> 00:09:49,000
 And I was torn, because a lot of them

179
00:09:49,000 --> 00:09:50,840
 were in an intermediate state or something.

180
00:09:50,840 --> 00:09:54,440
 But I think there's some pretty good, more mature offerings

181
00:09:54,440 --> 00:09:55,600
 this time.

182
00:09:55,600 --> 00:09:57,480
 And I'm pretty excited about that.

183
00:09:57,480 --> 00:09:59,720
 So I feel more confident recommending

184
00:09:59,720 --> 00:10:03,080
 one or two specific things.

185
00:10:03,080 --> 00:10:04,120
 OK, so the first--

186
00:10:07,360 --> 00:10:10,560
 I guess I've forgotten my intro order,

187
00:10:10,560 --> 00:10:13,480
 but let me forward pass that for a second.

188
00:10:13,480 --> 00:10:20,040
 OK, the first bit of RL software that

189
00:10:20,040 --> 00:10:24,440
 has become the winning format, I think,

190
00:10:24,440 --> 00:10:27,080
 for specifying the environment half of this

191
00:10:27,080 --> 00:10:28,200
 is the OpenAI gem.

192
00:10:28,200 --> 00:10:29,160
 Many of you know this.

193
00:10:33,040 --> 00:10:40,880
 So there's a standard Python interface, the gem environment,

194
00:10:40,880 --> 00:10:43,720
 which asks you to define your RL problem--

195
00:10:43,720 --> 00:10:47,320
 not the algorithm, but the problem--

196
00:10:47,320 --> 00:10:50,840
 just by filling in a few simple callbacks.

197
00:10:50,840 --> 00:10:53,480
 You have a basic init method, a step method,

198
00:10:53,480 --> 00:10:56,480
 which takes your action, outputs the observations

199
00:10:56,480 --> 00:10:58,520
 at the next step, advances your simulator,

200
00:10:58,520 --> 00:11:02,480
 however you want to do that, a basic reset method, something

201
00:11:02,480 --> 00:11:04,760
 to render just for the human or for making

202
00:11:04,760 --> 00:11:08,880
 videos, which could be separate from the observations.

203
00:11:08,880 --> 00:11:11,880
 These are all, of course, very analogous to the things

204
00:11:11,880 --> 00:11:14,200
 we have been using in Drake.

205
00:11:14,200 --> 00:11:17,160
 This picture is not so different than a sort of systems

206
00:11:17,160 --> 00:11:19,520
 view of the world.

207
00:11:19,520 --> 00:11:21,280
 So every one of those things has sort

208
00:11:21,280 --> 00:11:24,440
 of an analogy in the tools we've been using.

209
00:11:24,440 --> 00:11:28,400
 We have-- we put our diagram builder inside the init,

210
00:11:28,400 --> 00:11:29,480
 and our--

211
00:11:29,480 --> 00:11:32,160
 not just the diagram, but the simulator.

212
00:11:32,160 --> 00:11:37,200
 Our step function is equivalent to advance to in Drake speak,

213
00:11:37,200 --> 00:11:42,280
 but it also has to return the evaluated observation,

214
00:11:42,280 --> 00:11:45,400
 the evaluated reward.

215
00:11:45,400 --> 00:11:49,400
 Reset just means start over, create a new context, probably

216
00:11:49,400 --> 00:11:53,200
 a random context, actually.

217
00:11:53,200 --> 00:11:55,040
 And those sort of all--

218
00:11:55,040 --> 00:11:55,920
 I think it's pretty--

219
00:11:55,920 --> 00:11:58,520
 this is what's been great about the OpenAI gem,

220
00:11:58,520 --> 00:12:04,880
 is that this is asks very little of the interface,

221
00:12:04,880 --> 00:12:06,840
 and it's very easy to populate, whether it's

222
00:12:06,840 --> 00:12:09,840
 from a game engine or from an Atari game,

223
00:12:09,840 --> 00:12:12,520
 or all kinds of problems are easy to sort

224
00:12:12,520 --> 00:12:15,800
 of cast in that framework.

225
00:12:15,800 --> 00:12:18,360
 But I also think it's very telling, maybe,

226
00:12:18,360 --> 00:12:21,320
 to think about just the difference, the different sort

227
00:12:21,320 --> 00:12:21,920
 of view.

228
00:12:21,920 --> 00:12:23,920
 And maybe it's one of the best ways

229
00:12:23,920 --> 00:12:29,720
 to express my mixed feelings about RL,

230
00:12:29,720 --> 00:12:33,320
 is that this picture of the world

231
00:12:33,320 --> 00:12:39,840
 is general enough to be used for everything.

232
00:12:39,840 --> 00:12:45,560
 And that API, you can put sort of anything behind it.

233
00:12:45,560 --> 00:12:48,920
 But if you contrast that with sort of the Drake systems

234
00:12:48,920 --> 00:12:50,640
 framework that I've been advocating,

235
00:12:50,640 --> 00:12:55,920
 where the goal in Drake has been to expose everything,

236
00:12:55,920 --> 00:12:58,760
 not to bottle up everything.

237
00:12:58,760 --> 00:13:01,180
 I mean, this is really a sort of a philosophical difference.

238
00:13:01,180 --> 00:13:06,240
 And it's not clear if one's better or worse yet, right?

239
00:13:06,240 --> 00:13:08,040
 But there's a philosophical difference,

240
00:13:08,040 --> 00:13:12,680
 where I believe that the systems are very structured.

241
00:13:12,680 --> 00:13:14,400
 I think our mechanics is very structured.

242
00:13:14,400 --> 00:13:16,680
 I think our controllers are very structured.

243
00:13:16,680 --> 00:13:18,760
 I think you should do everything in your power

244
00:13:18,760 --> 00:13:21,640
 to express that structure in a clean way,

245
00:13:21,640 --> 00:13:23,800
 and allow your algorithms to dig in and exploit

246
00:13:23,800 --> 00:13:30,840
 the structure when they can, and make that as glass box,

247
00:13:30,840 --> 00:13:33,120
 clear box as possible.

248
00:13:33,120 --> 00:13:36,400
 And the RL approach is more general,

249
00:13:36,400 --> 00:13:38,840
 but it's weaker in the sense that it doesn't ask

250
00:13:38,840 --> 00:13:40,200
 you to declare those things.

251
00:13:40,200 --> 00:13:42,280
 It only assumes a black box.

252
00:13:42,280 --> 00:13:45,120
 And that's a philosophical difference.

253
00:13:45,120 --> 00:13:48,800
 And so I actually, this week, have

254
00:13:48,800 --> 00:13:52,000
 been trying to make sure there's a nice interface available

255
00:13:52,000 --> 00:13:52,880
 for you to--

256
00:13:52,880 --> 00:13:55,480
 if you have a Drake system, you can use the open AI tools

257
00:13:55,480 --> 00:13:56,880
 and things like this.

258
00:13:56,880 --> 00:13:58,520
 So it's easy to go back and forth,

259
00:13:58,520 --> 00:14:01,360
 and I'll show you that in a second.

260
00:14:01,360 --> 00:14:04,560
 But it sort of pains me to do it.

261
00:14:04,560 --> 00:14:07,480
 I mean, of course, I want to be able to enable both.

262
00:14:07,480 --> 00:14:12,160
 But I feel like we've tried to expose

263
00:14:12,160 --> 00:14:13,560
 all this beautiful structure, write

264
00:14:13,560 --> 00:14:16,280
 all the diagrams and all the systems in a way that's

265
00:14:16,280 --> 00:14:18,680
 sort of like, if they're convex, they're convex, whatever.

266
00:14:18,680 --> 00:14:20,480
 And then it's kind of like, we're

267
00:14:20,480 --> 00:14:22,720
 going to let you look at them through a little drinking

268
00:14:22,720 --> 00:14:25,640
 straw in order to do the algorithms.

269
00:14:25,640 --> 00:14:28,400
 And it's not leveraging the extra work that

270
00:14:28,400 --> 00:14:30,920
 has happened behind the scenes.

271
00:14:30,920 --> 00:14:34,000
 So I would say that's the only--

272
00:14:34,000 --> 00:14:35,160
 I actually love--

273
00:14:35,160 --> 00:14:36,760
 I do really like RL.

274
00:14:36,760 --> 00:14:40,960
 I think RL is clearly the most exciting thing that's

275
00:14:40,960 --> 00:14:42,400
 happening, I think, right now.

276
00:14:42,400 --> 00:14:45,720
 It's generating the most excitement right now.

277
00:14:45,720 --> 00:14:48,640
 And even my thesis-- that's what this funny slide was before--

278
00:14:48,640 --> 00:14:50,320
 my thesis was actually in RL, right?

279
00:14:50,320 --> 00:14:54,560
 So this was in 2003, probably, this one,

280
00:14:54,560 --> 00:14:56,840
 where I was in building E25, back when

281
00:14:56,840 --> 00:14:59,560
 the neuroscientists were in E25.

282
00:14:59,560 --> 00:15:03,280
 And because I was in a neuroscience lab

283
00:15:03,280 --> 00:15:04,960
 and I was trying to build robots,

284
00:15:04,960 --> 00:15:09,640
 I had to bring a CD rack shelf from home.

285
00:15:09,640 --> 00:15:11,800
 And someone needed a piece of rubber,

286
00:15:11,800 --> 00:15:13,880
 so I only had one piece of rubber.

287
00:15:13,880 --> 00:15:15,760
 I was working on a shoestring budget,

288
00:15:15,760 --> 00:15:17,800
 but this is a little walking robot

289
00:15:17,800 --> 00:15:18,920
 that just fell down a ramp.

290
00:15:18,920 --> 00:15:21,400
 There's no motors, no RL there.

291
00:15:21,400 --> 00:15:23,400
 And then my thesis was about making

292
00:15:23,400 --> 00:15:26,800
 a robot do RL in the wild, sort of,

293
00:15:26,800 --> 00:15:29,360
 and learn it quickly to learn how to walk.

294
00:15:29,360 --> 00:15:33,600
 And this was the actuated version of that simple robot.

295
00:15:33,600 --> 00:15:35,120
 And I spent a lot of hours watching

296
00:15:35,120 --> 00:15:39,720
 that thing do gradient descent with kind of a--

297
00:15:39,720 --> 00:15:42,060
 you're trying to write your thesis and you're hearing--

298
00:15:42,060 --> 00:15:44,280
 [TAPPING]

299
00:15:44,280 --> 00:15:45,880
 Everyone's over here.

300
00:15:45,880 --> 00:15:50,960
 But no, I mean, this was defining for me

301
00:15:50,960 --> 00:15:56,040
 to think about what you could do with online learning.

302
00:15:56,040 --> 00:16:00,080
 And I think-- and even in my job talk,

303
00:16:00,080 --> 00:16:01,280
 to get the job at--

304
00:16:01,280 --> 00:16:03,760
 when I went around giving my faculty candidate talks,

305
00:16:03,760 --> 00:16:07,680
 I was saying, even if we could solve the optimal control

306
00:16:07,680 --> 00:16:10,000
 problem perfectly for humanoid robots,

307
00:16:10,000 --> 00:16:11,880
 you would still need online learning

308
00:16:11,880 --> 00:16:13,400
 to adapt to all the changes that are

309
00:16:13,400 --> 00:16:14,600
 going to happen in the world.

310
00:16:14,600 --> 00:16:16,320
 And I still believe that.

311
00:16:16,320 --> 00:16:16,800
 OK.

312
00:16:16,800 --> 00:16:19,480
 So this little robot basically fell down a ramp

313
00:16:19,480 --> 00:16:22,000
 because of the mechanical design,

314
00:16:22,000 --> 00:16:25,440
 but then it learned how to walk using RL.

315
00:16:25,440 --> 00:16:28,080
 That was doing policy gradient-based--

316
00:16:28,080 --> 00:16:30,960
 actually, an actor-critic-based algorithm

317
00:16:30,960 --> 00:16:34,160
 that was learning to walk in real time.

318
00:16:34,160 --> 00:16:36,240
 It took only a few minutes to learn how to walk

319
00:16:36,240 --> 00:16:38,160
 because the design put it in a space

320
00:16:38,160 --> 00:16:43,240
 where it could tune only a very small policy at that time.

321
00:16:43,240 --> 00:16:44,600
 And it would adapt on the fly.

322
00:16:44,600 --> 00:16:47,360
 As it walked around, this was--

323
00:16:47,360 --> 00:16:49,160
 walking from E25 towards the Media Lab

324
00:16:49,160 --> 00:16:50,540
 was like the crowning achievement

325
00:16:50,540 --> 00:16:53,120
 because it wasn't a very big robot.

326
00:16:53,120 --> 00:16:58,720
 And right around that time when they were shooting that video,

327
00:16:58,720 --> 00:17:02,160
 Marvin Minsky walked by.

328
00:17:02,160 --> 00:17:04,440
 And he looked down at the robot, and he

329
00:17:04,440 --> 00:17:06,760
 looked at the camera crew that was behind the robot.

330
00:17:06,760 --> 00:17:11,000
 He's like, I think the camera is more impressive than the robot.

331
00:17:11,000 --> 00:17:13,240
 And I cried myself to sleep that night,

332
00:17:13,240 --> 00:17:17,440
 but I was still proud of the robot.

333
00:17:17,440 --> 00:17:19,040
 Anyway, so this was defining for me.

334
00:17:19,040 --> 00:17:23,760
 I really think a lot about RL, but I

335
00:17:23,760 --> 00:17:28,880
 think that there is a fundamental sample complexity

336
00:17:28,880 --> 00:17:30,720
 issue in the amount of training data

337
00:17:30,720 --> 00:17:32,760
 that you need to do the types of algorithms

338
00:17:32,760 --> 00:17:34,400
 we'll talk about today.

339
00:17:34,400 --> 00:17:36,520
 And so I have been trying to contribute

340
00:17:36,520 --> 00:17:39,640
 to trying to exploit the structure in the equations

341
00:17:39,640 --> 00:17:41,520
 more.

342
00:17:41,520 --> 00:17:43,280
 OK, so there's this OpenAI gem.

343
00:17:43,280 --> 00:17:44,080
 It exists.

344
00:17:44,080 --> 00:17:47,400
 I think you can use anything that's

345
00:17:47,400 --> 00:17:53,620
 sort of a system in Drake can be a system in OpenAI gem.

346
00:17:53,620 --> 00:17:56,440
 And similarly, you could take any OpenAI gem system

347
00:17:56,440 --> 00:17:57,400
 and use it in Drake.

348
00:17:57,400 --> 00:17:59,000
 You just won't be able to use all

349
00:17:59,000 --> 00:18:01,600
 of the gradient and other features in Drake

350
00:18:01,600 --> 00:18:03,800
 if you do that.

351
00:18:03,800 --> 00:18:05,600
 So I made this Drake gem.

352
00:18:05,600 --> 00:18:11,920
 Many people have done Drake wrappers around exposing

353
00:18:11,920 --> 00:18:14,400
 the gem interface around Drake, but I tried to make one

354
00:18:14,400 --> 00:18:18,640
 that you could build off of for your projects if you want this.

355
00:18:18,640 --> 00:18:22,640
 So it just goes through and defines all of those carefully.

356
00:18:22,640 --> 00:18:26,960
 It's actually-- I think it's important to do it right.

357
00:18:26,960 --> 00:18:29,360
 I mean, there's sort of right ways

358
00:18:29,360 --> 00:18:32,920
 to reinitialize the simulator to get everything seeded properly

359
00:18:32,920 --> 00:18:34,520
 off a single random seed and the like,

360
00:18:34,520 --> 00:18:37,080
 but it's all very easy to do.

361
00:18:37,080 --> 00:18:38,660
 So that's available if people want it.

362
00:18:38,660 --> 00:18:48,080
 OK, and like I said, back in the day-- so the OpenAI gem

363
00:18:48,080 --> 00:18:50,160
 is for the environments.

364
00:18:50,160 --> 00:18:56,280
 And this has been relatively convergent.

365
00:18:56,280 --> 00:19:01,120
 Most people are using the AI gem interface for some time now.

366
00:19:01,120 --> 00:19:07,240
 But for the algorithms, there are

367
00:19:07,240 --> 00:19:09,840
 lots of good tools out there.

368
00:19:09,840 --> 00:19:12,640
 And I'd say they're even more mature this year.

369
00:19:12,640 --> 00:19:17,080
 So the one that I will be using in the notes

370
00:19:17,080 --> 00:19:21,120
 as I write them up this week is the stable baselines

371
00:19:21,120 --> 00:19:22,000
 3 as an example.

372
00:19:31,080 --> 00:19:33,240
 We're using PyTorch in the class.

373
00:19:33,240 --> 00:19:34,960
 It uses PyTorch.

374
00:19:34,960 --> 00:19:37,800
 Some of the other baselines algorithms

375
00:19:37,800 --> 00:19:40,240
 are still using TensorFlow, and so harder for me

376
00:19:40,240 --> 00:19:43,660
 to use alongside the notes without having

377
00:19:43,660 --> 00:19:45,560
 more dependencies and the like.

378
00:19:45,560 --> 00:19:49,520
 It's got a lot of the famous algorithms implemented.

379
00:19:49,520 --> 00:19:53,040
 It strikes me that this isn't the best advertisement.

380
00:19:53,040 --> 00:19:55,800
 The particular lots of red that they put here

381
00:19:55,800 --> 00:19:59,160
 is a little scary, but there's still some good check marks.

382
00:19:59,160 --> 00:20:00,960
 And it's honest, right?

383
00:20:00,960 --> 00:20:02,500
 But there are a lot of the algorithms

384
00:20:02,500 --> 00:20:05,160
 that work for a lot of cases.

385
00:20:05,160 --> 00:20:10,400
 So this has got many of the RL algorithms.

386
00:20:10,400 --> 00:20:18,280
 I guess I already wrote algorithms.

387
00:20:18,280 --> 00:20:20,920
 And then there's one other tool that I think is incredibly

388
00:20:20,920 --> 00:20:25,920
 good that we've used a bunch, which is this NeverGrad tool.

389
00:20:25,920 --> 00:20:27,240
 Now my slides are not quite--

390
00:20:28,160 --> 00:20:32,080
 for some of the black box optimization,

391
00:20:32,080 --> 00:20:35,800
 which is not purely RL.

392
00:20:35,800 --> 00:20:37,440
 It's for a broader view of this.

393
00:20:37,440 --> 00:20:40,840
 NeverGrad has a bunch of good algorithms,

394
00:20:40,840 --> 00:20:41,760
 and we'll use that too.

395
00:20:41,760 --> 00:20:51,160
 NeverGrad meaning no gradients for black box optimization.

396
00:20:51,160 --> 00:20:54,620
 [TYPING]

397
00:20:54,620 --> 00:21:13,040
 OK, so let's dig in and talk a little bit

398
00:21:13,040 --> 00:21:18,320
 about the implications of black box optimization

399
00:21:18,320 --> 00:21:23,320
 and why it's good and why it's expensive in some ways.

400
00:21:23,320 --> 00:21:23,820
 OK?

401
00:21:23,820 --> 00:21:43,360
 OK, so I've been advocating many times

402
00:21:43,360 --> 00:21:46,480
 to think about our manipulation problems

403
00:21:46,480 --> 00:21:48,360
 through the lens of optimization.

404
00:21:48,360 --> 00:21:55,840
 The general form of that is something like this, right?

405
00:21:55,840 --> 00:22:04,040
 In many cases, many algorithms we've used,

406
00:22:04,040 --> 00:22:08,600
 like the solvers in SNOPT or if you've

407
00:22:08,600 --> 00:22:14,760
 used any of our MOSEC or Girobi sort of tools,

408
00:22:14,760 --> 00:22:23,800
 exploit some structure in f and g.

409
00:22:23,800 --> 00:22:29,880
 The weakest form, the sort of SNOPT

410
00:22:29,880 --> 00:22:32,560
 or the general nonlinear optimization,

411
00:22:32,560 --> 00:22:34,600
 maybe it's just asking for the gradients.

412
00:22:34,600 --> 00:22:43,560
 Some of the more advanced algorithms

413
00:22:43,560 --> 00:22:45,760
 from MOSEC and Girobi will ask if you

414
00:22:45,760 --> 00:22:47,680
 can say that this is quadratic or it's

415
00:22:47,680 --> 00:22:50,440
 convex in some structured convex form.

416
00:22:50,440 --> 00:22:52,360
 It's similar for these constraints

417
00:22:52,360 --> 00:22:54,320
 to be a convex set.

418
00:22:54,320 --> 00:22:59,960
 Then you can level even more advanced algorithms at it.

419
00:22:59,960 --> 00:23:05,760
 So what we're going to go to today is just a simpler form.

420
00:23:05,760 --> 00:23:10,560
 We're going to minimize f of x and assume almost nothing.

421
00:23:10,560 --> 00:23:13,960
 [WRITING ON BOARD]

422
00:23:13,960 --> 00:23:18,300
 About f.

423
00:23:18,300 --> 00:23:25,720
 We're not even going to assume it's a-- we'll

424
00:23:25,720 --> 00:23:28,400
 start off by assuming f is even a deterministic function,

425
00:23:28,400 --> 00:23:30,980
 but there's going to be versions of this where you won't even

426
00:23:30,980 --> 00:23:33,060
 assume that you get the same answer every time you

427
00:23:33,060 --> 00:23:34,760
 put an x in.

428
00:23:34,760 --> 00:23:38,440
 So when I think of this as a black box,

429
00:23:38,440 --> 00:23:42,480
 I'm saying that I give you an x, you give me f of x out,

430
00:23:42,480 --> 00:23:43,120
 and that's it.

431
00:23:43,120 --> 00:23:45,080
 I don't get to ask any more detailed questions.

432
00:23:45,080 --> 00:23:51,800
 Don't get to know anything about what's

433
00:23:51,800 --> 00:23:53,160
 happening behind the scenes.

434
00:23:53,160 --> 00:23:56,120
 It could be calling a game engine.

435
00:23:56,120 --> 00:23:59,680
 It could be playing Go.

436
00:23:59,680 --> 00:24:02,600
 Doesn't matter.

437
00:24:02,600 --> 00:24:11,080
 OK, so in this view of the world-- I'm

438
00:24:11,080 --> 00:24:16,120
 going to erase that just to stay on the same boards here.

439
00:24:16,120 --> 00:24:19,160
 In this view of the world, we had some really nice algorithms.

440
00:24:19,160 --> 00:24:33,360
 So for instance, if I had some complicated optimization

441
00:24:33,360 --> 00:24:37,640
 problem, the simplest versions would be gradient descent.

442
00:24:37,640 --> 00:24:43,160
 I get a point here.

443
00:24:43,160 --> 00:24:44,540
 I start moving down the landscape.

444
00:24:44,540 --> 00:24:53,020
 We talked about sort of Newton-like or quasi-Newton

445
00:24:53,020 --> 00:25:04,820
 algorithms or the quadratic programming

446
00:25:04,820 --> 00:25:06,780
 generalization of that, sequential quadratic

447
00:25:06,780 --> 00:25:10,780
 programming, which maybe if I have a sample point here, what

448
00:25:10,780 --> 00:25:14,260
 I would do would be use some of the gradient information

449
00:25:14,260 --> 00:25:20,060
 to make a local quadratic approximation of the function,

450
00:25:20,060 --> 00:25:23,700
 jump right down to the minimum, get a new sample point,

451
00:25:23,700 --> 00:25:27,580
 jump right down, and eventually converge on the minimum.

452
00:25:27,580 --> 00:25:33,500
 So if I tell you now that you can assume almost nothing

453
00:25:33,500 --> 00:25:38,860
 about f, we don't actually even want to assume it's smooth,

454
00:25:38,860 --> 00:25:42,260
 but I think our pictures will indicate it's smooth for now,

455
00:25:42,260 --> 00:25:45,940
 just to get our head around the problem.

456
00:25:45,940 --> 00:25:51,100
 Then what kind of optimization are you left with?

457
00:25:51,100 --> 00:25:53,780
 I mean, in a one-dimensional board example,

458
00:25:53,780 --> 00:25:56,300
 you could just sample until you find a good solution

459
00:25:56,300 --> 00:25:57,980
 and be done.

460
00:25:57,980 --> 00:26:00,820
 But in high dimensions, we're thinking that's probably not--

461
00:26:00,820 --> 00:26:03,320
 it's harder to draw, but it's important to think about this

462
00:26:03,320 --> 00:26:06,460
 as sort of a high-dimensional object.

463
00:26:06,460 --> 00:26:10,700
 And just trying every point until you find a good one,

464
00:26:10,700 --> 00:26:12,700
 brute force search isn't going to get the job done.

465
00:26:12,700 --> 00:26:18,900
 So how do you do something like gradient-based optimization

466
00:26:18,900 --> 00:26:22,340
 when you only have a black box?

467
00:26:22,340 --> 00:26:26,500
 And you can imagine that almost most of the ideas over here

468
00:26:26,500 --> 00:26:29,380
 have sort of a sampling-based analogy.

469
00:26:29,380 --> 00:26:29,880
 Right?

470
00:26:29,880 --> 00:26:54,220
 Which is, in many ways, not so different than what

471
00:26:54,220 --> 00:26:57,460
 we talked about with kinematic trajectory optimization

472
00:26:57,460 --> 00:26:58,940
 versus sample-based motion planning.

473
00:26:58,940 --> 00:27:02,020
 There's actually a lot of nice parallels

474
00:27:02,020 --> 00:27:07,180
 between those two worlds and the two worlds we're doing today.

475
00:27:07,180 --> 00:27:12,020
 But maybe the simplest algorithm,

476
00:27:12,020 --> 00:27:15,260
 gradient-like algorithm, would be if I take my random sample.

477
00:27:15,260 --> 00:27:18,660
 [WRITING ON BOARD]

478
00:27:18,660 --> 00:27:32,900
 Perturb it by some amount.

479
00:27:32,900 --> 00:27:38,180
 So let's say I have my guess that the i-th step is xi.

480
00:27:38,180 --> 00:27:44,460
 You have f of xi.

481
00:27:44,460 --> 00:27:47,300
 Try to go ahead and evaluate f of xi

482
00:27:47,300 --> 00:27:49,540
 plus some small perturbation.

483
00:27:49,540 --> 00:27:54,180
 So I'll make a little perturbation here, w.

484
00:27:54,180 --> 00:28:01,620
 I'll get a different point.

485
00:28:01,620 --> 00:28:05,460
 Maybe that's just drawn from some Gaussian.

486
00:28:05,460 --> 00:28:09,300
 I'll just make a small random change to my parameters, w,

487
00:28:09,300 --> 00:28:10,420
 in some direction.

488
00:28:10,420 --> 00:28:11,920
 And the simplest algorithm, I think,

489
00:28:11,920 --> 00:28:16,900
 would just be to say, if this value is less than this value,

490
00:28:16,900 --> 00:28:17,740
 keep it.

491
00:28:17,740 --> 00:28:19,260
 Use that as my new point.

492
00:28:19,260 --> 00:28:22,820
 And then we'll wash, rinse, and repeat.

493
00:28:22,820 --> 00:28:24,740
 If it went uphill, discard it.

494
00:28:24,740 --> 00:28:31,580
 Maybe a slightly more refined version of that

495
00:28:31,580 --> 00:28:37,100
 could be to say that I will move in the direction of this point

496
00:28:37,100 --> 00:28:41,740
 proportional to the reward I got, the relative reward.

497
00:28:41,740 --> 00:28:43,640
 So if this looked a lot better, I'll

498
00:28:43,640 --> 00:28:46,800
 move aggressively in the direction of that sample point.

499
00:28:46,800 --> 00:28:50,560
 And maybe even if it went up, I could move somehow

500
00:28:50,560 --> 00:28:52,940
 in the opposite direction based on this.

501
00:28:52,940 --> 00:29:00,500
 So there's a sort of a first order

502
00:29:00,500 --> 00:29:01,600
 sample-based approximation.

503
00:29:01,600 --> 00:29:02,100
 OK.

504
00:29:02,100 --> 00:29:18,280
 But there's also-- you can imagine second order methods

505
00:29:18,280 --> 00:29:22,840
 or richer methods that are doing sort of the same thing.

506
00:29:22,840 --> 00:29:27,200
 I'm highly positive about the SQP style optimization.

507
00:29:27,200 --> 00:29:30,240
 I think it's a very powerful, fast, converging

508
00:29:30,240 --> 00:29:31,880
 set of algorithms.

509
00:29:31,880 --> 00:29:35,520
 And you could imagine taking my initial sample point

510
00:29:35,520 --> 00:29:37,760
 and taking lots of random samples.

511
00:29:37,760 --> 00:29:43,840
 Again, the picture is not fully expressive in 2D on the board.

512
00:29:43,840 --> 00:29:46,320
 But you can imagine trying to take lots of samples

513
00:29:46,320 --> 00:29:47,840
 around here.

514
00:29:47,840 --> 00:29:50,920
 Maybe I explore broadly.

515
00:29:50,920 --> 00:29:54,560
 And then fit a-- I almost said covariance,

516
00:29:54,560 --> 00:29:56,520
 but let's call it a quadratic.

517
00:29:56,520 --> 00:30:08,720
 Fit a quadratic, fit to samples, and then

518
00:30:08,720 --> 00:30:11,880
 do sort of something like a quasi-Newton descent.

519
00:30:25,160 --> 00:30:30,120
 OK, and this turns out to be a very powerful class

520
00:30:30,120 --> 00:30:32,400
 of algorithms, this general idea of trying

521
00:30:32,400 --> 00:30:36,800
 to use samples to approximate some

522
00:30:36,800 --> 00:30:38,800
 of the other types of algorithms that we like.

523
00:30:38,800 --> 00:30:43,640
 There are other considerations, too,

524
00:30:43,640 --> 00:30:47,400
 that make sampling a nice choice.

525
00:30:47,400 --> 00:30:47,900
 Right?

526
00:30:48,040 --> 00:30:51,520
 [SIPPING]

527
00:30:51,520 --> 00:31:15,020
 All right.

528
00:31:15,020 --> 00:31:20,300
 So let's just think for a minute about what's

529
00:31:20,300 --> 00:31:23,300
 the relative merits of a sampling-based approach

530
00:31:23,300 --> 00:31:27,780
 versus the exact gradient-based approach.

531
00:31:27,780 --> 00:31:34,180
 I mean, first of all, the sampling only requires--

532
00:31:34,180 --> 00:31:42,980
 that's easy, right?

533
00:31:42,980 --> 00:31:44,380
 f of x.

534
00:31:44,380 --> 00:31:47,780
 Doesn't require the actual gradient.

535
00:31:47,780 --> 00:31:57,260
 I think there's a question of how expensive is evaluating

536
00:31:57,260 --> 00:32:02,380
 f of x versus partial f of x if you have it.

537
00:32:02,380 --> 00:32:07,220
 That's definitely a consideration.

538
00:32:10,780 --> 00:32:16,100
 Sometimes it can be so much faster to implement--

539
00:32:16,100 --> 00:32:19,580
 if taking gradients is quite slow,

540
00:32:19,580 --> 00:32:21,740
 then it might actually be better to just run f

541
00:32:21,740 --> 00:32:23,300
 a bunch of times separately.

542
00:32:23,300 --> 00:32:29,100
 I remember Mo Todorov going back and forth with this from Majoko.

543
00:32:29,100 --> 00:32:31,060
 He was like-- one day I would talk to him.

544
00:32:31,060 --> 00:32:32,660
 He's like, oh, yeah, I wrote all the analytical gradients.

545
00:32:32,660 --> 00:32:35,180
 And then he's like, oh, no, I realized this is just faster.

546
00:32:35,180 --> 00:32:36,140
 Because I could put it on a GPU.

547
00:32:36,140 --> 00:32:37,300
 And he went back and forth.

548
00:32:37,300 --> 00:32:40,500
 So there was a time where he had all the analytical gradients.

549
00:32:40,500 --> 00:32:42,340
 And I think he's mostly gotten rid of them.

550
00:32:42,340 --> 00:32:48,180
 Another sort of important consideration,

551
00:32:48,180 --> 00:32:52,060
 like how many GPUs--

552
00:32:52,060 --> 00:32:53,260
 how big is your GPU, right?

553
00:32:53,260 --> 00:33:10,180
 How many threads, how many GPUs?

554
00:33:10,180 --> 00:33:12,660
 Because doing lots of samples of f

555
00:33:12,660 --> 00:33:15,340
 can be sort of trivially parallelized.

556
00:33:15,340 --> 00:33:21,820
 And if that is expensive but not as expensive as--

557
00:33:21,820 --> 00:33:23,620
 if it's free to make this in parallel,

558
00:33:23,620 --> 00:33:27,100
 then maybe it's cheaper, again, than the partial f partial x.

559
00:33:27,100 --> 00:33:28,100
 And that's a big one.

560
00:33:28,100 --> 00:33:30,820
 I think the success of these methods

561
00:33:30,820 --> 00:33:32,620
 is tied, I think, very closely with the fact

562
00:33:32,620 --> 00:33:34,540
 that we've got good GPUs and the like now.

563
00:33:40,020 --> 00:33:42,020
 But there is more subtle reasons that I really

564
00:33:42,020 --> 00:33:47,900
 want to think about, more, I think, robustness reasons.

565
00:33:47,900 --> 00:34:05,140
 So what if your cost function looks like something like this?

566
00:34:06,060 --> 00:34:06,560
 Right?

567
00:34:06,560 --> 00:34:18,780
 Right?

568
00:34:18,780 --> 00:34:24,260
 If there's a lot of sort of local, noisy structure

569
00:34:24,260 --> 00:34:26,060
 that happens in your optimization.

570
00:34:26,060 --> 00:34:28,500
 OK?

571
00:34:28,500 --> 00:34:31,780
 The gradient is a beautiful object, of course.

572
00:34:31,780 --> 00:34:34,340
 But it's-- for better or for worse,

573
00:34:34,340 --> 00:34:36,780
 it's an extremely local object.

574
00:34:36,780 --> 00:34:38,380
 If I happen to sample this point,

575
00:34:38,380 --> 00:34:39,940
 I might get instantaneously a gradient

576
00:34:39,940 --> 00:34:41,940
 that looks like that just because

577
00:34:41,940 --> 00:34:46,500
 of the high frequency components of my landscape.

578
00:34:46,500 --> 00:34:49,140
 And that could be a very poor representation of what I

579
00:34:49,140 --> 00:34:52,940
 actually-- the direction I actually want to move in.

580
00:34:52,940 --> 00:34:57,420
 So I think there is some robustness in actually

581
00:34:57,420 --> 00:34:59,780
 taking multiple samples.

582
00:34:59,780 --> 00:35:02,820
 Of course, it could still be susceptible to noisy

583
00:35:02,820 --> 00:35:07,820
 evaluations, but somehow the sampling-based thing

584
00:35:07,820 --> 00:35:12,380
 can potentially power through some noisy--

585
00:35:12,380 --> 00:35:14,300
 locally noisy observations.

586
00:35:14,300 --> 00:35:22,740
 So I think there's a very deep question that I don't

587
00:35:22,740 --> 00:35:24,060
 have an answer for you for.

588
00:35:24,060 --> 00:35:26,420
 I've seen examples that look a lot like this.

589
00:35:26,420 --> 00:35:27,940
 And I've seen examples that look more

590
00:35:27,940 --> 00:35:30,620
 like those simple pictures coming out of manipulation.

591
00:35:30,620 --> 00:35:32,740
 But I think there's a deep question, which

592
00:35:32,740 --> 00:35:36,460
 is, do our manipulation problems look like this or not?

593
00:35:36,460 --> 00:35:39,020
 Do the problems we care about solving and control,

594
00:35:39,020 --> 00:35:40,780
 more generally, look like this or not?

595
00:35:40,780 --> 00:35:46,660
 I think for the low-dimensional problems where

596
00:35:46,660 --> 00:35:49,540
 it's easy to plot these things, I don't worry too much

597
00:35:49,540 --> 00:35:50,300
 that it does.

598
00:35:50,300 --> 00:35:53,540
 But in the higher-dimensional, much richer sort of contact

599
00:35:53,540 --> 00:35:55,580
 kind of configurations, it's hard to know.

600
00:35:55,580 --> 00:35:57,180
 It's hard to know what those look like.

601
00:35:57,180 --> 00:35:59,460
 Like I said, I've seen examples where we're like, oh,

602
00:35:59,460 --> 00:36:00,900
 clearly the performance of our algorithm

603
00:36:00,900 --> 00:36:02,700
 is suffering because of something like this.

604
00:36:02,700 --> 00:36:05,660
 And then you plot them, and they're actually pretty smooth.

605
00:36:05,660 --> 00:36:08,820
 I think that there's other examples like people

606
00:36:08,820 --> 00:36:13,420
 tend to use these sampling-based methods sometimes

607
00:36:13,420 --> 00:36:17,540
 to optimize neural network-based models.

608
00:36:17,540 --> 00:36:19,540
 And so you think, well, maybe the neural network

609
00:36:19,540 --> 00:36:21,260
 is capturing the function correctly,

610
00:36:21,260 --> 00:36:23,380
 but it's locally not very smooth.

611
00:36:23,380 --> 00:36:26,620
 And I think that is probably true in some cases.

612
00:36:26,620 --> 00:36:29,380
 But we've seen other cases where we do our best to visualize

613
00:36:29,380 --> 00:36:30,820
 them, and they look pretty smooth.

614
00:36:30,820 --> 00:36:31,320
 Yes?

615
00:36:31,320 --> 00:36:32,780
 For higher-dimensional problems,

616
00:36:32,780 --> 00:36:35,740
 how do you check whether it's a normal shape or more

617
00:36:35,740 --> 00:36:37,700
 like a 2D shape?

618
00:36:37,700 --> 00:36:38,260
 Good question.

619
00:36:38,260 --> 00:36:41,860
 So when I say we've checked sometimes

620
00:36:41,860 --> 00:36:43,660
 and have looked at this in higher dimensions,

621
00:36:43,660 --> 00:36:45,500
 what do you do?

622
00:36:45,500 --> 00:36:47,940
 The tools are not as strong as I would like.

623
00:36:47,940 --> 00:36:51,460
 But a standard heuristic would be take your sample point,

624
00:36:51,460 --> 00:36:54,460
 pick a random direction, and make a 2D plot.

625
00:36:54,460 --> 00:36:56,140
 And if you do that a few times, you

626
00:36:56,140 --> 00:36:59,100
 can sort of convince yourself of the local shape,

627
00:36:59,100 --> 00:37:03,560
 even if you can't say anything rigorously about it.

628
00:37:03,560 --> 00:37:10,540
 I think in general, the sense of taking small probes

629
00:37:10,540 --> 00:37:12,160
 into the neural network, for instance.

630
00:37:12,160 --> 00:37:15,880
 And as a follow-up to that, is it common for the whole function

631
00:37:15,880 --> 00:37:18,840
 to have a similar level of local minima?

632
00:37:18,840 --> 00:37:21,120
 Or is it possible that it's just pockets

633
00:37:21,120 --> 00:37:22,840
 and really simply 2D?

634
00:37:22,840 --> 00:37:23,440
 Yeah, OK.

635
00:37:23,440 --> 00:37:26,160
 So the question is, do you expect

636
00:37:26,160 --> 00:37:28,200
 to see this uniformly everywhere,

637
00:37:28,200 --> 00:37:30,480
 like this high-frequency stuff, or just in pockets?

638
00:37:30,480 --> 00:37:32,480
 I think it's completely problem-dependent.

639
00:37:32,480 --> 00:37:36,320
 And I would suspect, in a lot of our manipulation formulations,

640
00:37:36,320 --> 00:37:38,800
 if I've got a huge swath of parameter space

641
00:37:38,800 --> 00:37:40,960
 where I don't even touch an object,

642
00:37:40,960 --> 00:37:43,680
 and then there's some parts where

643
00:37:43,680 --> 00:37:45,400
 the detailed mechanics are coming in

644
00:37:45,400 --> 00:37:47,800
 and it's much more complicated, that it's probably

645
00:37:47,800 --> 00:37:51,040
 going to be smooth sailing but maybe uninformative

646
00:37:51,040 --> 00:37:53,380
 for a lot of places, and then a lot of activity

647
00:37:53,380 --> 00:37:54,640
 in other places.

648
00:37:54,640 --> 00:37:56,320
 I would definitely think that's true,

649
00:37:56,320 --> 00:37:59,200
 which makes it hard to set global learning rate

650
00:37:59,200 --> 00:38:00,200
 parameters and the like.

651
00:38:00,200 --> 00:38:15,440
 So this is, I think, a very important point.

652
00:38:15,440 --> 00:38:17,160
 And I really do think that this number

653
00:38:17,160 --> 00:38:21,600
 of parallel executions is a very important point, too.

654
00:38:21,600 --> 00:38:26,440
 But of course, the most naive version

655
00:38:26,440 --> 00:38:29,160
 of this, of a sampling algorithm,

656
00:38:29,160 --> 00:38:31,040
 would say that every time I want to make

657
00:38:31,040 --> 00:38:33,760
 a local approximation of my gradient,

658
00:38:33,760 --> 00:38:37,880
 I'll take n samples, where n is the dimensionality

659
00:38:37,880 --> 00:38:39,440
 of my parameter space.

660
00:38:39,440 --> 00:38:40,920
 So basically, I'll change--

661
00:38:40,920 --> 00:38:45,560
 I'll perturb the decision variables

662
00:38:45,560 --> 00:38:48,240
 in every possible direction at least once.

663
00:38:48,240 --> 00:38:51,800
 That'd be like a finite difference type method.

664
00:38:51,800 --> 00:38:53,600
 And if you're doing that, then you'd

665
00:38:53,600 --> 00:38:56,560
 expect potentially the number of possible evaluations

666
00:38:56,560 --> 00:38:59,320
 that you have to do in f, in parallel,

667
00:38:59,320 --> 00:39:03,120
 to grow very badly if your number of x's

668
00:39:03,120 --> 00:39:05,280
 is like the weights of a neural network.

669
00:39:05,280 --> 00:39:08,400
 You would expect that to start getting bad.

670
00:39:08,400 --> 00:39:10,720
 So there's ways to try to fight against that.

671
00:39:10,720 --> 00:39:15,960
 And then the question is, do you have a super good gradient

672
00:39:15,960 --> 00:39:16,960
 based--

673
00:39:16,960 --> 00:39:20,000
 for neural networks, we do have very good gradient algorithms.

674
00:39:20,000 --> 00:39:22,240
 So these two do fight each other.

675
00:39:22,240 --> 00:39:24,800
 And they fight each other in interesting ways

676
00:39:24,800 --> 00:39:26,120
 as the dimensionality goes high.

677
00:39:26,120 --> 00:39:33,880
 Now, there's another name for these sort of black box

678
00:39:33,880 --> 00:39:39,440
 sampling based algorithms, which for a while

679
00:39:39,440 --> 00:39:45,320
 was sort of a bad thing, a bad word, or something like that.

680
00:39:45,320 --> 00:39:45,880
 I don't know.

681
00:39:45,880 --> 00:39:47,960
 But these are really the genetic algorithms.

682
00:39:47,960 --> 00:39:55,600
 They were not as popular before, or swarm-based optimization,

683
00:39:55,600 --> 00:39:56,100
 let's say.

684
00:39:56,100 --> 00:40:07,200
 But I think, like I said, because of the ability

685
00:40:07,200 --> 00:40:08,740
 to do these things in parallel, and I

686
00:40:08,740 --> 00:40:11,200
 think because of these nice robustness properties,

687
00:40:11,200 --> 00:40:14,000
 they've come back into fashion.

688
00:40:14,000 --> 00:40:19,600
 So the one that is most similar to this picture

689
00:40:19,600 --> 00:40:23,760
 that I said of trying to make a local quadratic approximation

690
00:40:23,760 --> 00:40:29,840
 of my data and then doing a quasi-Newton update

691
00:40:29,840 --> 00:40:31,520
 is an algorithm called CMAES.

692
00:40:31,520 --> 00:40:39,040
 I mean, all these algorithms are pretty similar.

693
00:40:39,040 --> 00:40:42,040
 There's many algorithms that are small variations

694
00:40:42,040 --> 00:40:43,200
 on each other.

695
00:40:43,200 --> 00:40:45,600
 So cross-entropy methods are pretty similar to this, too.

696
00:40:45,600 --> 00:40:48,440
 But I'll highlight CMAES here.

697
00:40:48,440 --> 00:40:56,560
 So CMA stands for covariant matrix adaptation.

698
00:40:56,560 --> 00:41:09,120
 It's often with an ES, evolutionary strategy.

699
00:41:09,120 --> 00:41:09,620
 OK.

700
00:41:09,620 --> 00:41:22,240
 As we've said before, the probabilistic interpretation

701
00:41:22,240 --> 00:41:24,600
 would be that you're trying to fit the covariance

702
00:41:24,600 --> 00:41:27,160
 matrix of a Gaussian kernel.

703
00:41:27,160 --> 00:41:29,960
 But that's the same as fitting a quadratic form

704
00:41:29,960 --> 00:41:32,680
 for a quasi-Newton method.

705
00:41:32,680 --> 00:41:34,960
 And this is just sort of a picture

706
00:41:35,080 --> 00:41:39,480
 if you actually do try to do a simple optimization,

707
00:41:39,480 --> 00:41:42,680
 if you're on a simple quadratic landscape

708
00:41:42,680 --> 00:41:44,880
 and you start with a swarm of particles,

709
00:41:44,880 --> 00:41:50,240
 you'd expect the-- in fact, in the simple case of it

710
00:41:50,240 --> 00:41:52,960
 being a quadratic, you actually expect

711
00:41:52,960 --> 00:41:58,680
 that the local covariance matrix approximation will indeed

712
00:41:58,680 --> 00:42:01,400
 reproduce the Hessian of the quadratic form.

713
00:42:01,400 --> 00:42:05,480
 So it's an accurate second order approximation

714
00:42:05,480 --> 00:42:09,360
 of the quadratic form.

715
00:42:09,360 --> 00:42:11,640
 You get a new covariance matrix.

716
00:42:11,640 --> 00:42:13,280
 You have a new Gaussian to sample from,

717
00:42:13,280 --> 00:42:15,440
 which tells you where I should draw samples

718
00:42:15,440 --> 00:42:18,680
 on the next update, wash, rinse, and repeat.

719
00:42:18,680 --> 00:42:20,920
 And it will converge to some local--

720
00:42:20,920 --> 00:42:24,800
 there's an additional scheduling and other sort of heuristics

721
00:42:24,800 --> 00:42:27,920
 inside there about the path that it takes

722
00:42:27,920 --> 00:42:30,440
 given these approximations.

723
00:42:30,440 --> 00:42:31,880
 But roughly, it's what we say.

724
00:42:31,880 --> 00:42:33,240
 It's a quasi-Newton method that's

725
00:42:33,240 --> 00:42:36,760
 trying to use swarms of particles

726
00:42:36,760 --> 00:42:41,040
 to estimate the local curvature and move down the hill.

727
00:42:41,040 --> 00:42:47,880
 Is that clear?

728
00:42:47,880 --> 00:42:54,040
 There's another feature of these algorithms

729
00:42:54,040 --> 00:42:59,320
 that I think is important, often sort of mixed in

730
00:42:59,320 --> 00:43:01,080
 with this local convergence analysis.

731
00:43:01,080 --> 00:43:03,920
 So in a quadratic form, you can really sort of focus in

732
00:43:03,920 --> 00:43:05,160
 on the convergence rate.

733
00:43:05,160 --> 00:43:07,120
 You can talk about all the things we would like

734
00:43:07,120 --> 00:43:08,540
 to talk about with gradient descent

735
00:43:08,540 --> 00:43:10,000
 or other optimization algorithms.

736
00:43:10,000 --> 00:43:12,980
 You can talk-- it's just converging to a local minima.

737
00:43:12,980 --> 00:43:14,840
 If you're in the vicinity of a local minima,

738
00:43:14,840 --> 00:43:18,280
 you'd like it to behave roughly like this.

739
00:43:18,280 --> 00:43:28,280
 But there's also some sort of global aspect

740
00:43:28,280 --> 00:43:40,080
 to the sampling-based algorithms,

741
00:43:40,080 --> 00:43:46,800
 some sort of global optimization interpretation.

742
00:43:46,800 --> 00:43:50,760
 And this is, I think, harder to appreciate rigorously.

743
00:43:50,760 --> 00:43:57,520
 Even in my simple picture, where I've--

744
00:43:57,520 --> 00:44:01,680
 if I were to do even the completely deterministic

745
00:44:01,680 --> 00:44:04,920
 quadratic approximation of my Hessian

746
00:44:04,920 --> 00:44:08,120
 and make a quasi-Newton update, it could be--

747
00:44:08,120 --> 00:44:10,680
 if I'm sorry to be a screw over here--

748
00:44:10,680 --> 00:44:12,520
 it could be that as I'm walking down here,

749
00:44:12,520 --> 00:44:17,080
 I get a quasi-Newton step that jumps me all the way across

750
00:44:17,080 --> 00:44:19,680
 and finds this better local minima.

751
00:44:19,680 --> 00:44:21,120
 That can absolutely-- it can even

752
00:44:21,120 --> 00:44:23,800
 happen with gradient descent if I'm taking big steps.

753
00:44:23,800 --> 00:44:26,520
 But it's maybe more likely to happen in a quasi-Newton

754
00:44:26,520 --> 00:44:28,480
 algorithm, which is intentionally taking

755
00:44:28,480 --> 00:44:30,040
 potentially very big steps.

756
00:44:30,040 --> 00:44:33,360
 It could have gotten lucky and gotten here.

757
00:44:33,360 --> 00:44:36,680
 That can absolutely happen for the same reason

758
00:44:36,680 --> 00:44:41,600
 in the evolutionary algorithms, in the CMA-style algorithms.

759
00:44:41,600 --> 00:44:45,280
 But these algorithms, because they're doing samples,

760
00:44:45,280 --> 00:44:48,200
 will often have some extra layers of heuristics

761
00:44:48,200 --> 00:44:51,040
 that try to add a global aspect to their optimization.

762
00:44:51,040 --> 00:44:54,800
 They'll cast off far-ranging samples, maybe, for instance,

763
00:44:54,800 --> 00:44:57,160
 and just explore.

764
00:44:57,160 --> 00:45:01,080
 It costs little to throw out a few Hail Marys out there

765
00:45:01,080 --> 00:45:05,160
 to see if they can find another possible minima.

766
00:45:05,160 --> 00:45:09,240
 And so they do tend to have a more global success.

767
00:45:09,240 --> 00:45:13,440
 I'd say they can find global optima in a stronger way

768
00:45:13,440 --> 00:45:16,480
 than a method that's dedicated itself

769
00:45:16,480 --> 00:45:20,160
 to myopically looking at the local curvature.

770
00:45:20,160 --> 00:45:24,080
 So there's, I think, a somewhat confusing but important

771
00:45:24,080 --> 00:45:28,480
 global optimization aspect to the sample-based planning

772
00:45:28,480 --> 00:45:29,960
 algorithms.

773
00:45:29,960 --> 00:45:32,400
 And I think there's a big discussion about,

774
00:45:32,400 --> 00:45:34,560
 should we be using these algorithms

775
00:45:34,560 --> 00:45:36,760
 to do planning with a neural network or whatever?

776
00:45:36,760 --> 00:45:39,840
 And I think there's a, why does it work?

777
00:45:39,840 --> 00:45:41,680
 I often see people going back and forth

778
00:45:41,680 --> 00:45:44,200
 between these kind of justifications,

779
00:45:44,200 --> 00:45:47,040
 the parallel execution type of justifications,

780
00:45:47,040 --> 00:45:48,520
 the global optimization aspect.

781
00:45:48,520 --> 00:45:52,040
 They're all mixed together in some way.

782
00:45:52,040 --> 00:45:54,840
 But if you put them all together, this has now

783
00:45:54,840 --> 00:45:58,760
 come back into fashion as a good set of algorithms to use.

784
00:45:58,760 --> 00:46:19,280
 Just to say that one more possible way,

785
00:46:19,280 --> 00:46:25,720
 if I have a gradient descent type algorithm that's

786
00:46:25,720 --> 00:46:28,040
 using local gradients, we said that there's--

787
00:46:28,040 --> 00:46:30,880
 I'm just trying to be like I'm a vehicle flying

788
00:46:30,880 --> 00:46:33,960
 around some obstacles and going from the start to the goal,

789
00:46:33,960 --> 00:46:35,620
 or I'm reaching around some obstacle,

790
00:46:35,620 --> 00:46:40,320
 and this is the current path that I'm considering,

791
00:46:40,320 --> 00:46:42,800
 it seems very unlikely with gradient-based methods

792
00:46:42,800 --> 00:46:47,200
 that it'll suddenly find a completely different solution.

793
00:46:47,200 --> 00:46:48,720
 That's the same picture.

794
00:46:48,720 --> 00:46:51,240
 This is just a geometric version of the same picture,

795
00:46:51,240 --> 00:46:54,240
 but in a trajectory optimization sort of case,

796
00:46:54,240 --> 00:46:56,800
 you really don't expect gradient descent, any information

797
00:46:56,800 --> 00:46:58,720
 over here, to ever tell you to jump over here.

798
00:46:58,720 --> 00:47:00,320
 Because at some point, you're going

799
00:47:00,320 --> 00:47:03,240
 to do worse for a long time before you get better

800
00:47:03,240 --> 00:47:05,280
 and go to the other side.

801
00:47:05,280 --> 00:47:09,320
 And I think these algorithms will occasionally

802
00:47:09,320 --> 00:47:14,480
 send flyers out there and find an ultimately better solution

803
00:47:14,480 --> 00:47:16,920
 in ways that you don't expect your gradient-based methods

804
00:47:16,920 --> 00:47:20,600
 to do.

805
00:47:20,600 --> 00:47:21,320
 Yeah, of course.

806
00:47:21,320 --> 00:47:23,040
 Would you expect an algorithm of this type

807
00:47:23,040 --> 00:47:25,400
 to be more robust to--

808
00:47:25,400 --> 00:47:28,040
 I'm imagining a case where you are

809
00:47:28,040 --> 00:47:29,600
 trying to optimize the policy, and it

810
00:47:29,600 --> 00:47:32,440
 finds a very deep but very shallow or very narrow

811
00:47:32,440 --> 00:47:33,280
 optimum.

812
00:47:33,280 --> 00:47:35,320
 But then if you try to run that on a real robot,

813
00:47:35,320 --> 00:47:37,440
 the odds that actually you think that's going to be

814
00:47:37,440 --> 00:47:38,320
 [INAUDIBLE]

815
00:47:38,320 --> 00:47:40,440
 Would an algorithm like this be more robust

816
00:47:40,440 --> 00:47:42,840
 to find an optimum like that?

817
00:47:42,840 --> 00:47:43,560
 Awesome question.

818
00:47:43,800 --> 00:47:47,040
 So the question was, what if I have these sort of landscapes

819
00:47:47,040 --> 00:47:52,960
 that maybe have a small, narrow optimization?

820
00:47:52,960 --> 00:47:55,440
 I mean, you could do the same thing where you could have

821
00:47:55,440 --> 00:48:00,120
 a narrow local minima that's maybe a trap, for instance.

822
00:48:00,120 --> 00:48:03,480
 That's not the one you want to end up in.

823
00:48:03,480 --> 00:48:06,560
 I think the case of the good solution being narrow

824
00:48:06,560 --> 00:48:09,120
 is one case, and the case of a suboptimal solution being

825
00:48:09,120 --> 00:48:10,480
 narrow is another case.

826
00:48:10,480 --> 00:48:12,560
 I think these algorithms, they are both

827
00:48:12,560 --> 00:48:17,240
 subject to possibly getting stuck there.

828
00:48:17,240 --> 00:48:20,200
 In practice, the algorithm is just like a learning rate.

829
00:48:20,200 --> 00:48:21,680
 They have a handful of parameters

830
00:48:21,680 --> 00:48:23,160
 that control how much exploration

831
00:48:23,160 --> 00:48:25,640
 versus how fast they converge and how fast they settle.

832
00:48:25,640 --> 00:48:27,640
 And when you feel like your algorithm is getting

833
00:48:27,640 --> 00:48:33,040
 stuck in these, you dial up the heat in a sort of entropy

834
00:48:33,040 --> 00:48:37,120
 kind of way and try to explore a little bit more.

835
00:48:37,120 --> 00:48:39,920
 And you end up finding a balance there.

836
00:48:39,920 --> 00:48:44,640
 But that is, again, very problem specific.

837
00:48:44,640 --> 00:48:47,080
 Did you have some intuition about whether you'd expect one

838
00:48:47,080 --> 00:48:49,360
 to be better or worse than the other?

839
00:48:49,360 --> 00:48:51,840
 My intuition is that if you're sampling,

840
00:48:51,840 --> 00:48:55,240
 then you're more robust because you have a very narrow value

841
00:48:55,240 --> 00:48:56,240
 of good cost.

842
00:48:56,240 --> 00:48:57,240
 Yes.

843
00:48:57,240 --> 00:48:59,240
 And then sampling around the rim of that

844
00:48:59,240 --> 00:49:01,760
 and then ignoring it more.

845
00:49:01,760 --> 00:49:03,520
 Right, so I think what could happen

846
00:49:03,520 --> 00:49:05,560
 with an algorithm like this, he says,

847
00:49:05,560 --> 00:49:07,480
 for the same reason I said, if it's sending out

848
00:49:07,480 --> 00:49:10,240
 flyers, maybe if it starts converging

849
00:49:10,240 --> 00:49:12,400
 with a local quadratic approximation that's

850
00:49:12,400 --> 00:49:16,440
 very narrow in here, then that's where-- at some point,

851
00:49:16,440 --> 00:49:18,080
 it will actually get in convergence mode

852
00:49:18,080 --> 00:49:22,000
 and try to efficiently-- but if it occasionally throws out

853
00:49:22,000 --> 00:49:25,000
 these sort of extra samples, it might

854
00:49:25,000 --> 00:49:27,440
 discover that it's made a mistake and jump out.

855
00:49:27,440 --> 00:49:30,560
 And I agree with you on that.

856
00:49:30,560 --> 00:49:33,720
 But that's going to be subject-- the amount of exploration

857
00:49:33,720 --> 00:49:35,880
 versus exploitation it does is subject to these sort

858
00:49:35,880 --> 00:49:38,480
 of temperature kind of parameters.

859
00:49:38,480 --> 00:49:39,480
 Did you have a question?

860
00:49:39,480 --> 00:49:39,980
 Yeah.

861
00:49:39,980 --> 00:49:41,940
 Yeah, I was wondering what it was like.

862
00:49:41,940 --> 00:49:46,440
 I think I've seen some results that say that it seems to be

863
00:49:46,440 --> 00:49:47,920
 [INAUDIBLE]

864
00:49:47,920 --> 00:49:54,920
 And so is that just a matter of [INAUDIBLE]

865
00:49:54,920 --> 00:49:57,920
 So why is it, for example, using a window or something

866
00:49:57,920 --> 00:49:59,920
 like [INAUDIBLE]

867
00:49:59,920 --> 00:50:03,920
 Yeah, I think-- so there are many variants of it.

868
00:50:03,920 --> 00:50:06,120
 It'd be interesting-- if you have that paper,

869
00:50:06,120 --> 00:50:07,800
 if you want to track down the reference,

870
00:50:07,800 --> 00:50:09,760
 I'd actually be interested in that.

871
00:50:09,760 --> 00:50:10,240
 Yes.

872
00:50:10,240 --> 00:50:13,360
 Some of them keep multiple populations around

873
00:50:13,360 --> 00:50:16,400
 and can be more explicitly multimodal.

874
00:50:16,400 --> 00:50:19,200
 Some of them really do just have more feelers

875
00:50:19,200 --> 00:50:22,600
 out there in some sense.

876
00:50:22,600 --> 00:50:26,520
 But I think the inner loop CMAES is really

877
00:50:26,520 --> 00:50:29,240
 this sort of covariance-- makes local Gaussians

878
00:50:29,240 --> 00:50:33,840
 and will shrink into a minimized necessary.

879
00:50:33,840 --> 00:50:40,360
 The cross-entropy methods, which are, I think, known to some

880
00:50:40,360 --> 00:50:41,920
 of you, are very similar to CMAES.

881
00:50:41,920 --> 00:50:43,000
 They make a slightly different-- they

882
00:50:43,000 --> 00:50:44,280
 take a slightly different path.

883
00:50:44,280 --> 00:50:47,480
 And the way they update their local Hessian approximations

884
00:50:47,480 --> 00:50:48,480
 is slightly different.

885
00:50:48,480 --> 00:50:50,240
 But these are all very similar algorithms.

886
00:50:56,400 --> 00:50:59,600
 So that is a very important first big thing that's

887
00:50:59,600 --> 00:51:04,880
 happening, I think, when you give up on the structure in f,

888
00:51:04,880 --> 00:51:07,040
 you open the door to these algorithms

889
00:51:07,040 --> 00:51:08,320
 making a lot more sense.

890
00:51:08,320 --> 00:51:11,000
 And maybe they make sense even if you have structured f,

891
00:51:11,000 --> 00:51:12,920
 but you just have a really big GPU.

892
00:51:12,920 --> 00:51:19,360
 And that's the way the cost-benefit trade-off falls.

893
00:51:19,360 --> 00:51:22,240
 I'm pretty sure I had the Nevergrad list of solvers

894
00:51:22,240 --> 00:51:22,880
 here, too.

895
00:51:22,880 --> 00:51:26,280
 Nevergrad is a toolbox that just has a bunch of these solvers

896
00:51:26,280 --> 00:51:28,840
 implemented, super easy to use in Python.

897
00:51:28,840 --> 00:51:36,240
 And it's got a whole list of these sort of optimization

898
00:51:36,240 --> 00:51:42,640
 algorithms that are all based on no gradients, hence Nevergrad.

899
00:51:42,640 --> 00:51:44,240
 I think it's a very--

900
00:51:44,240 --> 00:51:48,080
 I have no qualms recommending this as a tool to play with.

901
00:51:48,080 --> 00:51:49,320
 We've used it often.

902
00:51:49,320 --> 00:52:03,960
 So I think that's the first sort of major shift in thinking.

903
00:52:03,960 --> 00:52:07,360
 Well, I should say one thing we didn't talk about yet

904
00:52:07,360 --> 00:52:10,760
 is when I went from the left side of the board

905
00:52:10,760 --> 00:52:16,480
 to the right side of the board, I dropped my constraints.

906
00:52:16,480 --> 00:52:23,360
 So that is an important thing that I left out.

907
00:52:23,360 --> 00:52:28,120
 I think that the structured solvers I've always advocated

908
00:52:28,120 --> 00:52:37,320
 using fairly simple objectives and rich constraints.

909
00:52:37,320 --> 00:52:42,560
 That's, I think, a much more robust way to sort of live.

910
00:52:42,560 --> 00:52:45,520
 [LAUGHS]

911
00:52:45,520 --> 00:53:03,760
 I've always said, keep this simple.

912
00:53:08,400 --> 00:53:13,480
 In our kinematic optimization, our IK problems, for instance,

913
00:53:13,480 --> 00:53:17,720
 I was just saying, just do Q minus desired squared,

914
00:53:17,720 --> 00:53:18,880
 something like this.

915
00:53:18,880 --> 00:53:24,560
 Keep that simple, and then add all your rich constraints.

916
00:53:24,560 --> 00:53:26,120
 Not everybody agrees with me on that,

917
00:53:26,120 --> 00:53:30,440
 but I've seen lots of people go down--

918
00:53:30,440 --> 00:53:32,680
 so spend a lot of time tuning cost functions

919
00:53:32,680 --> 00:53:34,600
 when everything's up in the cost function.

920
00:53:34,600 --> 00:53:39,280
 And the constraints are just, I think, a much more--

921
00:53:39,280 --> 00:53:43,200
 it's a stronger way to say what you actually require,

922
00:53:43,200 --> 00:53:44,840
 and then a lot of the tuning goes away.

923
00:53:44,840 --> 00:53:52,520
 Nevergrande explicitly says you can only do--

924
00:53:52,520 --> 00:53:57,120
 it's actually better than many sort of sample-based methods.

925
00:53:57,120 --> 00:53:59,400
 But it says, we're only going to let

926
00:53:59,400 --> 00:54:03,720
 you give us computationally very cheap constraints.

927
00:54:03,720 --> 00:54:05,380
 It's like, the method is actually, like,

928
00:54:05,380 --> 00:54:08,000
 add cheap constraints to your solver,

929
00:54:08,000 --> 00:54:11,200
 because the only thing it will do is do rejection sampling.

930
00:54:11,200 --> 00:54:14,680
 So if it's walking around and you give it an x,

931
00:54:14,680 --> 00:54:15,960
 it'll just evaluate g.

932
00:54:15,960 --> 00:54:17,160
 If it's less than--

933
00:54:17,160 --> 00:54:20,080
 if it violates the constraints, it throws that sample out.

934
00:54:20,080 --> 00:54:22,240
 That's the only method of constraint reasoning

935
00:54:22,240 --> 00:54:24,960
 that these solvers typically do.

936
00:54:24,960 --> 00:54:26,840
 And there is not--

937
00:54:26,840 --> 00:54:28,840
 these algorithms do not typically

938
00:54:28,840 --> 00:54:32,160
 embrace the rich constraints.

939
00:54:32,160 --> 00:54:35,560
 You end up playing the game where you say,

940
00:54:35,560 --> 00:54:38,480
 I'm going to minimize f of x plus, like,

941
00:54:38,480 --> 00:54:42,880
 lambda times g of x, for instance.

942
00:54:42,880 --> 00:54:46,760
 I want g of x, maybe minus, or something,

943
00:54:46,760 --> 00:54:48,520
 whatever my sign should be.

944
00:54:48,520 --> 00:54:54,920
 And you start putting a penalty approximation

945
00:54:54,920 --> 00:54:56,440
 of a true constraint.

946
00:54:56,440 --> 00:55:06,640
 I guess I do want that to be plus.

947
00:55:06,640 --> 00:55:09,720
 And there are good ways to schedule this,

948
00:55:09,720 --> 00:55:11,640
 that penalty parameter.

949
00:55:11,640 --> 00:55:14,400
 But it becomes a harder game, because really, what you're

950
00:55:14,400 --> 00:55:17,120
 doing is something that looks a lot more like this.

951
00:55:17,120 --> 00:55:25,760
 And you've got lots of knobs to tune,

952
00:55:25,760 --> 00:55:28,960
 and they all kind of compete.

953
00:55:28,960 --> 00:55:32,840
 Some people worry a lot about RL not embracing

954
00:55:32,840 --> 00:55:34,880
 the full constraint view of the world

955
00:55:34,880 --> 00:55:37,640
 and being only in this jam everything

956
00:55:37,640 --> 00:55:39,240
 into the cost function.

957
00:55:39,240 --> 00:55:41,640
 Some people think it's not a big deal.

958
00:55:41,640 --> 00:55:43,600
 I'm somewhere in the middle, I'd say.

959
00:55:43,600 --> 00:55:53,920
 Let's talk about, I think, another essential aspect,

960
00:55:53,920 --> 00:55:56,240
 which goes together with the black box optimization.

961
00:55:56,240 --> 00:56:01,600
 By virtue of feeling like we're going to do sampling anyways,

962
00:56:01,600 --> 00:56:07,720
 it's natural to couple that with stochastic formulations

963
00:56:07,720 --> 00:56:09,000
 of the optimal control problem.

964
00:56:09,000 --> 00:56:15,560
 Yeah, sure.

965
00:56:15,560 --> 00:56:34,000
 [INAUDIBLE]

966
00:56:34,000 --> 00:56:36,480
 In terms of the black box solvers?

967
00:56:36,480 --> 00:56:37,600
 So I'll repeat the question.

968
00:56:37,600 --> 00:56:43,960
 So it's certainly true that you can take any optimization

969
00:56:43,960 --> 00:56:50,400
 problem here, and I could write that as s f of x less than

970
00:56:50,400 --> 00:56:54,320
 or equal to s g of x less than or equal to 0.

971
00:56:54,320 --> 00:56:56,600
 You just try to push down on s.

972
00:56:56,600 --> 00:57:01,440
 This is a scalar, and then maybe you have to--

973
00:57:01,440 --> 00:57:02,800
 so those are equivalent.

974
00:57:02,800 --> 00:57:04,960
 But that's putting things more from the objective

975
00:57:04,960 --> 00:57:07,360
 down into the constraint, not going the other way, right?

976
00:57:07,360 --> 00:57:09,360
 Yeah.

977
00:57:09,360 --> 00:57:14,960
 [INAUDIBLE]

978
00:57:14,960 --> 00:57:17,520
 OK, so you're not worried about the penalty method.

979
00:57:17,520 --> 00:57:19,200
 You're just worried about the basic statement about-- yeah,

980
00:57:19,200 --> 00:57:19,700
 yeah.

981
00:57:19,700 --> 00:57:30,880
 Yeah, I think these ways do not embrace

982
00:57:30,880 --> 00:57:32,760
 what I'm trying to say here.

983
00:57:32,760 --> 00:57:36,360
 You can hide your objective, of course, in the constraints.

984
00:57:36,360 --> 00:57:37,720
 I mean, this comes down, I think,

985
00:57:37,720 --> 00:57:39,800
 to what your solver likes, whether you prefer

986
00:57:39,800 --> 00:57:42,000
 to write it like this or prefer to write it like this.

987
00:57:42,000 --> 00:57:44,880
 And some solvers do actually really like this.

988
00:57:44,880 --> 00:57:48,080
 Many times, they require you to-- a lot of the convex

989
00:57:48,080 --> 00:57:51,040
 solvers you know require you to write it like this in order

990
00:57:51,040 --> 00:57:53,160
 to write something as a semi-definite--

991
00:57:53,160 --> 00:57:54,840
 if you have a quadratic objective

992
00:57:54,840 --> 00:57:56,040
 in a semi-definite program, then you

993
00:57:56,040 --> 00:57:59,920
 have to do something like this, for instance.

994
00:57:59,920 --> 00:58:04,280
 But I think this is more of a--

995
00:58:04,280 --> 00:58:10,800
 you could defeat this heuristic by writing constraints

996
00:58:10,800 --> 00:58:14,360
 in such a way that you had a very simple cost function,

997
00:58:14,360 --> 00:58:16,400
 and you still jammed all your penalties and stuff

998
00:58:16,400 --> 00:58:17,160
 in the constraints.

999
00:58:17,160 --> 00:58:18,120
 That's not what I mean.

1000
00:58:18,120 --> 00:58:22,920
 I'm saying, if you don't want to collide with the mug,

1001
00:58:22,920 --> 00:58:26,200
 say you don't want to collide with the mugs, not say,

1002
00:58:26,200 --> 00:58:30,880
 well, I'd be kind of sad if I collided a bit with the mug.

1003
00:58:30,880 --> 00:58:34,120
 I think this is a stronger thing to tell the solver.

1004
00:58:34,120 --> 00:58:35,080
 That's a good question.

1005
00:58:35,080 --> 00:58:43,040
 Another really big important thing

1006
00:58:43,040 --> 00:58:50,920
 is this sort of stochastic formulation of control.

1007
00:58:55,360 --> 00:58:58,720
 So stochastic optimal control is as old as optimal control.

1008
00:58:58,720 --> 00:58:59,800
 It's not an RL thing.

1009
00:58:59,800 --> 00:59:09,200
 But RL has embraced those formulations.

1010
00:59:09,200 --> 00:59:12,600
 And let me just try to--

1011
00:59:12,600 --> 00:59:15,800
 I'd say I think this is inspired in RL probably first

1012
00:59:15,800 --> 00:59:16,920
 by the practical, right?

1013
00:59:21,680 --> 00:59:26,120
 On a real robot, frankly, I mean,

1014
00:59:26,120 --> 00:59:28,160
 even if you think of your robot as a black box

1015
00:59:28,160 --> 00:59:31,160
 that you can set your control parameters,

1016
00:59:31,160 --> 00:59:33,800
 run an experiment, measure the outcome,

1017
00:59:33,800 --> 00:59:36,000
 wash, rinse, and repeat, you can never

1018
00:59:36,000 --> 00:59:37,360
 run the same experiment twice.

1019
00:59:37,360 --> 00:59:44,520
 I was acutely aware of that during my thesis.

1020
00:59:44,520 --> 00:59:46,360
 It was very hard to get the same--

1021
00:59:46,360 --> 00:59:48,520
 the robot to be the same initial conditions.

1022
00:59:49,520 --> 00:59:54,200
 It was very hard to get repeatable data,

1023
00:59:54,200 --> 00:59:55,560
 even in the load regime.

1024
00:59:55,560 --> 00:59:57,520
 This is what experimental science is all about.

1025
00:59:57,520 --> 01:00:08,280
 I've had a little bit of--

1026
01:00:08,280 --> 01:00:10,200
 I've had some really, really good collaborators

1027
01:00:10,200 --> 01:00:12,120
 in experimental fluid dynamics.

1028
01:00:12,120 --> 01:00:13,640
 And the amount of effort that they

1029
01:00:13,640 --> 01:00:18,320
 put into making experiments as repeatable as possible.

1030
01:00:18,320 --> 01:00:20,960
 I can only imagine what the condensed matter

1031
01:00:20,960 --> 01:00:22,560
 folks do and the like, right?

1032
01:00:22,560 --> 01:00:25,360
 And the roboticists just don't do that.

1033
01:00:25,360 --> 01:00:28,760
 You just expect every time I run the robot,

1034
01:00:28,760 --> 01:00:29,880
 it's going to be different.

1035
01:00:29,880 --> 01:00:31,280
 My actuator's heated up.

1036
01:00:31,280 --> 01:00:33,280
 I didn't put it in the same initial conditions.

1037
01:00:33,280 --> 01:00:36,280
 It stepped on a pebble this time, whatever it is, right?

1038
01:00:36,280 --> 01:00:39,520
 And I think we've just embraced it in RL more than in most

1039
01:00:39,520 --> 01:00:41,040
 other cases.

1040
01:00:41,040 --> 01:00:43,760
 So let's think about what the implication for that is, right?

1041
01:00:43,760 --> 01:00:47,480
 So how would I write this in the simplest

1042
01:00:47,480 --> 01:00:50,200
 form of a stochastic optimization?

1043
01:00:50,200 --> 01:00:53,240
 So I wrote min of x, f of x before.

1044
01:00:53,240 --> 01:00:57,680
 But now if f of x is some sort of random evaluation,

1045
01:00:57,680 --> 01:01:00,080
 there's a couple different ways I could write that.

1046
01:01:00,080 --> 01:01:01,800
 I'll choose to write it like this.

1047
01:01:01,800 --> 01:01:06,240
 I'll make the randomness explicit.

1048
01:01:06,240 --> 01:01:11,520
 So w is, for instance, drawn from some random distribution.

1049
01:01:11,520 --> 01:01:14,160
 It doesn't have to be Gaussian, but let's just say--

1050
01:01:14,160 --> 01:01:17,640
 make that explicit.

1051
01:01:17,640 --> 01:01:22,680
 And if w is a random variable and f depends on w,

1052
01:01:22,680 --> 01:01:26,640
 then my cost is a random variable also.

1053
01:01:26,640 --> 01:01:28,080
 I need to take the expected value.

1054
01:01:28,080 --> 01:01:31,520
 I need to take some statistic of that random variable

1055
01:01:31,520 --> 01:01:33,480
 in order to make a scalar cost.

1056
01:01:33,480 --> 01:01:34,940
 And this is the one we almost always

1057
01:01:34,940 --> 01:01:37,440
 choose in stochastic optimal control,

1058
01:01:37,440 --> 01:01:40,240
 because the expected value plays well with the additive cost

1059
01:01:40,240 --> 01:01:42,200
 formulations.

1060
01:01:42,200 --> 01:01:44,560
 And this is very consistent with what

1061
01:01:44,560 --> 01:01:48,840
 I've said before about the modeling choices in the systems

1062
01:01:48,840 --> 01:01:56,840
 framework, where we very explicitly--

1063
01:01:56,840 --> 01:01:58,800
 and throughout robust control, I'd

1064
01:01:58,800 --> 01:02:01,040
 say you'll see pictures that look like this, where

1065
01:02:01,040 --> 01:02:04,160
 you have your control inputs coming in here,

1066
01:02:04,160 --> 01:02:10,200
 and you have an explicit disturbance

1067
01:02:10,200 --> 01:02:11,520
 port, or something like this.

1068
01:02:11,520 --> 01:02:17,240
 Disturbance input.

1069
01:02:17,240 --> 01:02:23,000
 So don't call rand in the middle of your plant dynamics function.

1070
01:02:23,000 --> 01:02:24,360
 Make it very explicit.

1071
01:02:24,360 --> 01:02:26,640
 And then you can start thinking about it more carefully

1072
01:02:26,640 --> 01:02:27,140
 like this.

1073
01:02:27,140 --> 01:02:35,880
 Stochastic optimal control is a more specific version

1074
01:02:35,880 --> 01:02:38,760
 of this big picture, where I know

1075
01:02:38,760 --> 01:02:40,200
 that I have a dynamical system.

1076
01:02:40,200 --> 01:02:42,760
 So this f is actually a rollout of a long-term dynamical

1077
01:02:42,760 --> 01:02:44,080
 system.

1078
01:02:44,080 --> 01:02:52,800
 So stochastic optimal control is just

1079
01:02:52,800 --> 01:02:57,840
 narrowing in on the stochastic optimization problem, where

1080
01:02:57,840 --> 01:03:00,200
 I want to maybe minimize over, let's say,

1081
01:03:00,200 --> 01:03:12,040
 my policy of my controller now of some long-term cost that's

1082
01:03:12,040 --> 01:03:13,200
 over time.

1083
01:03:13,200 --> 01:03:14,740
 So I'll just write it out like this.

1084
01:03:14,740 --> 01:03:43,980
 [WRITING ON BOARD]

1085
01:03:43,980 --> 01:03:45,540
 And probably I have to choose where

1086
01:03:45,540 --> 01:03:48,060
 I want the randomness to come in.

1087
01:03:48,060 --> 01:03:50,620
 There's a couple different choices.

1088
01:03:50,620 --> 01:03:55,460
 It might be that there's randomness in the dynamics.

1089
01:03:55,460 --> 01:03:57,660
 We'll see that there's going to be choices we make,

1090
01:03:57,660 --> 01:04:01,580
 where we might add randomness explicitly to the policy.

1091
01:04:01,580 --> 01:04:08,100
 But we still have a random disturbance input.

1092
01:04:08,100 --> 01:04:09,780
 Random noise or disturbance.

1093
01:04:09,780 --> 01:04:11,660
 And I'll take some expected value over those.

1094
01:04:11,660 --> 01:04:22,140
 [WRITING ON BOARD]

1095
01:04:22,140 --> 01:04:24,900
 So there's a lot of work specific in stochastic optimal

1096
01:04:24,900 --> 01:04:29,220
 control to exploiting this sort of important structure.

1097
01:04:29,220 --> 01:04:31,020
 But let's start by thinking of it

1098
01:04:31,020 --> 01:04:35,340
 just as now a stochastic optimization problem.

1099
01:04:35,340 --> 01:04:42,180
 [WRITING ON BOARD]

1100
01:04:42,180 --> 01:04:45,580
 I mean, there's lots of places that people put in randomness

1101
01:04:45,580 --> 01:04:50,060
 in our actual manipulation RL experiments.

1102
01:04:50,060 --> 01:04:54,420
 So you can name them, I'm sure.

1103
01:04:54,420 --> 01:04:58,660
 What are the ones you see in all the videos?

1104
01:04:58,660 --> 01:05:01,340
 Like, what are the crazy things people do to add randomness

1105
01:05:01,340 --> 01:05:04,260
 to the simulations?

1106
01:05:04,260 --> 01:05:04,940
 Yeah.

1107
01:05:04,940 --> 01:05:05,440
 OK, good.

1108
01:05:05,440 --> 01:05:07,140
 So you get the random disturbances

1109
01:05:07,140 --> 01:05:08,220
 where you're jamming something.

1110
01:05:08,220 --> 01:05:08,720
 Yeah?

1111
01:05:08,720 --> 01:05:11,580
 [INAUDIBLE]

1112
01:05:11,580 --> 01:05:12,660
 Yeah, right.

1113
01:05:12,660 --> 01:05:17,460
 So the robot's getting hit from all sides.

1114
01:05:17,460 --> 01:05:19,820
 I mean, in Boston Dynamics, I guess they actually

1115
01:05:19,820 --> 01:05:20,460
 do it for real.

1116
01:05:20,460 --> 01:05:23,260
 Yeah.

1117
01:05:23,260 --> 01:05:27,180
 I mean, I think the one that I always laugh at

1118
01:05:27,180 --> 01:05:30,340
 is the domain randomization, where

1119
01:05:30,340 --> 01:05:34,140
 they will put the most ridiculous patterns

1120
01:05:34,140 --> 01:05:38,540
 for the vision, for robustness in the perception system.

1121
01:05:38,540 --> 01:05:40,540
 The fact that you might have an elephant

1122
01:05:40,540 --> 01:05:44,060
 on the side of your coffee mug or something like that,

1123
01:05:44,060 --> 01:05:46,700
 or a giraffe or whatever, just cracks me up.

1124
01:05:46,700 --> 01:05:53,300
 But these can all be interpreted in some squinty way

1125
01:05:53,300 --> 01:05:55,900
 as adding some sort of randomness, random parameters

1126
01:05:55,900 --> 01:05:57,300
 to my system.

1127
01:05:57,300 --> 01:06:03,740
 If I'm allowing w to be an entire rich signal,

1128
01:06:03,740 --> 01:06:05,460
 it would be fine if it's just a constant.

1129
01:06:05,460 --> 01:06:06,860
 That would still fit in the class.

1130
01:06:06,860 --> 01:06:14,180
 OK, so let's think through how it changes the optimization

1131
01:06:14,180 --> 01:06:17,340
 problem to now have these stochastic objectives.

1132
01:06:17,340 --> 01:06:30,340
 And as a thought experiment, imagine

1133
01:06:30,340 --> 01:06:34,940
 I've got some manipuland on the table

1134
01:06:34,940 --> 01:06:38,220
 here that I'm trying to pick up.

1135
01:06:38,220 --> 01:06:39,380
 Something on the table here.

1136
01:06:39,380 --> 01:06:44,620
 I've got my shunk coming down from above.

1137
01:06:57,980 --> 01:07:00,900
 Let me just consider, so I can plot things,

1138
01:07:00,900 --> 01:07:02,580
 a very simple policy.

1139
01:07:02,580 --> 01:07:18,700
 We'll just move straight down to height alpha,

1140
01:07:18,700 --> 01:07:20,500
 and then close the hand and then lift.

1141
01:07:20,500 --> 01:07:21,000
 Right?

1142
01:07:21,000 --> 01:07:35,620
 And let's say that the cost function, or the reward,

1143
01:07:35,620 --> 01:07:43,260
 is just the height of the center of mass of the object,

1144
01:07:43,260 --> 01:07:46,100
 manipuland.

1145
01:07:46,100 --> 01:07:47,440
 What is that going to look like?

1146
01:07:47,440 --> 01:07:49,880
 [INAUDIBLE]

1147
01:07:49,880 --> 01:08:05,720
 Maybe if I set my height of my controller too low,

1148
01:08:05,720 --> 01:08:09,160
 then maybe I have a collision or something down here.

1149
01:08:09,160 --> 01:08:10,760
 Or maybe I just give a bad score if I

1150
01:08:10,760 --> 01:08:12,640
 have a collision with the hand.

1151
01:08:12,640 --> 01:08:15,560
 [WRITING]

1152
01:08:15,560 --> 01:08:26,160
 And then maybe if I'm too high, the height of the mug

1153
01:08:26,160 --> 01:08:30,760
 is somewhere over here, let's say I don't get any point.

1154
01:08:30,760 --> 01:08:32,880
 I don't get any reward, because the center of mass

1155
01:08:32,880 --> 01:08:33,880
 just stayed where it was.

1156
01:08:33,880 --> 01:08:38,200
 And somewhere in the middle here,

1157
01:08:38,200 --> 01:08:44,120
 I've got a plateau where I've made successful contact

1158
01:08:44,120 --> 01:08:48,960
 with my cylindrical mug, and I lift up.

1159
01:08:48,960 --> 01:08:53,680
 Just a toy example of a kind of reward function

1160
01:08:53,680 --> 01:08:56,640
 that we might get when we have manipulation.

1161
01:08:56,640 --> 01:08:58,520
 We have the possibility of making contact,

1162
01:08:58,520 --> 01:09:02,800
 of colliding dramatically, of completely missing the object.

1163
01:09:02,800 --> 01:09:06,600
 You can often get these sort of pretty ugly--

1164
01:09:06,600 --> 01:09:08,600
 this does not look like these nice pictures

1165
01:09:08,600 --> 01:09:10,160
 that I showed before.

1166
01:09:10,160 --> 01:09:11,620
 It's not the kind of landscape you'd

1167
01:09:11,620 --> 01:09:16,200
 want to do sort of gradient descent on by default.

1168
01:09:16,200 --> 01:09:21,560
 OK, so this is often not the problem

1169
01:09:21,560 --> 01:09:24,480
 that we try to formulate in RL.

1170
01:09:24,480 --> 01:09:29,040
 I'm going to draw giraffes on here and stuff, right?

1171
01:09:29,040 --> 01:09:33,400
 But I'm also probably going to change the shape of the mug,

1172
01:09:33,400 --> 01:09:38,960
 maybe change the initial positions of the hand, right?

1173
01:09:38,960 --> 01:09:42,040
 And that can do good things, right?

1174
01:09:42,040 --> 01:09:50,400
 So if I ended up with even just a richer shaped object, right?

1175
01:09:50,400 --> 01:09:55,200
 Maybe it's a-- I don't know what that is, a chalice, right?

1176
01:09:55,200 --> 01:09:59,140
 Then maybe I've got a slightly better cost function.

1177
01:09:59,140 --> 01:10:01,600
 Maybe I'm still in collision for a bunch of the time,

1178
01:10:01,600 --> 01:10:03,520
 but maybe there's some interesting times

1179
01:10:03,520 --> 01:10:05,080
 where I can grasp successfully.

1180
01:10:05,080 --> 01:10:07,040
 I fail in the middle.

1181
01:10:07,040 --> 01:10:08,280
 I grasp-- I don't know.

1182
01:10:08,280 --> 01:10:10,640
 I could get something by just having a more interesting

1183
01:10:10,640 --> 01:10:11,120
 object.

1184
01:10:11,120 --> 01:10:15,360
 I could potentially have more interesting cost functions,

1185
01:10:15,360 --> 01:10:15,880
 OK?

1186
01:10:15,880 --> 01:10:20,320
 But that doesn't sort of defeat the problem of if I just

1187
01:10:20,320 --> 01:10:23,360
 airball, I've got nothing going on here.

1188
01:10:23,360 --> 01:10:27,440
 Having lots of samples down here,

1189
01:10:27,440 --> 01:10:29,760
 that's just not going to give me any gradient information

1190
01:10:29,760 --> 01:10:31,240
 to base my search on.

1191
01:10:31,240 --> 01:10:32,760
 I've got lots of samples over here.

1192
01:10:32,760 --> 01:10:36,440
 I've got nothing good to do.

1193
01:10:36,440 --> 01:10:43,920
 OK, so it's very interesting to think that-- I mean,

1194
01:10:43,920 --> 01:10:45,520
 you might think that if you're asking

1195
01:10:45,520 --> 01:10:49,000
 the same robot, the same policy, to pick up

1196
01:10:49,000 --> 01:10:52,640
 a whole variety of objects, that that would be a harder

1197
01:10:52,640 --> 01:10:54,740
 optimization problem.

1198
01:10:54,740 --> 01:10:56,200
 I would think that, right?

1199
01:10:56,200 --> 01:10:58,840
 That sounds like a harder optimization problem.

1200
01:10:58,840 --> 01:11:01,640
 Tune a robot to pick up a single object versus pick up

1201
01:11:01,640 --> 01:11:02,960
 an entire category of objects.

1202
01:11:02,960 --> 01:11:05,560
 You'd think that would be a bigger ask.

1203
01:11:05,560 --> 01:11:08,760
 But in sort of a gradient optimization landscape way,

1204
01:11:08,760 --> 01:11:12,000
 it can actually make things better, right?

1205
01:11:12,000 --> 01:11:17,400
 So imagine now that just I have a variety of different-- well,

1206
01:11:17,400 --> 01:11:20,080
 let me even go back to an even simpler example here.

1207
01:11:20,080 --> 01:11:22,200
 So the characteristic I care about here

1208
01:11:22,200 --> 01:11:24,880
 is these rough discontinuities, right?

1209
01:11:24,880 --> 01:11:27,960
 So what about if I just bottle that up

1210
01:11:27,960 --> 01:11:32,200
 and think about a very simple case of this?

1211
01:11:32,200 --> 01:11:35,520
 If I'm just trying to minimize some discontinuous function.

1212
01:11:35,520 --> 01:11:48,520
 This is a function that is 1 if x is greater than 0,

1213
01:11:48,520 --> 01:11:51,200
 negative 1 if x is less than 0.

1214
01:11:51,200 --> 01:11:58,600
 [WRITING ON BOARD]

1215
01:11:58,600 --> 01:12:01,560
 That's a nasty optimization problem for gradients, right?

1216
01:12:01,560 --> 01:12:04,200
 It's also a boring one because I guess

1217
01:12:04,200 --> 01:12:06,160
 there's a lot of uniquely good answers.

1218
01:12:06,160 --> 01:12:08,640
 But just if we think about its gradient-based properties.

1219
01:12:08,640 --> 01:12:16,280
 Randomness can make these problems better.

1220
01:12:16,280 --> 01:12:19,240
 OK, so let's think of a small variation on that,

1221
01:12:19,240 --> 01:12:22,120
 where I want to say min over x now.

1222
01:12:22,120 --> 01:12:23,960
 And I'll add noise in sort of the way

1223
01:12:23,960 --> 01:12:26,120
 I've indicated above here.

1224
01:12:26,120 --> 01:12:29,200
 Let's just say we'll do it like this.

1225
01:12:29,200 --> 01:12:43,440
 What does that optimization do?

1226
01:12:44,400 --> 01:12:44,880
 OK.

1227
01:12:44,880 --> 01:12:56,200
 What does that optimization look like?

1228
01:12:56,200 --> 01:13:00,040
 Yeah.

1229
01:13:00,040 --> 01:13:01,760
 [INAUDIBLE]

1230
01:13:01,760 --> 01:13:04,120
 OK.

1231
01:13:04,120 --> 01:13:07,640
 So what is your intuition for why that is?

1232
01:13:07,640 --> 01:13:10,880
 Because the bigger x is, the smaller w

1233
01:13:10,880 --> 01:13:14,320
 has to be for the sine of x plus w to be possible.

1234
01:13:14,320 --> 01:13:17,240
 So it should be increasing x.

1235
01:13:17,240 --> 01:13:17,740
 OK.

1236
01:13:17,740 --> 01:13:25,320
 So the bigger x is, then this can get smaller.

1237
01:13:25,320 --> 01:13:33,000
 So maybe if I were to plot this, somehow this

1238
01:13:33,000 --> 01:13:37,240
 might be my probability of x plus w.

1239
01:13:40,760 --> 01:13:41,880
 Yeah.

1240
01:13:41,880 --> 01:13:46,080
 And so you're saying that as I make x bigger,

1241
01:13:46,080 --> 01:13:48,280
 then I'm going to get more of my Gaussian on there.

1242
01:13:48,280 --> 01:13:50,520
 And that's exactly the right picture.

1243
01:13:50,520 --> 01:13:54,200
 So what I'll get, I think, I know,

1244
01:13:54,200 --> 01:13:58,480
 is actually a beautiful sort of smooth version

1245
01:13:58,480 --> 01:14:00,920
 of that original function.

1246
01:14:00,920 --> 01:14:04,320
 That Gaussian-- you can think of this Gaussian

1247
01:14:04,320 --> 01:14:07,760
 as actually acting as a smoothing function that

1248
01:14:07,760 --> 01:14:12,920
 goes over your cost landscape and smooths things out.

1249
01:14:12,920 --> 01:14:14,480
 OK.

1250
01:14:14,480 --> 01:14:17,800
 And gradient descent here has a much better chance

1251
01:14:17,800 --> 01:14:19,080
 of doing something interesting.

1252
01:14:19,080 --> 01:14:29,760
 What's super interesting is that I

1253
01:14:29,760 --> 01:14:33,920
 think a lot of the domain randomization

1254
01:14:33,920 --> 01:14:39,400
 that we're doing in RL is having a similar effect on the cost

1255
01:14:39,400 --> 01:14:41,840
 landscapes that we're generating.

1256
01:14:41,840 --> 01:14:50,600
 So there's a more general interpretation of these ideas.

1257
01:14:50,600 --> 01:14:53,040
 In stochastic optimization, there's

1258
01:14:53,040 --> 01:14:55,160
 a field of randomized smoothing.

1259
01:15:02,280 --> 01:15:04,360
 OK.

1260
01:15:04,360 --> 01:15:08,760
 And in fact, many ways that you would

1261
01:15:08,760 --> 01:15:12,680
 choose to add noise to your simulation,

1262
01:15:12,680 --> 01:15:14,800
 or to your policy, or whatever--

1263
01:15:14,800 --> 01:15:18,560
 a lot of different choices of w will have this interpretation

1264
01:15:18,560 --> 01:15:21,760
 that it'll take potentially a complicated landscape.

1265
01:15:21,760 --> 01:15:26,720
 I've got a fun one plotted up here from Terry, actually.

1266
01:15:26,720 --> 01:15:27,600
 OK.

1267
01:15:27,600 --> 01:15:29,640
 This is just a--

1268
01:15:29,640 --> 01:15:32,720
 Terry's way of thinking about this was he's

1269
01:15:32,720 --> 01:15:35,200
 trying to throw a ball over a wall.

1270
01:15:35,200 --> 01:15:36,160
 OK.

1271
01:15:36,160 --> 01:15:40,720
 And he's trying to maximize the distance,

1272
01:15:40,720 --> 01:15:42,920
 the final distance of the ball.

1273
01:15:42,920 --> 01:15:44,440
 And the only control decision to make

1274
01:15:44,440 --> 01:15:47,240
 is sort of the angle at which you throw.

1275
01:15:47,240 --> 01:15:48,200
 OK.

1276
01:15:48,200 --> 01:15:53,000
 And for some small angles, you'll just land smoothly.

1277
01:15:53,000 --> 01:15:57,600
 And you'll get better and better scores, less cost here.

1278
01:15:57,600 --> 01:16:00,280
 At some point, you'll run into the wall.

1279
01:16:00,280 --> 01:16:05,200
 All of these angles have exactly the same cost.

1280
01:16:05,200 --> 01:16:07,080
 And then suddenly, you're over the wall.

1281
01:16:07,080 --> 01:16:08,320
 So you drop down.

1282
01:16:08,320 --> 01:16:10,440
 45 is sort of the optimal solution,

1283
01:16:10,440 --> 01:16:12,800
 is to throw it 45 degrees.

1284
01:16:12,800 --> 01:16:14,560
 At some point, you throw too steeply,

1285
01:16:14,560 --> 01:16:16,920
 and you actually hit the wall again, because you went up

1286
01:16:16,920 --> 01:16:17,760
 and on the way down.

1287
01:16:17,760 --> 01:16:23,600
 But if you were to just add some randomness--

1288
01:16:23,600 --> 01:16:25,920
 so if you took the policy parameters,

1289
01:16:25,920 --> 01:16:28,840
 and you say, I'm going to throw the ball at theta,

1290
01:16:28,840 --> 01:16:31,080
 plus or minus some Gaussian.

1291
01:16:31,080 --> 01:16:32,960
 So every time I throw it, I'll just throw it

1292
01:16:32,960 --> 01:16:35,080
 at theta plus some Gaussian.

1293
01:16:35,080 --> 01:16:38,480
 And I'll take the expected value of that cost instead.

1294
01:16:38,480 --> 01:16:41,880
 Then for sort of arbitrarily complicated landscapes,

1295
01:16:41,880 --> 01:16:44,800
 you end up with things that look much more

1296
01:16:44,800 --> 01:16:48,720
 amenable to gradient descent.

1297
01:16:48,720 --> 01:16:50,280
 And I think this is an essential part

1298
01:16:50,280 --> 01:16:55,160
 of what's making policy-based, gradient-based methods work

1299
01:16:55,160 --> 01:16:55,880
 in RL.

1300
01:16:55,880 --> 01:17:03,680
 OK, I've talked too slowly, I guess.

1301
01:17:03,680 --> 01:17:04,320
 I'm sorry.

1302
01:17:04,320 --> 01:17:11,640
 But let me see if I can at least indicate

1303
01:17:11,640 --> 01:17:14,520
 one other important idea.

1304
01:17:14,520 --> 01:17:17,480
 So I think those are maybe the two I really

1305
01:17:17,480 --> 01:17:19,280
 wanted to land first.

1306
01:17:19,280 --> 01:17:22,360
 One is that we're switched to black box optimization.

1307
01:17:22,360 --> 01:17:24,760
 The second is that I think these stochastic formulations

1308
01:17:24,760 --> 01:17:29,560
 really affect the success of a gradient-based method.

1309
01:17:29,560 --> 01:17:34,920
 All right, let me just tell you what policy gradient is

1310
01:17:34,920 --> 01:17:39,320
 in a way that Abhishek can build on here.

1311
01:17:43,480 --> 01:17:56,040
 So policy gradient in RL is not quite black box optimization.

1312
01:17:56,040 --> 01:17:59,680
 So imagine I have a function.

1313
01:17:59,680 --> 01:18:03,800
 Imagine I'm trying to do this, minimize over x, f of x.

1314
01:18:03,800 --> 01:18:05,880
 I'll leave the randomness out for just a moment

1315
01:18:05,880 --> 01:18:09,520
 just to make this point simple.

1316
01:18:09,520 --> 01:18:12,760
 Imagine I have a nested function.

1317
01:18:12,760 --> 01:18:17,560
 I have two parts of my system, two parts of the cost

1318
01:18:17,560 --> 01:18:18,800
 function.

1319
01:18:18,800 --> 01:18:25,720
 Let's say this is something that is known,

1320
01:18:25,720 --> 01:18:32,520
 and I know partial g, partial x.

1321
01:18:32,520 --> 01:18:35,360
 So I have gradients on the inside.

1322
01:18:35,360 --> 01:18:39,960
 And this is unknown, black box.

1323
01:18:39,960 --> 01:18:44,640
 [WRITING]

1324
01:18:44,640 --> 01:18:48,280
 OK, so not surprisingly, this is going to be my policy.

1325
01:18:48,280 --> 01:18:49,880
 This is going to be my neural network.

1326
01:18:49,880 --> 01:18:57,480
 [WRITING]

1327
01:18:57,480 --> 01:19:00,280
 And this could be my dynamics and cost function.

1328
01:19:00,280 --> 01:19:06,280
 There's a lot of parameters in a neural network.

1329
01:19:06,280 --> 01:19:09,320
 You probably don't want to just randomly check

1330
01:19:09,320 --> 01:19:11,040
 all the parameters of a neural network.

1331
01:19:11,040 --> 01:19:12,560
 Well, we can talk about when you do

1332
01:19:12,560 --> 01:19:13,800
 and when you don't want to do.

1333
01:19:13,800 --> 01:19:14,440
 It's viable.

1334
01:19:14,440 --> 01:19:17,200
 But it seems like you'd like to leverage the fact

1335
01:19:17,200 --> 01:19:20,560
 that at least part of my gradients are known.

1336
01:19:20,560 --> 01:19:27,600
 And this is the key idea in the policy gradient algorithms,

1337
01:19:27,600 --> 01:19:32,520
 basically is to, instead of adding--

1338
01:19:32,520 --> 01:19:34,080
 so there would be two approaches I

1339
01:19:34,080 --> 01:19:36,880
 could do if I wanted to do the random version of this.

1340
01:19:36,880 --> 01:19:43,840
 [WRITING]

1341
01:19:43,840 --> 01:19:45,680
 I could try to minimize something like this.

1342
01:19:45,680 --> 01:19:46,760
 I could add noise directly.

1343
01:19:46,760 --> 01:19:59,840
 [WRITING]

1344
01:19:59,840 --> 01:20:04,560
 Or I can add noise to the output of my neural network,

1345
01:20:04,560 --> 01:20:05,060
 let's say.

1346
01:20:05,060 --> 01:20:22,840
 [WRITING]

1347
01:20:22,840 --> 01:20:27,400
 And if you do this second version, in both cases,

1348
01:20:27,400 --> 01:20:33,480
 there's an interpretation where if x plus w was better than x,

1349
01:20:33,480 --> 01:20:35,600
 then I would like to make x plus w more

1350
01:20:35,600 --> 01:20:37,400
 likely to happen in the future.

1351
01:20:37,400 --> 01:20:40,640
 That's the basic gradient descent sort of story.

1352
01:20:40,640 --> 01:20:46,680
 If x plus w was better, make it more likely to happen.

1353
01:20:46,680 --> 01:20:50,120
 In this case, you say I've got a neural network outputting

1354
01:20:50,120 --> 01:20:51,640
 y equals g of x.

1355
01:20:51,640 --> 01:20:55,080
 [WRITING]

1356
01:20:55,080 --> 01:20:58,960
 If y plus w was better, I'd like to make y plus w more likely

1357
01:20:58,960 --> 01:21:00,280
 to happen in the future.

1358
01:21:00,280 --> 01:21:03,000
 And I can do that by using gradient descent on g.

1359
01:21:03,000 --> 01:21:11,840
 So the policy gradient suite of algorithms in RL

1360
01:21:11,840 --> 01:21:15,840
 is basically a combination of the black box optimization,

1361
01:21:15,840 --> 01:21:18,920
 which is leveraging the gradient of just the policy,

1362
01:21:18,920 --> 01:21:20,840
 hence the name.

1363
01:21:20,840 --> 01:21:23,360
 It's often, I think, misused.

1364
01:21:23,360 --> 01:21:25,240
 The word policy gradient is often misused.

1365
01:21:25,240 --> 01:21:29,040
 But I think that, in my mind, that's the key idea,

1366
01:21:29,040 --> 01:21:31,240
 is that you take the gradient of your policy,

1367
01:21:31,240 --> 01:21:32,800
 the true gradient of your policy,

1368
01:21:32,800 --> 01:21:35,480
 and you combine it with a noisy approximate gradient

1369
01:21:35,480 --> 01:21:38,960
 from sampling for the part you don't know.

1370
01:21:38,960 --> 01:21:43,880
 And you're actually-- I don't feel too bad.

1371
01:21:43,880 --> 01:21:45,680
 I think we've got a problem on the problem set that

1372
01:21:45,680 --> 01:21:47,440
 will help you explore the details of that

1373
01:21:47,440 --> 01:21:51,240
 with enough instructions that it'll be OK.

1374
01:21:51,240 --> 01:21:56,160
 But this is sort of the key idea in policy gradient.

1375
01:21:56,160 --> 01:22:00,560
 You can imagine, if you have the additive structure

1376
01:22:00,560 --> 01:22:03,280
 from stochastic optimal control, then you

1377
01:22:03,280 --> 01:22:07,880
 can even be smarter about taking gradients

1378
01:22:07,880 --> 01:22:09,840
 through the serial chain and leverage

1379
01:22:09,840 --> 01:22:11,760
 the structure of the optimal control problem.

1380
01:22:11,760 --> 01:22:13,840
 And the more advanced algorithms in RL do that.

1381
01:22:13,840 --> 01:22:20,720
 That was a super-- it was like the three-minute version

1382
01:22:20,720 --> 01:22:21,840
 of a complicated topic.

1383
01:22:21,840 --> 01:22:24,560
 But is that OK?

1384
01:22:24,560 --> 01:22:26,040
 At that level, does it make sense?

1385
01:22:26,040 --> 01:22:28,320
 Yeah?

1386
01:22:28,320 --> 01:22:30,120
 OK.

1387
01:22:30,120 --> 01:22:30,620
 Good.

1388
01:22:30,620 --> 01:22:36,200
 So I will see many of you in face-to-face this week.

1389
01:22:36,200 --> 01:22:38,360
 Those of you that I'm going to meet in a few minutes,

1390
01:22:38,360 --> 01:22:41,000
 I'm happy to-- I'm happy, in general, to meet in person.

1391
01:22:41,000 --> 01:22:42,480
 It's just there's a logistical problem

1392
01:22:42,480 --> 01:22:44,360
 of getting to the offices and stuff like that.

1393
01:22:44,360 --> 01:22:48,200
 But most of you, I guess, I'll see on Zoom, just for logistics.

